<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="FLIPPED Android">
<meta name="description" content="The higher I got, the more amazed I was by the view.">
<meta name="theme-color" content="#000">
<title>Flipped&#39;s Blog</title>
<link rel="shortcut icon" href="/favicon.ico?v=1697116290420">
<link rel="stylesheet" href="/media/css/gemini.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/default.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>





</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="gemini">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>Flipped&#39;s Blog</span>
            </a>  
          
        </div>
        
          <p class="subtitle">The higher I got, the more amazed I was by the view.</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item nav-item-active">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout gemini ">
      <div class="section-layout-wrapper">
        <div id="sidebarMeta" class="sidebar">
    
<div class="sidebar-wrapper box-shadow-wrapper bg-color">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">Flipped</p>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">23</span>
        <span class="site-item-stat-name language" data-lan="article">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">9</span>
        <span class="site-item-stat-name language" data-lan="category">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">9</span>
        <span class="site-item-stat-name language" data-lan="tag">标签</span>
      </a>
    </div>
  </div>
  
    
  
  
    <div class="sidebar-item sidebar-item-social">
      <div class="social-item">
        
          
            <a href="">
              <i class="fa " title=""></i>
            </a>
          
        
        
      </div>
    </div>
  



</div>
</div>
<script>
  let sidebarMeta = document.querySelector('#sidebarMeta');
  let scheme = 'gemini';
  let sidebarWrapper = document.querySelector('.sidebar-wrapper');
  if (sidebarMeta && (scheme === 'pisces' || scheme === 'gemini')) {
    document.addEventListener('scroll', function(e) {
      if (document.scrollingElement.scrollTop > parseInt(sidebarMeta.style.marginTop) + 10) {
        sidebarWrapper.classList.add('home-sidebar-fixed')
      } else {
        sidebarWrapper.classList.remove('home-sidebar-fixed')
      }
    });
  }
  </script>
        <div class="section-box gemini">
          <section class="section  posts-expand slide-down-in">
            
  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/5PnOhK37O/">
      Spring Boot 自动配置
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2023-06-12 19:25:20">2023-06-12</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/spring/">
        <span>spring</span>
      </a>、
      
      
      
      <a href="https://flipped94.github.io/tag/spring-boot/">
        <span>spring boot</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>4<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>846<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>自动配置是由 Spring 自动发现 <code>@Configuration</code> 类，并添加到应用上下文。自动配置可能是有条件的，其激活取决于外部因素，例如具有特定值的某个配置参数。</p>
<h2 id="springboot-如何实现自动装配">SpringBoot 如何实现自动装配</h2>

                
                  <!-- 自动摘要出来的内容有<code则补上结尾,防止格式错误 -->
                  </code></pre>
                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/5PnOhK37O/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/iDQygBprt/">
      MyBatis 插件
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2023-05-29 15:11:37">2023-05-29</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/mybatis/">
        <span>MyBatis</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>5<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>891<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>很多开源框架也使用了插件扩展方式，例如，Dubbo 通过 SPI 方式实现了插件化的效果。MyBatis 也提供了类似的插件扩展机制。</p>
<p>MyBatis 允许自定义 Interceptor 拦截 SQL 语句执行过程中的某些关键逻辑，允许拦截的方法：</p>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/iDQygBprt/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/H34OOTkit/">
      Spring Boot 集成 Redis Sentinel
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2023-05-18 09:50:09">2023-05-18</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/redis/">
        <span>Redis</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>5<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>895<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>在普通的主从复制方案下（如在 Spring Boot 集成 Reids 主从中所描述的那样），一旦 主节点宕机，需要手动恢复主节点或选择从节点成为新的主节点（需要修改应用的主节点地址），这个过程需要人工干预。可以借助 Redis Sentinel（哨兵）实现自动故障切换，解决这个痛点。</p>
<h1 id="什么是-redis-sentinel">什么是 Redis Sentinel</h1>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/H34OOTkit/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/WaSvElZr4/">
      Spring Boot 集成 Redis 主从复制
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2023-05-17 22:06:22">2023-05-17</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/redis/">
        <span>Redis</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>3<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>506<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>单机 Redis 存在单点风险问题，最简单的处理方法就是主从复制，本文使用 Spring Boot 演示 Redis 主从复制（一主两从），结构如下所示。<br>
<img src="https://github.com/flipped94/redis-master-slave-demo/blob/main/image/redis-master-slave.png" alt="" loading="lazy"></p>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/WaSvElZr4/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/UqOG-r8J9/">
      Kafka（三）Producer
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-24 15:41:54">2021-01-24</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/kafka/">
        <span>Kafka</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>13<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>3056<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>本文主要关于 Kafka Producer 设计和 Producer API。</p>
<h2 id="producer-设计">Producer 设计</h2>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/UqOG-r8J9/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/qqGWSVvBP/">
      Kafka（二）Admin API
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-24 10:19:41">2021-01-24</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/kafka/">
        <span>Kafka</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>4<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>756<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>Kafka 包括五个核心 API：</p>
<ul>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/qqGWSVvBP/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/zawpATTcu/">
      Kafka（一） 入门
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-23 23:22:06">2021-01-23</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/kafka/">
        <span>Kafka</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>17<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>4617<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><h2 id="11-引言">1.1 引言</h2>
<h3 id="什么是事件流">什么是事件流？</h3>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/zawpATTcu/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/MW6ZY5hk/">
      安装 WSL2 (win10专业版，19042)
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-20 21:18:56">2021-01-20</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/linux/">
        <span>Linux</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>2<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>265<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>与 WSL 不同，WSL2 是一个完整的Linux内核。本文主要介绍在win10（版本号<strong>19042.746，专业版</strong>）中启用 WSL2。</p>
<h2 id="安装wsl2">安装WSL2</h2>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/MW6ZY5hk/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/Kyv9tMmW/">
      解决nvm下载node慢的问题
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-05 09:45:13">2021-01-05</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>1<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>124<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><p>nvm 是一个管理 node 版本的工具，可以安装切换不同版本的 node 提高开发效率。但是 nvm 默认的下载地址 http://nodejs.org/dist/ 服务器在国外，国内很慢，可能会下载失败。<br>
<img src="https://img.flipped.work/img/20210105094833.png"/><br>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/Kyv9tMmW/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>

  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://flipped94.github.io/post/9m2MXIyWR/">
      wait/notify/notifyAll 方法
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2021-01-01 17:01:39">2021-01-01</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://flipped94.github.io/tag/java-duo-xian-cheng/">
        <span>Java多线程</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>6<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>1487<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
            
              <p><ul>
<li>为什么 wait 方法必须在 synchronized 保护的同步代码中使用？</li>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://flipped94.github.io/post/9m2MXIyWR/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
    </div>
  </article>
  
            
            
<div class="page bg-color">
  <ul class="pagination-ul">
    
      <li class="pagination-dir">
        <a href="https://flipped94.github.io/">
          <i class="fa fa-angle-left"></i>
        </a>
      </li>
    
    
      
        <li class="pagination-li ">
            <a href="/page/../">
              1
            </a>
        </li>
      
        <li class="pagination-li pagination-active">
            <a href="/page/2">
              2
            </a>
        </li>
      
        <li class="pagination-li ">
            <a href="/page/3">
              3
            </a>
        </li>
      
    
    
      <li class="pagination-dir">
        <a href="/page/3">
          <i class="fa fa-angle-right"></i>
        </a>
      </li>
    
  </ul>
</div>
          </section>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a
        href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      
    </div>
  </footer>
  
  
  <div class="gemini back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
    back2TopText = document.querySelector('#back_to_top_text'),
    drawerBox = document.querySelector('#drawer_box'),
    rightSideBar = document.querySelector('.sidebar'),
    viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {

    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener('scroll', function (e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });


  let hasCacu = false;
  window.onresize = function () {
    calcuHeight();
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, transitionDir, {});
          }
        })
        window.Velocity(viewport, openProp, {
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp, {
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target", "_blank");
      }
    })
  }

  let faSearch = document.querySelector('#fa_search');
  faSearch.addEventListener('click', function () {
    document.querySelector('#search_mask').style = ''
  })

  // 代码高亮
  hljs.initHighlightingOnLoad();
  
  // 离开当前页title变化
  var leaveTitle = "";
  if (leaveTitle) {
    document.addEventListener('visibilitychange', function () {
      if (document.visibilityState == 'hidden') {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }

</script>
    <div class="light-box" id="light_box"></div>
<script>
  let imgs = document.querySelectorAll('.post-body img');
  let lightBox = document.querySelector('#light_box');
  lightBox.addEventListener('mousedown', (e) => {
    e.preventDefault()
  })
  lightBox.addEventListener('mousewheel', (e) => {
    e.preventDefault()
  })
  let width = window.innerWidth * 0.8;
  lightBox.onclick = () => {
    let img = lightBox.querySelector('img');
    lightBox.style = '';
    img && img.remove();
  }
  imgs.forEach(item => {
    item.onclick = function (e) {
      let lightImg = document.createElement('img');
      lightImg.src = this.src;
      lightBox.style = `height: 100%; opacity: 1; background-color: rgba(0, 0, 0, 0.5);cursor: zoom-out;`;
      lightImg.style = `width: ${width}px;border-radius: 2px;`;
      lightImg.onclick = function () {
        lightBox.style = '';
        this.remove();
      }
      lightBox.append(lightImg);
    }
  })
</script>
  </div>
</body>

<div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/jr1KpXQgr/"" data-c="
          &lt;p&gt;本文主要介绍如何搭建 Redis 集群、与集群交互、重新分片、故障转移等。&lt;/p&gt;
&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;
&lt;p&gt;要创建 Redis 集群，首先需要有一些以集群模式运行的空 Redis 实例。下面是以集群模式运行 Redis 实例的最小化配置。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;port 7000
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;要启用集群模式，需将 &lt;code&gt;cluster-enabled&lt;/code&gt; 指令设置为 &amp;quot;yes&amp;quot;。 每个实例还包含存储该节点配置的文件的路径，默认为 nodes.conf。这个配置文件由 Redis 集群的节点自行创建和更新，不能手动地去修改。&lt;/p&gt;
&lt;p&gt;一个最小的集群需要最少３个主节点，建议配置６个节点：３个主节点和３个从节点。在本地可以通过目录和端口区分节点，进行部署测试。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir cluster-test
cd cluster-test
mkdir 7000 7001 7002 7003 7004 7005
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 7000-7005 的每个目录中创建配置文件 redis.conf，内容就用上面的最简配置做模板，注意修改端口号为文件夹名称。然后打开 6 个终端，在每个终端中启动一个实例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd 7000
../redis-server ./redis.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从日志中看到每个节点都为自己分配了一个新 ID：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;12678:M 12 Oct 2023 10:12:05.847 * No cluster configuration found, I&#39;m 5d35bda6ad172d2bef65791657065794c2b06225
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个ID将一直被此节点使用，作为此节点在整个集群中的唯一标识。节点区分其他节点也是通过此ID来标识，而非IP或端口。IP可以改，端口可以改，但此ID不能改，直到这个节点离开集群。这个ID称之为节点ID(Node ID)。&lt;/p&gt;
&lt;h3 id=&#34;搭建集群&#34;&gt;搭建集群&lt;/h3&gt;
&lt;p&gt;经过上一步骤，现在已经运行了 6 个 Redis 实例，还需要通过向节点写入一些配置来创建集群。这里只介绍 &lt;code&gt;redis-cli&lt;/code&gt; 创建集群（redis源码 utils/create-cluster目录中的create-cluster脚本也可以创建集群）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \
127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
--cluster-replicas 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;create&lt;/code&gt; 命令是创建新的集群。 选项 &lt;code&gt;--cluster-replicas 1&lt;/code&gt; 表示为每一个主服务器配一个重服务器。其余的参数是要创建的集群中各实例的地址列表&lt;/p&gt;
&lt;p&gt;redis-cli 命令会给出一个配置。 输入 &amp;quot;yes&amp;quot; 接受配置。 集群会被配置并彼此连接好，意思是各节点实例被引导彼此通话并最终形成集群。最后，如果一切顺利，会看到类似下面的信息：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;[OK] All 16384 slots covered.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;与集群交互&#34;&gt;与集群交互&lt;/h3&gt;
&lt;p&gt;要连接到 Redis 集群，需要一个支持集群的 Redis 客户端，例如可以使用 &lt;code&gt;redis-cli&lt;/code&gt; 测试 Redis 集群：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ redis-cli -c -p 7000
127.0.0.1:7000&amp;gt; set foo bar
-&amp;gt; Redirected to slot [12182] located at 127.0.0.1:7002
OK
127.0.0.1:7002&amp;gt; set hello world
-&amp;gt; Redirected to slot [866] located at 127.0.0.1:7000
OK
127.0.0.1:7000&amp;gt; get foo
-&amp;gt; Redirected to slot [12182] located at 127.0.0.1:7002
&amp;quot;bar&amp;quot;
127.0.0.1:7002&amp;gt; get hello
-&amp;gt; Redirected to slot [866] located at 127.0.0.1:7000
&amp;quot;world&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;redis-cli&lt;/code&gt; 集群功能支持非常基础，它利用 Redis 集群节点能够将客户端重定向到正确节点（例如set foo 和 get foo 重定向到了 7002 节点）。 更好的客户端能够缓存哈希槽和节点地址之间的映射，直接使用正确连接，仅当集群配置发生更改时（例如故障转移后或系统管理员通过添加或删除节点更改集群布局后），才会刷新映射。&lt;/p&gt;
&lt;h3 id=&#34;第一个示例应用&#34;&gt;第一个示例应用&lt;/h3&gt;
&lt;p&gt;在演示如何操作 Redis 集群、执行故障转移或重新分片等操作之前，需要一些示例应用程序，或者至少能够理解简单的 Redis 集群客户端交互的语义。&lt;/p&gt;
&lt;p&gt;本节用两个示例应用介绍 &lt;a href=&#34;https://github.com/antirez/redis-rb-cluster&#34;&gt;redis-rb-cluster&lt;/a&gt;的基本用法。第一个是 redis-rb-cluster 库中的 example.rb 文件：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#39;./cluster&#39;

if ARGV.length != 2
    startup_nodes = [
        {:host =&amp;gt; &amp;quot;127.0.0.1&amp;quot;, :port =&amp;gt; 6379},
        {:host =&amp;gt; &amp;quot;127.0.0.1&amp;quot;, :port =&amp;gt; 6380}
    ]
else
    startup_nodes = [
        {:host =&amp;gt; ARGV[0], :port =&amp;gt; ARGV[1].to_i}
    ]
end

rc = RedisCluster.new(startup_nodes,32,:timeout =&amp;gt; 0.1)

last = false

while not last
    begin
        last = rc.get(&amp;quot;__last__&amp;quot;)
        last = 0 if !last
    rescue =&amp;gt; e
        puts &amp;quot;error #{e.to_s}&amp;quot;
        sleep 1
    end
end

((last.to_i+1)..1000000000).each{|x|
    begin
        rc.set(&amp;quot;foo#{x}&amp;quot;,x)
        puts rc.get(&amp;quot;foo#{x}&amp;quot;)
        rc.set(&amp;quot;__last__&amp;quot;,x)
    rescue =&amp;gt; e
        puts &amp;quot;error #{e.to_s}&amp;quot;
    end
    sleep 0.1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该应用做了一件非常简单的事情，执行了以下一些命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SET foo0 0
SET foo1 1
SET foo2 2
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行该应用会产生以下输出：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ruby ./example.rb
1
2
3
4
5
6
7
8
9
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个应用做的事情虽然简单，但是通过它可以看到重新分片期间会发生什么。&lt;/p&gt;
&lt;h3 id=&#34;重新分片&#34;&gt;重新分片&lt;/h3&gt;
&lt;p&gt;现在准备尝试集群重新分片，须保持 example.rb 程序运行，以便查看是否对程序运行产生一些影响。 另外，可以注释 sleep 调用，以便在重新分片期间产生更大的写入负载。&lt;/p&gt;
&lt;p&gt;重新分片基本上意味着将哈希槽从一组节点移动到另一组节点。 与集群创建一样，也是使用 &lt;code&gt;redis-cli&lt;/code&gt;完成。&lt;br&gt;
只需执行以下命令即可开始重新分片：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster reshard 127.0.0.1:7000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;只需要指定一个节点，&lt;code&gt;redis-cli&lt;/code&gt; 会自动找到其他节点。&lt;br&gt;
目前，&lt;code&gt;redis-cli&lt;/code&gt; 只能在管理员支持下进行重新分片，不能只是说将 5% 的槽从该节点移动到另一个节点（但这实现起来非常简单）。 redis-cli 会问几个问题。 第一个是想要多少槽重新分片：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;How many slots do you want to move (from 1 to 16384)?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以尝试重新分片 1000 个哈希槽，如果 example.rb 在没有 sleep 调用的情况下仍在运行，那么这些槽应该已经包含了大量的键。&lt;/p&gt;
&lt;p&gt;redis-cli 需要知道重新分片的目标是什么，即接收哈希槽的节点。通过节点 ID 指定实例节点（这里使用第一个主节点），可以使用以下命令找到节点的 ID：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli -p 7000 cluster nodes | grep myself 
5d35bda6ad172d2bef65791657065794c2b06225 127.0.0.1:7000@17000 myself,master - 0 1697080901000 1 connected 0-5460
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，目标节点是 &amp;quot;5d35bda6ad172d2bef65791657065794c2b062&amp;quot;。&lt;/p&gt;
&lt;p&gt;现在，系统会询问想要从哪些节点获取这些 key。 只需输入 &amp;quot;all&amp;quot; 即可从所有其他主节点获取哈希槽。&lt;/p&gt;
&lt;p&gt;最终确认后，将看到每个插槽的消息，表明将从一个节点移动到另一个节点。&lt;/p&gt;
&lt;p&gt;当重新分片正在进行时，应该能够看到示例程序的运行不受影响。 如果需要，可以在重新分片期间多次停止并重新启动它。重新分片结束后，可以使用以下命令测试集群的健康状况：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster check 127.0.0.1:7000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到所有哈希槽的分布，但这次主节点 127.0.0.1:7000 将拥有更多哈希插槽，约为 6461 个。&lt;/p&gt;
&lt;p&gt;使用如下命令可以字段进行重新分片，而无需以交互方式手动输入参数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster reshard &amp;lt;host&amp;gt;:&amp;lt;port&amp;gt; --cluster-from &amp;lt;node-id&amp;gt; --cluster-to &amp;lt;node-id&amp;gt; --cluster-slots &amp;lt;number of slots&amp;gt; --cluster-yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果可能经常重新分片，这个给命令是一个比较好的选择，但是目前 redis-cli 无法自动重新平衡集群，检查集群节点上键的分布并根据需要智能地移动哈希槽。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;--cluster-yes&lt;/code&gt; 选项表示集群管理器自动对询问回答“是”，从而以非交互模式运行。也可以通过设置 &lt;code&gt;REDISCLI_CLUSTER_YES&lt;/code&gt; 环境变量来激活此选项。&lt;/p&gt;
&lt;h3 id=&#34;第二个示例应用&#34;&gt;第二个示例应用&lt;/h3&gt;
&lt;p&gt;第一个示例应用程序不是很完美。它只是简单写数据，没有检查写入的内容是否正确。从我们的角度来看，总是可以将 key &amp;quot;foo&amp;quot; 的每个写操作都写入 42。在 redis-rb-cluster 库中，有一个更有趣的应用 consistency-test.rb 。 它使用了一些计数器（默认为 1000），并发送 &lt;code&gt;INCR&lt;/code&gt; 命令对计数器进行自增。该应用还做了两件事：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更新计数器时，会保存该写入。&lt;/li&gt;
&lt;li&gt;每次写入之前读取计数器，并将其与内存中的值进行比较，检查该值是否是我们期望的值，。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这意味着该应用是一个简单的一致性检查器，并且能够知道集群是否丢失了某些写入，或者它是否接受了未收到确认的写入。 在第一种情况下，会看到计数器的值小于保存的写入，而在第二种情况下，该值会更大。&lt;/p&gt;
&lt;p&gt;运行该应用每秒会产生一行输出：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ruby consistency-test.rb 127.0.0.1 7000
925 R (0 err) | 925 W (0 err) |
5030 R (0 err) | 5030 W (0 err) |
9261 R (0 err) | 9261 W (0 err) |
13517 R (0 err) | 13517 W (0 err) |
17780 R (0 err) | 17780 W (0 err) |
22025 R (0 err) | 22025 W (0 err) |
25818 R (0 err) | 25818 W (0 err) |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该行显示执行的读取 （R）和写入（W）次数以及错误（由于系统不可用，因此由于错误而未接受查询）数（err）。&lt;/p&gt;
&lt;p&gt;如果发现某些不一致，则会将新行添加到输出中。 例如，如果在程序运行时手动重置计数器，就会发生这种情况：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ redis-cli -h 127.0.0.1 -p 7000 set key_217 0
OK

(in the other tab I see...)

94774 R (0 err) | 94774 W (0 err) |
98821 R (0 err) | 98821 W (0 err) |
102886 R (0 err) | 102886 W (0 err) | 114 lost |
107046 R (0 err) | 107046 W (0 err) | 114 lost |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当将计数器设置为 0 时，实际值为 114，因此应用报告 114 个丢失的写入（集群未记住的 INCR 命令）。&lt;/p&gt;
&lt;p&gt;这个程序也会它来测试 Redis 集群故障转移。&lt;/p&gt;
&lt;h3 id=&#34;测试故障转移&#34;&gt;测试故障转移&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;在配置文件中添加配置 enable-debug-command yes，然后重启&lt;/strong&gt;，才能执行 &lt;code&gt;debug segfault&lt;/code&gt;。&lt;br&gt;
触发故障转移，最简单的（这也是分布式系统中可能发生的语义上最简单的故障）是使单个进程崩溃。&lt;/p&gt;
&lt;p&gt;可以使用以下命令查看主节点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ redis-cli -p 7000 cluster nodes | grep master
5d35bda6ad172d2bef65791657065794c2b06225 127.0.0.1:7000@17000 myself,master - 0 1697091768000 7 connected 0-5961 10923-11421
2a4af186044cf3a0264e90d20a8ebce778a79df1 127.0.0.1:7002@17002 master - 0 1697091768000 3 connected 11422-16383
9ee6e1a99dc0e1a6aa41666f70a3132bd2fa6e41 127.0.0.1:7001@17001 master - 0 1697091767571 2 connected 5962-10922
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 7000、7001、7002 是主节点，然后，使用 &lt;code&gt;DEBUG SEGAULT&lt;/code&gt; 命令使主节点 7002 崩溃：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ redis-cli -p 7002 debug segfault
Error: Server closed the connection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在可以查看一致性测试的输出：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;18849 R (0 err) | 18849 W (0 err) |
23151 R (0 err) | 23151 W (0 err) |
27302 R (0 err) | 27302 W (0 err) |
...
29659 R (578 err) | 29660 W (577 err) |
33749 R (578 err) | 33750 W (577 err) |
37918 R (578 err) | 37919 W (577 err) |
42077 R (578 err) | 42078 W (577 err) |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在故障转移期间，系统无法接受 578 次读取和 577 次写入，但是数据库中没有出现不一致情况。 这听起来可能出乎意料，因为在本教程的第一部分中，指出 Redis 集群可能会在故障转移期间丢失写入，因为它使用异步复制。 没有说的是，这种情况不太可能发生，因为 Redis 几乎同时向客户端发送回复，并将复制命令发送到副本，因此丢失数据的窗口非常小。 但很难触发并不意味着不可能，所以这并不会改变 Redis 集群提供的一致性保证。&lt;/p&gt;
&lt;p&gt;现在可以检查故障转移后的集群设置是什么（请注意，同时重新启动了崩溃的实例，以便它作为副本重新加入集群）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$  redis-cli -p 7000 cluster nodes
bcfdb9cb8cea74d4392512e5ce9d1595f78b58b7 127.0.0.1:7003@17003 slave 9ee6e1a99dc0e1a6aa41666f70a3132bd2fa6e41 0 1697092771903 2 connected
514272b9dcd053f2ec4ff62a268fa2eeb1f93dbd 127.0.0.1:7005@17005 slave 5d35bda6ad172d2bef65791657065794c2b06225 0 1697092770000 7 connected
5d35bda6ad172d2bef65791657065794c2b06225 127.0.0.1:7000@17000 myself,master - 0 1697092771000 7 connected 0-5961 10923-11421
2a4af186044cf3a0264e90d20a8ebce778a79df1 127.0.0.1:7002@17002 slave 58680287a896d053b2a1005f2ff6a91cdafc604a 0 1697092771402 8 connected
58680287a896d053b2a1005f2ff6a91cdafc604a 127.0.0.1:7004@17004 master - 0 1697092771000 8 connected 11422-16383
9ee6e1a99dc0e1a6aa41666f70a3132bd2fa6e41 127.0.0.1:7001@17001 master - 0 1697092770000 2 connected 5962-10922
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在，主服务器在端口 7000、7001 和 7004 上运行。以前的主服务器（即在端口 7002 上运行的 Redis 实例）现在是 7004 的副本。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CLUSTER NODES&lt;/code&gt; 命令的输出可能看起来很复杂，但实际上非常简单，并且由以下标记组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点ID&lt;/li&gt;
&lt;li&gt;IP:端口&lt;/li&gt;
&lt;li&gt;标志：主、从、自己、失败&lt;/li&gt;
&lt;li&gt;如果是从，则为主节点的节点 ID&lt;/li&gt;
&lt;li&gt;最后一次等待 PING 等待回复的时间。&lt;/li&gt;
&lt;li&gt;最后收到 PONG 的时间。&lt;/li&gt;
&lt;li&gt;该节点的配置纪元（请参阅集群规范）。&lt;/li&gt;
&lt;li&gt;到该节点的连接的状态。&lt;/li&gt;
&lt;li&gt;哈希槽&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;手动故障转移&#34;&gt;手动故障转移&lt;/h3&gt;
&lt;p&gt;有时，强制故障转移而不会对主节点造成任何问题是很有用的。 例如，要升级主节点的 Redis 进程，最好对其进行故障转移，将其转变为副本，同时对可用性的影响最小。&lt;/p&gt;
&lt;p&gt;Redis 集群支持使用 &lt;code&gt;CLUSTER FAILOVER&lt;/code&gt; 命令进行手动故障转移，该命令必须在要进行故障转移的主节点的副本之一中执行。&lt;/p&gt;
&lt;p&gt;手动故障转移很特殊，并且与实际主故障导致的故障转移相比更安全。 它们以一种避免故障转移过程中数据丢失的方式进行，仅当系统确定新主节点处理了旧主节点的所有复制时，才切换主从。&lt;/p&gt;
&lt;p&gt;执行手动故障转移时在副本日志中将看到日下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;# Manual failover user request accepted.
# Received replication offset for paused master manual failover: 347540
# All master replication stream processed, manual failover can start.
# Start of election delayed for 0 milliseconds (rank #0, offset 347540).
# Starting a failover election for epoch 7545.
# Failover election won: I&#39;m the new master.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;添加节点&#34;&gt;添加节点&lt;/h3&gt;
&lt;p&gt;添加新节点的第一步是添加一个空节点，然后将一些数据移入其中（如果它是新主节点），或者告诉它设置为已知节点的副本（如果它是副本）。这里会展示添加主从节点。&lt;/p&gt;
&lt;h4 id=&#34;添加主节点&#34;&gt;添加主节点。&lt;/h4&gt;
&lt;p&gt;在终端中打开一个新 tab，进入 cluster-test 目录，创建名为 7006 的目录，在里面创建一个 redis.conf 文件，与其他节点使用的文件类似，但使用 7006 作为端口号。最后使用 &lt;code&gt;redis-server redis.conf&lt;/code&gt; 启动服务器。&lt;/p&gt;
&lt;p&gt;现在，使用 redis-cli 来将节点添加到现有集群中：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;add-node&lt;/code&gt; 命令加入集群，第一个参数是新节点的地址，第二个参数是集群中任意一个节点的地址。&lt;br&gt;
现在可以连接到新节点来看看它是否真的加入了集群：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ redis-cli -h 127.0.0.1 -p 7006
127.0.0.1:7006&amp;gt; cluster nodes
5d35bda6ad172d2bef65791657065794c2b06225 127.0.0.1:7000@17000 master - 0 1697094039602 7 connected 0-5961 10923-11421
58680287a896d053b2a1005f2ff6a91cdafc604a 127.0.0.1:7004@17004 master - 0 1697094039501 8 connected 11422-16383
2a4af186044cf3a0264e90d20a8ebce778a79df1 127.0.0.1:7002@17002 slave,fail - 1697093742395 0 0 disconnected
9ee6e1a99dc0e1a6aa41666f70a3132bd2fa6e41 127.0.0.1:7001@17001 master - 0 1697094040000 2 connected 5962-10922
57e63c3535f293425cc6573d15b24fa38920ae22 127.0.0.1:7006@17006 myself,master - 0 1697094040000 0 connected
514272b9dcd053f2ec4ff62a268fa2eeb1f93dbd 127.0.0.1:7005@17005 slave 5d35bda6ad172d2bef65791657065794c2b06225 0 1697094039602 7 connected
bcfdb9cb8cea74d4392512e5ce9d1595f78b58b7 127.0.0.1:7003@17003 slave 9ee6e1a99dc0e1a6aa41666f70a3132bd2fa6e41 0 1697094040605 2 connected
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，由于该节点已经连接到集群，因此它已经能够正确重定向客户端查询，并且通常是集群的一部分。 但与其主节点相比，它有两个不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它不保存任何数据，因为它没有分配哈希槽。&lt;/li&gt;
&lt;li&gt;因为它是一个没有分配哈希槽的master，所以当replica想要成为master时，它不参与选举过程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前面重新分片，也可以使用 redis-cli 的重新分片功能将哈希槽分配给该节点。&lt;/p&gt;
&lt;h4 id=&#34;添加从节点&#34;&gt;添加从节点&lt;/h4&gt;
&lt;p&gt;添加新副本可以通过两种方式执行。 最简单的方法是 redis-cli，并且使用 &lt;code&gt;--cluster-slave&lt;/code&gt; 选项，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster add-node 127.0.0.1:7007 127.0.0.1:7000 --cluster-slave
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此处的命令与添加主节点命令相同，因此没有指定该节点的主节点。这种情况下，redis-cli 会将新节点添加为从节点较少的主节点的从节点。&lt;/p&gt;
&lt;p&gt;但是，也可以使用以下命令指定成为指定主节点的从节点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster add-node 127.0.0.1:7007 127.0.0.1:7000 --cluster-slave --cluster-master-id 5d35bda6ad172d2bef65791657065794c2b06225
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;移除节点&#34;&gt;移除节点&lt;/h3&gt;
&lt;p&gt;要删除副本节点，只需使用 redis-cli 的 &lt;code&gt;del-node&lt;/code&gt; 命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli --cluster del-node 127.0.0.1:7000 `&amp;lt;node-id&amp;gt;`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第一个参数是集群中任意一个节点，第二个参数是要待删除节点的 ID。&lt;/p&gt;
&lt;p&gt;可以以相同的方式删除主节点，但是它必须为空主节点。 如果主节点不为空，则在删除之前须将其数据重新分片到所有其他主节点。&lt;/p&gt;
&lt;p&gt;删除主节点的另一种方法是对其执行手动故障转移，并在该节点变成新主节点的副本后删除该节点。&lt;/p&gt;
&lt;h3 id=&#34;副本迁移&#34;&gt;副本迁移&lt;/h3&gt;
&lt;p&gt;有一种特殊的情况，希望副本自动从一个主节点迁移到另一个主节点，而无需系统管理员的帮助。副本的自动重新配置称为副本迁移，能够提高Redis集群的可靠性。在 Redis 集群中，可以使用以下命令将从节点配置为另一个主节点的从节点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CLUSTER REPLICATE &amp;lt;master-node-id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在某些情况下，可能希望让集群副本从一个主节点移动到另一个主节点，因为通常 Redis 集群对故障的抵抗能力与定主节点的副本数量一样。例如，如果主节点只有一个副本，同事发生故障时，集群将无法继续操作，因为没有其他实例有主节点的哈希槽的副本。&lt;/p&gt;
&lt;p&gt;为了提高系统的可靠性，可以选择向每个主节点添加额外的副本，但这很昂贵。 副本迁移允许向一些主节点添加额外副本。 例如，有 10 个主节点，每个主节点有 1 个副本，总共 20 个实例。 但是，可以添加 3 个实例作为某些主实例的副本，即某些主实例将拥有多个副本。&lt;/p&gt;
&lt;p&gt;通过副本迁移，可以具有多个副本的主节点中的副本迁移到没有副本的主节点，作为其副本。 因此，当副本在凌晨 4 点出现故障后，另一个副本将取代它，并且当主服务器在凌晨 5 点也发生故障时，仍然可以选举一个副本，以便集群可以继续运行 操作。&lt;/p&gt;
&lt;p&gt;关于副本迁移，以下三点需要了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群将尝试从拥有最多副本数的主节点迁移副本&lt;/li&gt;
&lt;li&gt;要从副本迁移中受益，只需向集群中的某个主节点添加更多副本&lt;/li&gt;
&lt;li&gt;cluster-migration-barrier配置控制副本迁移功能&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;升级-redis-集群中的节点&#34;&gt;升级 Redis 集群中的节点&lt;/h3&gt;
&lt;p&gt;升级副本节点很容易，因为只需停止节点并使用更新版本的 Redis 重新启动它。 如果存在使用副本节点读取的客户端，则当副本不可用时，它们应该能够重新连接到其他副本。&lt;/p&gt;
&lt;p&gt;升级则稍显复杂，建议的过程是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 CLUSTER FAILOVER 触发主节点到其副本之一的手动故障转移。&lt;/li&gt;
&lt;li&gt;等待主节点变成从节点。&lt;/li&gt;
&lt;li&gt;最后像升级副本一样升级节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果希望主节点成为刚刚升级的节点，请触发新的手动故障转移，以便将升级后的节点恢复为主节点。&lt;/p&gt;
&lt;p&gt;按照此过程，依次升级一个节点，直到升级所有节点。&lt;/p&gt;
&lt;h3 id=&#34;迁移到-redis-集群&#34;&gt;迁移到 Redis 集群&lt;/h3&gt;
&lt;p&gt;愿意迁移到 Redis 集群的用户可能只有一个主节点，或者可能已经使用了预先存在的分片设置，其中key 在 N 个节点之间分配，使用一些内部算法或由其客户端库或 Redis 代理实现的分片算法。&lt;/p&gt;
&lt;p&gt;在这两种情况下，都可以轻松迁移到 Redis 集群，但最重要的细节是应用程序是否使用多 key 操作以及如何使用。 存在三种不同的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不使用多个 key 操作、事务、或涉及多个 key 的 Lua 脚本（即使通过事务或 Lua 脚本将多个命令（关于同一 key）分组在一起进行访问）。&lt;/li&gt;
&lt;li&gt;使用涉及多个 key 的多个操作、事务、 Lua 脚本，但仅限于具有相同哈希标签的 key，这意味着一起使用的键都具有恰好相同的 {...} 子字符串。 例如，SUNION {user:1000}.foo {user:1000}.bar 是在同一哈希标签的上下文中定义。&lt;/li&gt;
&lt;li&gt;多个 key 操作、事务或涉及多个键的 Lua 脚本与不具有显式或相同哈希标签的 key 一起使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第三种情况不是由 Redis 集群处理的：需要修改应用程序，不使用多 key 操作或仅在同一哈希标签的上下文中使用它们。&lt;/p&gt;
&lt;p&gt;假设预先存在的数据集拆分为 N 个主节点，如果没有预先存在的分片，则 N=1，则需要执行以下步骤才能将数据集迁移到 Redis 集群：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;停止客户端。 目前无法自动实时迁移到 Redis 集群。&lt;/li&gt;
&lt;li&gt;使用 BGREWRITEAOF 命令为所有 N 个 master 生成 AOF 文件（aof-1~ aof-n），并等待 AOF 文件完全生成。&lt;/li&gt;
&lt;li&gt;将 AOF 文件 保存到某处。&lt;/li&gt;
&lt;li&gt;创建一个由 N 个主节点和 0 个副本节点组成的 Redis 集群。 确保所有节点都使用 AOF 持久化方式。&lt;/li&gt;
&lt;li&gt;停止所有集群节点，替换它们的 AOF 文件，第一个节点使用 aof-1，第二个节点使用 aof-2，以此类推。&lt;/li&gt;
&lt;li&gt;使用新的 AOF 文件重新启动 Redis 集群节点。会提示有些 key 根据节点的配置不应该在该节点。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;redis-cli --cluster fix&lt;/code&gt; 命令修复集群，以便根据哈希槽来迁移 key。&lt;/li&gt;
&lt;li&gt;最后使用 &lt;code&gt;redis-cli --cluster check&lt;/code&gt; 确保集群正常。&lt;/li&gt;
&lt;li&gt;重新启动修改为使用 Redis 集群感知客户端库的客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;还有一种将数据从外部实例导入到 Redis 集群的替代方法，即使用 &lt;code&gt;redis-cli --cluster import&lt;/code&gt; 命令。&lt;/p&gt;
&lt;p&gt;该命令将正在运行的实例的所有 key（从源实例中删除key）移动到指定的预先存在的 Redis 集群。 但是，如果使用 Redis 2.8 实例作为源实例，操作可能会很慢，因为 2.8 没有实现迁移连接缓存，因此可能需要使用 Redis 3.x 版本重新启动源实例才能执行此类操作。&lt;/p&gt;
">Redis 集群（2）搭建集群</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/qMbMReIQX/"" data-c="
          &lt;p&gt;Redis 集群提供了一种数据在多个 Redis 节点之间自动分片存储的运行模式。Redis 集群模式提供一定程度的高可用：在某些节点发生故障或无法通信时仍然可用。但是，如果发生更大的故障（例如，当大多数主节点不可用时），集群将停止服务。&lt;/p&gt;
&lt;p&gt;因此，借助 Redis 集群，可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自动将数据分布到多个节点。&lt;/li&gt;
&lt;li&gt;当部分节点故障或无法与集群的其余节点通信时仍然可用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;redis-集群-tcp-端口&#34;&gt;Redis 集群 TCP 端口&lt;/h3&gt;
&lt;p&gt;每个 Redis 集群节点都需要两个打开的 TCP 连接：一个为客户端提供服务的端口（例如 6379）和一个集群总线端口。 默认情况下，集群总线端口是前者接口+10000（例如16379）。&lt;/p&gt;
&lt;p&gt;集群总线是一种使用二进制协议的节点到节点的通信通道，由于带宽和处理时间较小，更适合在节点之间交换信息。 节点使用集群总线进行故障检测、配置更新、故障转移授权等。 客户端永远不应尝试与集群总线端口进行通信，而应使用客户端通信端口。 需要确保在防火墙中开放这两个端口，否则 Redis 集群节点将无法通信。&lt;/p&gt;
&lt;p&gt;为了使 Redis 集群正常工作，节点端口需要遵循如下原则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端通信端口（例如6379）需要开放给所有与集群交互的客户端和集群内的其它节点(主要是用来做 keys 迁移)&lt;/li&gt;
&lt;li&gt;集群总线端口（例如16379）需要能被集群其它所有节点访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;redis集群数据分片&#34;&gt;Redis集群数据分片&lt;/h3&gt;
&lt;p&gt;Redis 集群不使用一致性哈希，而是使用哈希槽。整个 Redis 集群有16384个哈希槽，决定一个 key 应该分配到那个槽的算法是：计算该 key 的 CRC16 结果再模 16834。&lt;/p&gt;
&lt;p&gt;集群中的每个节点负责一部分哈希槽，比如集群中有３个节点，则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点 Ａ 存储的哈希槽范围是：0 -- 5500&lt;/li&gt;
&lt;li&gt;节点 Ｂ 存储的哈希槽范围是：5501 -- 11000&lt;/li&gt;
&lt;li&gt;节点 Ｃ 存储的哈希槽范围是：11001 -- 16384&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样的分布方式方便节点的添加和删除。比如，需要新增一个节点Ｄ，只需要把 Ａ、Ｂ、Ｃ 中的部分哈希槽数据移到 Ｄ 节点。同样，如果希望在集群中删除 Ａ 节点，只需要把 Ａ 节点的哈希槽的数据移到 Ｂ 和 Ｃ 节点，当 Ａ 节点的数据全部被移走后，Ａ 节点就可以完全从集群中删除。&lt;/p&gt;
&lt;p&gt;因为把哈希槽从一个节点移到另一个节点不需要停机，所以，增加或删除节点，或更改节点上的哈希槽，也不需要停机。&lt;/p&gt;
&lt;p&gt;Redis 集群支持多个 key 操作，只要单个命令执行（或整个事务，或Lua脚本执行）涉及的所有 key 属于同一个哈希槽。可以通过使用称为哈希标签的功能强制多个 key 分配到同一个哈希槽。&lt;/p&gt;
&lt;p&gt;如果 key 含有大括号 &lt;code&gt;{}&lt;/code&gt;，则只有大括号中的字符串进行哈希处理。 例如，&amp;quot;user:{123}:profile&amp;quot; 和 &amp;quot;user:{123}:account&amp;quot; 会分配到同一哈希槽，因为它们哈希标签相同。所以，可以在一个命令中同时操作他们。&lt;/p&gt;
&lt;h3 id=&#34;redis集群主从模型&#34;&gt;Redis集群主从模型&lt;/h3&gt;
&lt;p&gt;为了保证在部分节点故障或网络不通时集群依然能正常工作，集群使用了主从模型，每个哈希槽有一（主节点）到N个副本（N-1个从节点）。&lt;/p&gt;
&lt;p&gt;在刚才的集群例子中，有 A, B, C 三个节点，如果 B 节点故障集群就不能正常工作了，因为不再有办法为 5501-11000 范围内的哈希槽提供服务。&lt;/p&gt;
&lt;p&gt;但是，如果给每一个节点都增加一个从节点，就变成了：A , B, C 三个节点是主节点，A1,  B1,  C1 分别是他们的从节点，当 B 节点宕机时，集群也能正常运作。&lt;br&gt;
在我们的具有节点 A、B、C 的示例集群中，如果节点 B 发生故障，集群将无法继续，因为我们不再有办法为 5501-11000 范围内的哈希槽提供服务。&lt;/p&gt;
&lt;p&gt;B1 节点是 B 节点的副本，如果 B 节点故障，集群会提升 B1 为主节点，从而让集群继续正常工作。但是，如果 B 和 B1 同时故障，集群就不能继续工作了。&lt;/p&gt;
&lt;h3 id=&#34;redis集群一致性保证&#34;&gt;Redis集群一致性保证&lt;/h3&gt;
&lt;p&gt;Redis 集群不保证强一致性，这意味着在某些情况下，Redis 集群可能会丢失写入。&lt;/p&gt;
&lt;p&gt;Redis 集群丢失写入的第一个原因是它使用异步复制。 这意味着在写入期间会发生以下情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端向主节点 B 发起写的操作&lt;/li&gt;
&lt;li&gt;主节点 B 响应客户端写操作成功&lt;/li&gt;
&lt;li&gt;主节点 B 向它的从节点 B1, B2, B3 同步该写操作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从上面的流程可以看出来，B 在响应客户端之前不会等待 B1、B2、B3 的确认（这通常会导致性能过低）。所以，如果主节点 B 在通知客户端写操作成功之后，同步给从节点之前，主节点 Ｂ 故障了，其中一个没有收到该写操作的从节点会晋升成主节点，该写操作就这样永远丢失了。&lt;/p&gt;
&lt;p&gt;所以，需要在性能和一致性之间进行权衡。&lt;/p&gt;
&lt;p&gt;如果真的需要，Redis集群支持同步复制的方式，通过 WAIT 指令来实现，这可以让丢失写操作的可能性降到很低。但就算使用了同步复制的方式，Redis 集群依然不是强一致性的，在某些复杂的情况下，比如从节点在与主节点失去连接之后被选为主节点，不一致性还是会发生。&lt;/p&gt;
&lt;p&gt;还有另一种值得注意的情况，Redis 集群会丢失写入，这种情况发生在网络分区期间，客户端与少数实例（至少包括一个主实例）隔离。以 6 节点集群为例，当网络出问题时，他们被分成２组网络，组内网络联通，但２组之间的网络不通，假设 A, C, A1, B1, C1 彼此之间是联通的，另一边，B 和 Z1 的网络是联通的。Z1 可以继续往 B 发起写操作，Ｂ 也接受 Z1 的写操作。当网络恢复时，如果这个时间间隔足够短，集群仍然能继续正常工作。如果时间比较长，以致B1在大多数的这边被选为主节点，那刚才Z1发给Ｂ的写操作都将丢失。&lt;/p&gt;
&lt;p&gt;注意，Z1给Ｂ发送写操作是有一个限制的，如果时间长度达到了大多数节点那边可以选出一个新的主节点时，少数这边的所有主节点都不接受写操作。这个时间的配置，称之为节点超时（node timeout），对集群来说非常重要，当达到了这个节点超时的时间之后，主节点被认为已经宕机，可以用它的一个从节点来代替。同样，在节点超时时，如果主节点依然不能联系到其他主节点，它将进入错误状态，不再接受写操作。&lt;/p&gt;
&lt;h3 id=&#34;redis集群配置参数&#34;&gt;Redis集群配置参数&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;cluster-enabled &amp;lt;yes/no&amp;gt;&lt;/code&gt;：如果配置 &amp;quot;yes&amp;quot; 则开启集群功能，此 Redis 实例作为集群的一个节点，否则，它是一个普通的单 Redis 实例。&lt;br&gt;
&lt;code&gt;cluster-config-file &amp;lt;文件名&amp;gt;&lt;/code&gt;：虽然此配置的名字叫 &amp;quot;集群配置文件&amp;quot;，但是此配置文件不可编辑，它是集群节点自动维护的文件，主要用于记录集群中有哪些节点、他们的状态以及一些持久化参数等，方便在重启时恢复这些状态。通常是在收到请求之后这个文件就会被更新。&lt;br&gt;
&lt;code&gt;cluster-node-timeout &amp;lt;毫秒&amp;gt;&lt;/code&gt;：这是集群中的节点能够失联的最大时间，超过这个时间，该节点就会被认为故障。如果主节点超过这个时间还是不可达，则它的从节点将启动故障迁移，升级成主节点。注意，任何一个节点在这个时间之内如果还是没有连上大部分的主节点，则此节点将停止接收任何请求。&lt;br&gt;
&lt;code&gt;cluster-slave-validity-factor &amp;lt;factor&amp;gt;&lt;/code&gt;：如果设置成０，则无论从节点与主节点失联多久，从节点都会尝试升级成主节点。如果设置成正数，则 &lt;code&gt;cluster-node-timeout&lt;/code&gt; 乘以&lt;code&gt;cluster-slave-validity-factor&lt;/code&gt; 得到的时间，是从节点与主节点失联后，此从节点数据有效的最长时间，超过这个时间，从节点不会启动故障迁移。假设 &lt;code&gt;cluster-node-timeout=5&lt;/code&gt;，&lt;code&gt;cluster-slave-validity-factor=10&lt;/code&gt;，则如果从节点跟主节点失联超过50秒，此从节点不能成为主节点。注意，&lt;strong&gt;如果此参数配置为非0，将可能出现由于某主节点失联却没有从节点能顶上的情况，从而导致集群不能正常工作，在这种情况下，只有等到原来的主节点重新回归到集群，集群才恢复&lt;/strong&gt;。&lt;br&gt;
&lt;code&gt;cluster-migration-barrier &amp;lt;count&amp;gt;&lt;/code&gt;：主节点需要的最小从节点数，只有达到这个数，主节点失败时，它从节点才会进行迁移。&lt;br&gt;
&lt;code&gt;cluster-require-full-coverage &amp;lt;yes/no&amp;gt;&lt;/code&gt;：在部分 key 所在的节点不可用时，如果此参数设置为 &amp;quot;yes&amp;quot; (默认值), 则整个集群停止接受操作；如果此参数设置为 &amp;quot;no&amp;quot;，则集群依然为可达节点上的 key 提供读操作。&lt;br&gt;
&lt;code&gt;cluster-allow-reads-when-down &amp;lt;yes/no&amp;gt;&lt;/code&gt;：默认是 &amp;quot;no&amp;quot;，表示当集群因主节点数量达不到最小值或者哈希槽没有完全分配而被标记为失效时，节点将停止所有客户端请求。设置成 &amp;quot;yes&amp;quot;，则允许集群失效的情况下依然可从节点中读取数据，保证了高可用。&lt;/p&gt;
">Redis 集群（1）Redis 集群概念</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/g8uDppTc1/"" data-c="
          &lt;p&gt;本文介绍 ArrayList 的扩容过程。ArrayList 底层是数组 elementData，用于存放插入的数据。它的容量能动态增长。在添加大量元素前，应用程序可以使用 ensureCapacity 操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。&lt;/p&gt;
&lt;p&gt;ArrayList 的核心字段如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 默认初始容量
     */
    private static final int DEFAULT_CAPACITY = 10;

    /**
     * 空实例共享这个数组
     */
    private static final Object[] EMPTY_ELEMENTDATA = {};

    /**
     * 无参构造方法创建的实例共享这个数组。
     * 与 EMPTY_ELEMENTDATA 区分，是为了知道第一次添加元素时扩容多少
     */
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};

    /**
     * 实际存储元素的数组，ArrayList 的容量是这个数组的长度。
     * 所有无参构造方法创建的实例 elementData 都是 DEFAULTCAPACITY_EMPTY_ELEMENTDATA
     * 首次添加元素时扩容到 DEFAULT_CAPACITYThe
     */
    transient Object[] elementData; // non-private to simplify nested class access

    /**
     * 元素个数
     */
    private int size;

    /**
     * 可以分配容量的最大值，尝试分配更大内存会抛出 OutOfMemoryError
     */
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ArrayList 的构造方法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 创建指定容量的空列表
     * 
     * @param  initialCapacity  列表初始容量
     * @throws IllegalArgumentException 如果列表初始容量小于零抛出非法参数异常
     * 
     */
    public ArrayList(int initialCapacity) {
        if (initialCapacity &amp;gt; 0) {
            // 创建 initialCapacity 大小的数组
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            // 赋值空数组
            this.elementData = EMPTY_ELEMENTDATA;
        } else {
            // 初始容量小于零抛出非法参数异常
            throw new IllegalArgumentException(&amp;quot;Illegal Capacity: &amp;quot; + initialCapacity);
        }
    }

    /**
     * 创建初始容量为10的空列表
     */
    public ArrayList() {
        // 默认空数组
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }

    /**
     * 按照集合的迭代器返回的顺序构造包含指定集合的元素的列表。
     *
     * @param c 要将其元素放入列表的集合
     * @throws NullPointerException 如果集合为 null，抛出 NullPointerException 异常
     */
    public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) {
        // 如果 C 为 nul，抛出 NullPointerException 异常
        Object[] a = c.toArray();
        if ((size = a.length) != 0) {
            // 如果 c 也是 ArrayList，直接赋值
            if (c.getClass() == ArrayList.class) {
                elementData = a;
            } else {
                // 如果不是，则拷贝元素
                elementData = Arrays.copyOf(a, size, Object[].class);
            }
        } else {
            // 空数组
            elementData = EMPTY_ELEMENTDATA;
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;无参数构造方法创建 &lt;code&gt;ArrayList&lt;/code&gt; 时，元素数组被赋值默认空数组。当首次添加元素时分配容量 10 的数组。&lt;/p&gt;
&lt;p&gt;以 &lt;code&gt;public boolean add(E e)&lt;/code&gt; 为例，分析扩容机制。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 将元素添加到列表末尾
     *
     * @param e 待添加的元素
     * @return &amp;lt;tt&amp;gt;true&amp;lt;/tt&amp;gt; 
     */
    public boolean add(E e) {
        // 检查容量和扩容，size+1 为所需最小容量
        ensureCapacityInternal(size + 1);
        // 添加元素
        elementData[size++] = e;
        return true;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在看 &lt;code&gt;ensureCapacityInternal&lt;/code&gt; 方法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void ensureCapacityInternal(int minCapacity) {
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;首先，&lt;code&gt;ensureCapacityInternal&lt;/code&gt; 方法调用 &lt;code&gt;calculateCapacity&lt;/code&gt; 计算所需最小容量：如果是默认空列表首次添加元素，最小容量为默认容量（&lt;code&gt;DEFAULT_CAPACITY&lt;/code&gt;，即 10），否则为当前元素个数 + 1。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private static int calculateCapacity(Object[] elementData, int minCapacity) {
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        return Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    return minCapacity;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，调用&lt;code&gt;ensureExplicitCapacity&lt;/code&gt;方法执行是否扩容判断和扩容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
    // 扩容判断
    if (minCapacity - elementData.length &amp;gt; 0)
        grow(minCapacity);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果当前容量小于所需最小容量，则执行扩容逻辑，即 grow 方法表示开始真正扩容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 增加容量以确保至少可以容纳由最小容量参数指定的元素数量。
     *
     * @param minCapacity 所需最小容量
     */
    private void grow(int minCapacity) {
        // 旧容量
        int oldCapacity = elementData.length;
        // 新容量为旧容量的 1.5 倍
        int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1);
        // 如果新容量比最小容量小，则新容量为最小容量
        if (newCapacity - minCapacity &amp;lt; 0)
            newCapacity = minCapacity;
        // 如果新容量比列表最大容量大，则会进行大容量处理
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0)
            // 如果所需最小容量大于列表最大容量，则新容量为 Integer.MAX_VALUE，否则为 MAX_ARRAY_SIZE
            newCapacity = hugeCapacity(minCapacity);
        // 扩容
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

    private static int hugeCapacity(int minCapacity) {
        // 溢出抛出 OutOfMemoryError 异常
        if (minCapacity &amp;lt; 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity &amp;gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;
    }
&lt;/code&gt;&lt;/pre&gt;
">ArrayList 扩容分析</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/gnbZ_m69L/"" data-c="
          &lt;p&gt;来源《深入理解Java虚拟机 JVM 高级特性与最佳实战》&lt;/p&gt;
&lt;p&gt;JVM 内存结构与 Java 内存模型容易混淆，其实它们是不同的。两者的主要作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JVM 内存结构和 Java 虚拟机的运行时区域有关。&lt;/li&gt;
&lt;li&gt;Java 内存模型和 Java 的并发编程有关。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;执行 Java 程序的过程中，Java 虚拟机在会把它管理的内存划分成若干个不同的数据区域：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程私有：
&lt;ul&gt;
&lt;li&gt;程序计数器&lt;/li&gt;
&lt;li&gt;虚拟机栈&lt;/li&gt;
&lt;li&gt;本地方法栈&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;线程共享：
&lt;ul&gt;
&lt;li&gt;堆&lt;/li&gt;
&lt;li&gt;方法区&lt;/li&gt;
&lt;li&gt;直接内存 (非运行时数据区的一部分)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;程序计数器&#34;&gt;程序计数器&lt;/h2&gt;
&lt;p&gt;程序计数器可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。&lt;br&gt;
程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。&lt;/p&gt;
&lt;h2 id=&#34;虚拟机栈&#34;&gt;虚拟机栈&lt;/h2&gt;
&lt;p&gt;Java 虚拟机栈的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。除了一些 Native 方法调用是通过本地方法栈实现，其他所有的 Java 方法调用都是通过栈来实现的（也需要和其他运行时数据区域比如程序计数器配合）。方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。&lt;br&gt;
局部变量表 主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。&lt;br&gt;
程序运行中栈可能会出现两种错误：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;StackOverFlowError： 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。&lt;/li&gt;
&lt;li&gt;OutOfMemoryError： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出 OutOfMemoryError 异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本地方法栈&#34;&gt;本地方法栈&lt;/h2&gt;
&lt;p&gt;和虚拟机栈所发挥的作用非常相似，区别是：&lt;strong&gt;虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务&lt;/strong&gt;。&lt;br&gt;
与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失败时分别抛出 StackOverFlowError 和 OutOfMemoryError 两种异常。&lt;/p&gt;
&lt;h2 id=&#34;堆&#34;&gt;堆&lt;/h2&gt;
&lt;p&gt;堆唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。Java 世界中“几乎”所有的对象都在堆中分配，但是，随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是更好地回收内存，或者更快地分配内存。&lt;br&gt;
在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新生代内存(Young Generation)&lt;/li&gt;
&lt;li&gt;老生代(Old Generation)&lt;/li&gt;
&lt;li&gt;永久代(Permanent Generation)&lt;br&gt;
Java 堆既可以被实现成固定大小的，也可以是可扩展的，不过主流是可扩展的（通过-Xmx和Xms设定），如果在堆中没有内存完成实例分配，并且堆再也无法扩展时，将会抛出 OutOfMemoryError 异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;方法区&#34;&gt;方法区&lt;/h2&gt;
&lt;p&gt;方法区会存储已被虚拟机加载的 类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。如果方法去无法满足新的内存分配需求时将会抛出 OutOfMemoryError 异常。&lt;/p&gt;
&lt;h2 id=&#34;运行时常量池&#34;&gt;运行时常量池&lt;/h2&gt;
&lt;p&gt;运行时常量池是方法区的一部分，Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 常量池表，这部分内容会在类加载后存放到方法区的运行时常量池中。运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。&lt;/p&gt;
&lt;h2 id=&#34;字符串常量池&#34;&gt;字符串常量池&lt;/h2&gt;
&lt;p&gt;字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。&lt;/p&gt;
&lt;h2 id=&#34;直接内存&#34;&gt;直接内存&lt;/h2&gt;
&lt;p&gt;直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，，但是这部分内存也被频繁地使用，可能出现 OutOfMemoryError 异常。直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。&lt;/p&gt;
">Java 内存结构</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/joFVkvmFu/"" data-c="
          &lt;p&gt;MyBatis 有两方面的 XML 配置，一个是全局配置文件（假设文件名为mybatis-config.xml），另一个是 Mapper.xml 配置文件中的 SQL 语句。在初始化的过程中，MyBatis 会读取全局配置文件以及所有的 Mapper 映射配置文件，同时还会加载这两个配置文件中指定的类，解析类中的相关注解，最终将解析得到的信息转换成配置对象。完成配置加载之后，MyBatis 就会根据得到的配置对象初始化各个模块。&lt;/p&gt;
&lt;h2 id=&#34;mybatis-configxml-解析&#34;&gt;mybatis-config.xml 解析&lt;/h2&gt;
&lt;p&gt;MyBatis 初始化的第一个步骤就是加载和解析 mybatis-config.xml 这个全局配置文件，入口是 &lt;code&gt;XMLConfigBuilder&lt;/code&gt;，它由 &lt;code&gt;SqlSessionFactoryBuilder.build()&lt;/code&gt; 方法创建。&lt;code&gt;XMLConfigBuilder&lt;/code&gt; 会解析 mybatis-config.xml 配置文件得到对应的 &lt;code&gt;Configuration&lt;/code&gt; 全局配置对象，然后 &lt;code&gt;SqlSessionFactoryBuilder&lt;/code&gt; 会根据得到的 &lt;code&gt;Configuration&lt;/code&gt; 全局配置对象创建一个 &lt;code&gt;DefaultSqlSessionFactory&lt;/code&gt; 对象。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Test
  public void test() throws IOException {
    // 读取配置文件
    try (InputStream resourceAsStream = Resources.getResourceAsStream(&amp;quot;mybatis-config.xml&amp;quot;)) {
      // 解析配置文件，封装 Configuration 对象，创建 DefaultSqlSessionFactory 对象
      SqlSessionFactory sqlSessionFactory =
       new SqlSessionFactoryBuilder().build(resourceAsStream);
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;XMLConfigBuilder 对象的核心功能是解析 mybatis-config.xml 配置文件，它继承自 BaseBuilder 抽象类， BaseBuilder 定义了如下三个字段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;configuration（Configuration 类型）：MyBatis 初始化解析到的全部配置信息都会记录到 Configuration 对象中。&lt;/li&gt;
&lt;li&gt;typeAliasRegistry（TypeAliasRegistry 类型）：别名注册中心。在配置文件中，使用 &lt;code&gt;&amp;lt;typeAliases&amp;gt;&lt;/code&gt; 标签为类定义别名。&lt;/li&gt;
&lt;li&gt;typeHandlerRegistry（TypeHandlerRegistry 类型）：TypeHandler 注册中心。在配置文件中，使用 &lt;code&gt;&amp;lt;typeHandlers&amp;gt;&lt;/code&gt; 标签自定义 &lt;code&gt;TypeHandler&lt;/code&gt;，实现数据库类型与 Java 类型的自定义转换。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XMLConfigBuilder 定义了以下核心字段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parsed（boolean 类型）：状态标识字段，记录当是否已经成功解析完配置文件。&lt;/li&gt;
&lt;li&gt;parser（XPathParser 类型）：用来解析配置文件的 XML 解析器。&lt;/li&gt;
&lt;li&gt;environment（String 类型）： 标签定义的环境名称。&lt;/li&gt;
&lt;li&gt;localReflectorFactory（ReflectorFactory 类型）：实现对 Reflector 对象的创建和缓存。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;XMLConfigBuilder.parse()&lt;/code&gt; 方法触发了配置文件的解析：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
   * 解析 mybatis-config.xml 配置文件得到 Configuration 全局配置对象
   * @return Configuration
   */
  public Configuration parse() {
    if (parsed) {
      throw new BuilderException(&amp;quot;Each XMLConfigBuilder can only be used once.&amp;quot;);
    }
    parsed = true;
    parseConfiguration(parser.evalNode(&amp;quot;/configuration&amp;quot;));
    return configuration;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中的 &lt;code&gt;parseConfiguration()&lt;/code&gt; 方法定义了解析配置文件的完整流程：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 解析配置文件
  private void parseConfiguration(XNode root) {
    try {
      // 解析 &amp;lt;properties&amp;gt; 标签；
      propertiesElement(root.evalNode(&amp;quot;properties&amp;quot;));
      // 解析 &amp;lt;settings&amp;gt; 标签；
      Properties settings = settingsAsProperties(root.evalNode(&amp;quot;settings&amp;quot;));
      // 处理日志相关组件；
      loadCustomVfs(settings);
      loadCustomLogImpl(settings);
      // 解析 &amp;lt;typeAliases&amp;gt; 标签；
      typeAliasesElement(root.evalNode(&amp;quot;typeAliases&amp;quot;));
      // 解析 &amp;lt;plugins&amp;gt; 标签；
      pluginElement(root.evalNode(&amp;quot;plugins&amp;quot;));
      // 解析 &amp;lt;objectFactory&amp;gt; 标签；
      objectFactoryElement(root.evalNode(&amp;quot;objectFactory&amp;quot;));
      // 解析 &amp;lt;objectWrapperFactory&amp;gt; 标签；
      objectWrapperFactoryElement(root.evalNode(&amp;quot;objectWrapperFactory&amp;quot;));
      // 解析 &amp;lt;reflectorFactory&amp;gt; 标签；
      reflectorFactoryElement(root.evalNode(&amp;quot;reflectorFactory&amp;quot;));
      settingsElement(settings);
      // read it after objectFactory and objectWrapperFactory issue #631
      // 解析 &amp;lt;environments&amp;gt; 标签；
      environmentsElement(root.evalNode(&amp;quot;environments&amp;quot;));
      // 解析 &amp;lt;databaseIdProvider&amp;gt; 标签；
      databaseIdProviderElement(root.evalNode(&amp;quot;databaseIdProvider&amp;quot;));
      // 解析 &amp;lt;typeHandlers&amp;gt; 标签；
      typeHandlerElement(root.evalNode(&amp;quot;typeHandlers&amp;quot;));
      // 解析 &amp;lt;mappers&amp;gt; 标签。
      mapperElement(root.evalNode(&amp;quot;mappers&amp;quot;));
    } catch (Exception e) {
      throw new BuilderException(&amp;quot;Error parsing SQL Mapper Configuration. Cause: &amp;quot; + e, e);
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里选择  &lt;code&gt;&amp;lt;properties&amp;gt;&lt;/code&gt;，&lt;code&gt;&amp;lt;settings&amp;gt;&lt;/code&gt;，&lt;code&gt;&amp;lt;plugins&amp;gt;&lt;/code&gt;，&lt;code&gt;&amp;lt;mappers&amp;gt;&lt;/code&gt; 简要介绍。&lt;/p&gt;
&lt;h3 id=&#34;解析-properties-标签&#34;&gt;解析 &lt;code&gt;&amp;lt;properties&amp;gt;&lt;/code&gt; 标签&lt;/h3&gt;
&lt;p&gt;通过 &lt;code&gt;&amp;lt;properties&amp;gt;&lt;/code&gt; 标签定义 KV 信息供 MyBatis 使用，从 &lt;code&gt;&amp;lt;properties&amp;gt;&lt;/code&gt; 标签中解析出来的 KV 信息会被记录到 &lt;code&gt;Properties&lt;/code&gt; 对象（也就是 &lt;code&gt;Configuration&lt;/code&gt; 全局配置对象的 &lt;code&gt;variables&lt;/code&gt; 字段），解析其他标签时，MyBatis 会使用这个 &lt;code&gt;Properties&lt;/code&gt; 对象中记录的 KV 信息替换匹配的占位符。&lt;/p&gt;
&lt;h3 id=&#34;解析-settings-标签&#34;&gt;解析 &lt;code&gt;&amp;lt;settings&amp;gt;&lt;/code&gt; 标签&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;settings&amp;gt;&lt;/code&gt; 标签配置全局性的配置，例如，是否使用二级缓存、是否开启懒加载功能等。&lt;/p&gt;
&lt;h3 id=&#34;解析-plugins-标签&#34;&gt;解析 &lt;code&gt;&amp;lt;plugins&amp;gt;&lt;/code&gt; 标签&lt;/h3&gt;
&lt;p&gt;可以自定义一个实现了 Interceptor 接口的插件来扩展 MyBatis 的行为。&lt;code&gt;pluginElement()&lt;/code&gt; 方法就是解析 &lt;code&gt;&amp;lt;plugins&amp;gt;&lt;/code&gt; 标签中配置的自定义插件，具体实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void pluginElement(XNode parent) throws Exception {
    if (parent != null) {
      // 遍历全部的 &amp;lt;plugin&amp;gt; 子标签
      for (XNode child : parent.getChildren()) {
        // 获取每个 &amp;lt;plugin&amp;gt; 标签中的interceptor属性
        String interceptor = child.getStringAttribute(&amp;quot;interceptor&amp;quot;);
        // 获取 &amp;lt;plugin&amp;gt; 标签下的其他配置信息
        Properties properties = child.getChildrenAsProperties();
        // 初始化 interceptor 属性指定的自定义插件
        Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).getDeclaredConstructor().newInstance();
        // 初始化插件的配置
        interceptorInstance.setProperties(properties);
        // 将 Interceptor 对象添加到 Configuration 的插件链中
        configuration.addInterceptor(interceptorInstance);
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;解析-mappers-标签&#34;&gt;解析 &lt;code&gt;&amp;lt;mappers&amp;gt;&lt;/code&gt; 标签&lt;/h3&gt;
&lt;p&gt;MyBatis 初始化的时候还会加载 &lt;code&gt;&amp;lt;mappers&amp;gt;&lt;/code&gt; 标签下定义的 Mapper 映射文件。&lt;code&gt;&amp;lt;mappers&amp;gt;&lt;/code&gt; 标签映射文件的位置，&lt;code&gt;mapperElement()&lt;/code&gt; 方法就是加载各个 Mapper.xml 映射文件。同时，还会扫描文件相应的 Mapper 接口，处理其中的注解并将 Mapper 接口注册到 &lt;code&gt;MapperRegistry&lt;/code&gt; 中。mapperElement() 方法的具体实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void mapperElement(XNode parent) throws Exception {
    if (parent != null) {
      for (XNode child : parent.getChildren()) {
        // 扫描指定包
        if (&amp;quot;package&amp;quot;.equals(child.getName())) {
          String mapperPackage = child.getStringAttribute(&amp;quot;name&amp;quot;);
          configuration.addMappers(mapperPackage);
        } else {
          // 解析 mapper 标签， resource、url、class 三个属性，只能设置一个
          String resource = child.getStringAttribute(&amp;quot;resource&amp;quot;);
          String url = child.getStringAttribute(&amp;quot;url&amp;quot;);
          String mapperClass = child.getStringAttribute(&amp;quot;class&amp;quot;);
          // 如果&amp;lt;mapper&amp;gt;子标签指定了resource或是url属性，会创建XMLMapperBuilder对象解析映射文件
          if (resource != null &amp;amp;&amp;amp; url == null &amp;amp;&amp;amp; mapperClass == null) {
            ErrorContext.instance().resource(resource);
            InputStream inputStream = Resources.getResourceAsStream(resource);
            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
            mapperParser.parse();
          } else if (resource == null &amp;amp;&amp;amp; url != null &amp;amp;&amp;amp; mapperClass == null) {
            ErrorContext.instance().resource(url);
            InputStream inputStream = Resources.getUrlAsStream(url);
            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());
            mapperParser.parse();
          } else if (resource == null &amp;amp;&amp;amp; url == null &amp;amp;&amp;amp; mapperClass != null) {
            // 如果&amp;lt;mapper&amp;gt;子标签指定了class属性，则向MapperRegistry注册class属性指定的Mapper接口
            Class&amp;lt;?&amp;gt; mapperInterface = Resources.classForName(mapperClass);
            configuration.addMapper(mapperInterface);
          } else {
            throw new BuilderException(&amp;quot;A mapper element may only specify a url, resource or class, but not more than one.&amp;quot;);
          }
        }
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;
">MyBatis 启动流程（上）全局配置文件解析</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/wWHOe505F/"" data-c="
          &lt;p&gt;持久化指将数据写入持久存储，例如固态硬盘 (SSD)。 Redis 提供了以下持久化选项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RDB（Redis Database）：RDB 持久化以指定的时间间隔保存数据快照。&lt;/li&gt;
&lt;li&gt;AOF（Append Only File）：AOF 持久化记录服务器收到的每一个写操作，服务器启动时再次执行这些操作重建原始数据集。&lt;/li&gt;
&lt;li&gt;RDB + AOF：同时使用 AOF 和 RDB。&lt;/li&gt;
&lt;li&gt;无持久化：禁用持久化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rdb-持久化&#34;&gt;RDB 持久化&lt;/h2&gt;
&lt;h3 id=&#34;rdb-优点&#34;&gt;RDB 优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RDB  文件非常紧凑，非常适合备份。 例如，希望在最近 24 小时内每小时归档一次 RDB 文件，并在 30 天内每天保存一个 RDB 快照，这可以在灾难恢复时轻松恢复不同版本的数据集。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;RDB 文件非常适合灾难恢复，它是可以远程传输的紧凑文件。&lt;/li&gt;
&lt;li&gt;RDB 最大限度地提高了 Redis 的性能，因为 Redis 父进程为了持久化需要做的唯一工作就是 fork 一个子进程，子进程会完成剩下的工作。 父进程永远不会执行磁盘 I/O 或类似操作。&lt;/li&gt;
&lt;li&gt;与 AOF 相比，RDB 更快。&lt;/li&gt;
&lt;li&gt;在主备复制时，RDB 支持重启和故障转移后的部分重同步。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;rdb-缺点&#34;&gt;RDB 缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果需要在 Redis 停止工作（例如断电）的情况下将数据丢失的可能性降到最低，则 RDB 并不适用。&lt;/li&gt;
&lt;li&gt;RDB 需要经常 fork() 以便使用子进程进行持久化。如果数据集很大，fork() 可能会很耗时，如果数据集很大且 CPU 性能不佳，可能会导致 Redis 停止几毫秒甚至一秒的服务。AOF 也需要 fork() 但频率较低。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aof-持久化&#34;&gt;AOF 持久化&lt;/h2&gt;
&lt;h3 id=&#34;aof-优点&#34;&gt;AOF 优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AOF 持久化的实时性更好：存在三种不同的 AOF 持久化方式（ &lt;code&gt;fsync&lt;/code&gt; 策略）：&lt;code&gt;no&lt;/code&gt;、&lt;code&gt;everysec&lt;/code&gt; 和 &lt;code&gt;always&lt;/code&gt;。默认是 &lt;code&gt;everysec&lt;/code&gt;。&lt;code&gt;fsync&lt;/code&gt; 使用后台线程执行，当没有进行 &lt;code&gt;fsync&lt;/code&gt; 时，主线程会努力执行写入操作，因此只损失一秒钟的写入操作。&lt;/li&gt;
&lt;li&gt;AOF 日志是一个仅追加的日志，因此不会出现覆盖或损坏问题。即使由于某种原因（磁盘已满或其他原因），日志以半写命令结束，redis-check-aof 工具也能很容易地修复。&lt;/li&gt;
&lt;li&gt;Redis 能够在 AOF 过大时自动在后台重写它。重写是完全安全的，因为当 Redis 继续追加到旧文件时，会用创建当前数据集所需的最小操作集生成一个全新的文件，一旦第二个文件准备好，Redis 就会切换这两个文件并开始追加到新文件。&lt;/li&gt;
&lt;/ul&gt;
">Redis （4）持久化</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/rd9wJW_LL/"" data-c="
          &lt;p&gt;来源&lt;a href=&#34;https://redis.io/docs/data-types/&#34;&gt;Redis 数据类型&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;stream-流&#34;&gt;Stream 流&lt;/h2&gt;
&lt;p&gt;Redis 流是一种数据结构，其作用类似于仅追加日志。可以使用流实时记录和处理事件，Redis流的使用场景包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事件源（例如，跟踪用户行为、点击等）&lt;/li&gt;
&lt;li&gt;传感器监控（例如，来自现场设备的数据）&lt;/li&gt;
&lt;li&gt;通知（例如，存储用户的通知记录）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Redis为流条目生成一个唯一的ID。可以使用这些ID在以后检索相关的条目，或者读取和处理流中所有的后续条目。&lt;/p&gt;
&lt;p&gt;Redis流支持几种修剪策略（防止流无限制增长）和几种消费策略（见 &lt;strong&gt;XREAD&lt;/strong&gt;、&lt;strong&gt;XREADGROUP&lt;/strong&gt; 和 &lt;strong&gt;XRANGE&lt;/strong&gt;）。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;向流中添加几条天气数据&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; XADD temperatures:us-ny:10007 * temp_f 87.2 pressure 29.69 humidity 46
&amp;quot;1658354918398-0&amp;quot;
&amp;gt; XADD temperatures:us-ny:10007 * temp_f 83.1 pressure 29.21 humidity 46.5
&amp;quot;1658354934941-0&amp;quot;
&amp;gt; XADD temperatures:us-ny:10007 * temp_f 81.9 pressure 28.37 humidity 43.7
&amp;quot;1658354957524-0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;b&gt;*&lt;/b&gt; 表示由 redis 生成 ID，可以自定义，但是要保证递增性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读取从ID 1658354934941-0 开始的两个条目&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; XRANGE temperatures:us-ny:10007 1658354934941-0 + COUNT 2
1) 1) &amp;quot;1658354934941-0&amp;quot;
   2) 1) &amp;quot;temp_f&amp;quot;
      2) &amp;quot;83.1&amp;quot;
      3) &amp;quot;pressure&amp;quot;
      4) &amp;quot;29.21&amp;quot;
      5) &amp;quot;humidity&amp;quot;
      6) &amp;quot;46.5&amp;quot;
2) 1) &amp;quot;1658354957524-0&amp;quot;
   2) 1) &amp;quot;temp_f&amp;quot;
      2) &amp;quot;81.9&amp;quot;
      3) &amp;quot;pressure&amp;quot;
      4) &amp;quot;28.37&amp;quot;
      5) &amp;quot;humidity&amp;quot;
      6) &amp;quot;43.7&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;从流尾部读取最多100个新条目，如果没有写入，则最多阻塞300毫秒&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; XREAD COUNT 100 BLOCK 300 STREAMS temperatures:us-ny:10007 $
(nil)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;XADD&lt;/strong&gt; 向流添加新条目。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XREAD&lt;/strong&gt; 从给定的位置开始并向前移动读取一个或多个条目。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XRANGE&lt;/strong&gt; 返回两个 ID 范围之间的条目。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XLEN&lt;/strong&gt; 返回流的长度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;向流中添加条目是 O(1)。访问任何条目都是 O(n)，其中 n 是 ID 的长度。由于流 ID 通常很短且长度固定，因此这有效地减少为常量查找时间，因为流基于基数树（Radix Tree）实现。&lt;/p&gt;
&lt;p&gt;简单地说，Redis 流提供了高效的插入和读取。&lt;/p&gt;
&lt;h2 id=&#34;geospatial-地理位置&#34;&gt;Geospatial 地理位置&lt;/h2&gt;
&lt;p&gt;Redis 地理空间索引存储坐标并搜索它们。这种数据结构对于在给定的半径或边界内寻找附近的点很有用。&lt;/p&gt;
&lt;h3 id=&#34;示例-2&#34;&gt;示例&lt;/h3&gt;
&lt;p&gt;假设有一个移动应用程序，找到离你当前位置最近的所有电动汽车充电站。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;添加几个地点到地理空间索引中&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; GEOADD locations:ca -122.27652 37.805186 station:1
(integer) 1
&amp;gt; GEOADD locations:ca -122.2674626 37.8062344 station:2
(integer) 1
&amp;gt; GEOADD locations:ca -122.2469854 37.8104049 station:3
(integer) 1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;找到给定地点5公里半径内的所有站点，并返回到每个站点的距离：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; GEOSEARCH locations:ca FROMLONLAT -122.2612767 37.7936847 BYRADIUS 5 km WITHDIST
1) 1) &amp;quot;station:1&amp;quot;
   2) &amp;quot;1.8523&amp;quot;
2) 1) &amp;quot;station:2&amp;quot;
   2) &amp;quot;1.4979&amp;quot;
3) 1) &amp;quot;station:3&amp;quot;
   2) &amp;quot;2.2441&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令-2&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GEOADD&lt;/strong&gt; 向地理空间索引中添加地理位置（注意经度在前，纬度在后）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GEOSEARCH&lt;/strong&gt; 返回具有给定半径或边界的所有地理位置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hyperloglog&#34;&gt;HyperLogLog&lt;/h2&gt;
&lt;p&gt;HyperLogLog是估计集合的基数的一种数据结构。集合的基数是集合中不重复元素元素的数目，比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8},，基数为5。基数估计就是在误差可接受的范围内，快速计算基数。作为一种概率数据结构，HyperLogLog 以完美的准确性换取有效的空间利用。&lt;br&gt;
Redis HyperLogLog 实现最多使用12 KB，标准误差为0.81%。&lt;/p&gt;
&lt;h3 id=&#34;示例-3&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;向 HyperLogLog 中添加元素&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; PFADD members 123
(integer) 1
&amp;gt; PFADD members 500
(integer) 1
&amp;gt; PFADD members 12
(integer) 1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;估计集合成员数量&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; PFCOUNT members
(integer) 3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令-3&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PFADD&lt;/strong&gt; 向 HyperLogLog 添加元素。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PFCOUNT&lt;/strong&gt; 返回集合中成员数量的估计值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PFMERGE&lt;/strong&gt; 将两个或多个 HyperLogLog 合并为一个。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-2&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;向 HyperLogLog 写 (PFADD) 和读 (PFCOUNT) 是在常量时间和空间内完成的。合并是 O(n)，其中 n 为合并的 HyperLogLog 数量。&lt;/p&gt;
&lt;h3 id=&#34;限制&#34;&gt;限制&lt;/h3&gt;
&lt;p&gt;HyperLogLog 可以估计最多2^64(18,446,744,073,709,551,616)个成员的集合的基数。&lt;/p&gt;
&lt;h2 id=&#34;bitmap-位图&#34;&gt;Bitmap 位图&lt;/h2&gt;
&lt;p&gt;Redis 位图是字符串数据类型的扩展，它可以将字符串当作位向量（由一些二进制位组成的向量）。还可以对一个或多个字符串执行位操作。位图的一些使用场景:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高效的集合表示，用于集合的成员对应于整数0-N的情况。&lt;/li&gt;
&lt;li&gt;对象权限，其中每个位代表一个特定的权限，类似于文件系统存储权限的方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;示例-4&#34;&gt;示例&lt;/h3&gt;
&lt;p&gt;假设有 1000 个部署在现场的传感器，标记为 0-999。希望快速确定某个传感器是否在某个时间 ping 了服务器。可以用位图处理这种场景，这个位图的键是时间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传感器 123 在2024-01-01-00:00 ping 了服务器。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SETBIT pings:2024-01-01-00:00 123 1
(integer) 0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;传感器123是否在2024-01-01-00:00 ping 了服务器&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; GETBIT pings:2024-01-01-00:00 123
1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;传感器 456 呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; GETBIT pings:2024-01-01-00:00 456
0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令-4&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SETBIT&lt;/strong&gt; 将指定偏移量的位的值设置为 0 或 1。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GETBIT&lt;/strong&gt; 返回指定偏移量的位的值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BITOP&lt;/strong&gt; 对一个或多个字符串进行位操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-3&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SETBIT&lt;/strong&gt; 和 &lt;strong&gt;GETBIT&lt;/strong&gt; 为0(1)。BITOP 是 O(n)，其中 n 是最长字符串的长度。&lt;/p&gt;
">Redis (3) 数据类型（Stream/Geospatial/HyperLogLog/Bitmap）</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/f3KuchnPs/"" data-c="
          &lt;p&gt;本文学习基本的 Redis 数据类型以及如何使用它们，均使用 &lt;code&gt;redis-cli&lt;/code&gt; 完成。来源 &lt;a href=&#34;https://redis.io/docs/data-types/&#34;&gt;Redis 数据类型&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;键&#34;&gt;键&lt;/h2&gt;
&lt;p&gt;Redis 键是二进制安全的，意味着可以使用任何二进制序列作为键，从形如 &amp;quot;foo&amp;quot; 的字符串到 JPEG 文件的内容，甚至空字符串也是有效键。&lt;br&gt;
几条关于键的规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不推荐非常大的键。例如，一个1024字节的键，不仅在内存方面，而且还因为在数据库查找该键可能需要几次昂贵的比较。对该键进行散列（例如 SHA1）是一个更好的主意，特别是从内存和带宽的角度来看。&lt;/li&gt;
&lt;li&gt;不推荐非常短的键。把 &amp;quot;u1000flw&amp;quot; 作键就没有什么意义，如果写成 &amp;quot;user:1000:followers&amp;quot; 更具可读性，而且与键对象本身和值对象使用的空间相比，增加的空间很小。&lt;/li&gt;
&lt;li&gt;坚持使用某种模式。例如&amp;quot;类型:id&amp;quot;，如 &amp;quot;user:1000&amp;quot;。点或破折号通常用于多字段，如 &amp;quot;comment:4321:reply.to&amp;quot; 或 &amp;quot;comment:4321:reply-to&amp;quot;。&lt;/li&gt;
&lt;li&gt;键最大允许 512MB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;string-字符串&#34;&gt;String 字符串&lt;/h2&gt;
&lt;p&gt;Redis 字符串存储字节序列，包括文本、序列化对象和二进制数组。因此，字符串是最基本的Redis数据类型。它们经常被用于缓存，但它们也支持额外的功能，比如实现计数器和执行位操作。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;存储并检索&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SET user:1 salvatore
OK
&amp;gt; GET user:1
&amp;quot;salvatore&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;存储 JSON 字符串并设置 10 秒后过期&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SET ticket:27 &amp;quot;\&amp;quot;{&#39;username&#39;: &#39;priya&#39;, &#39;ticket_id&#39;: 321}\&amp;quot;&amp;quot; EX 100
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;计数器递增&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; INCR views:page:2
(integer) 1
&amp;gt; INCRBY views:page:2 10
(integer) 11
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;限制&#34;&gt;限制&lt;/h3&gt;
&lt;p&gt;默认情况下，Redis 字符串的最大容量为512MB。&lt;/p&gt;
&lt;h3 id=&#34;基础命令&#34;&gt;基础命令&lt;/h3&gt;
&lt;h4 id=&#34;存储和检索&#34;&gt;存储和检索&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SET&lt;/strong&gt;: 存储字符串值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SETNX&lt;/strong&gt;: 只在键不存在的情况下存储字符串值。对于实现锁很有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GET&lt;/strong&gt;: 检索字符串值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MGET&lt;/strong&gt;: 在一个操作中检索多个字符串值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;计数器&#34;&gt;计数器&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;INCRBY&lt;/strong&gt; 是以原子方式递增（当传递负数时则递减）计数器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;INCRBYFLOAT&lt;/strong&gt; 适用于浮点型计数器。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;位运算&#34;&gt;位运算&lt;/h4&gt;
&lt;p&gt;参见后文 bitmap 数据类型&lt;/p&gt;
&lt;h3 id=&#34;性能&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;大多数字符串操作都是 O(1)，这意味着它们的效率很高。然而，要注意 &lt;strong&gt;SUBSTR&lt;/strong&gt;、&lt;strong&gt;GETRANGE&lt;/strong&gt; 和 &lt;strong&gt;SETRANGE&lt;/strong&gt; 命令，它们可能是O(n)。这些随机访问的字符串命令在处理大字符串时可能会导致性能问题。&lt;/p&gt;
&lt;h2 id=&#34;list-列表&#34;&gt;List 列表&lt;/h2&gt;
&lt;p&gt;Redis 列表是字符串值的链表。Redis 列表经常用于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实现堆栈和队列。&lt;/li&gt;
&lt;li&gt;为后台工作系统构建队列管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;示例-2&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;将列表用作队列（先进先出）&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; LPUSH work:queue:ids 101
(integer) 1
&amp;gt; LPUSH work:queue:ids 237
(integer) 2
&amp;gt; RPOP work:queue:ids
&amp;quot;101&amp;quot;
&amp;gt; RPOP work:queue:ids
&amp;quot;237&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;将列表用作栈（先进后出）&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; LPUSH work:queue:ids 101
(integer) 1
&amp;gt; LPUSH work:queue:ids 237
(integer) 2
&amp;gt; LPOP work:queue:ids
&amp;quot;237&amp;quot;
&amp;gt; LPOP work:queue:ids
&amp;quot;101&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;列表长度&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; LLEN work:queue:ids
(integer) 0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;原子地从一个列表中弹出一个元素并移动到另一个列表：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; LPUSH board:todo:ids 101
(integer) 1
&amp;gt; LPUSH board:todo:ids 273
(integer) 2
&amp;gt; LMOVE board:todo:ids board:in-progress:ids LEFT LEFT
&amp;quot;273&amp;quot;
&amp;gt; LRANGE board:todo:ids 0 -1
1) &amp;quot;101&amp;quot;
&amp;gt; LRANGE board:in-progress:ids 0 -1
1) &amp;quot;273&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;如果想要创建一个永远不会超过 100 个元素的上限列表，你可以在每次调用 &lt;strong&gt;LPUSH&lt;/strong&gt; 后调用 &lt;strong&gt;LTRIM&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; LPUSH notifications:user:1 &amp;quot;You&#39;ve got mail!&amp;quot;
(integer) 1
&amp;gt; LTRIM notifications:user:1 0 99
OK
&amp;gt; LPUSH notifications:user:1 &amp;quot;Your package will be delivered at 12:01 today.&amp;quot;
(integer) 2
&amp;gt; LTRIM notifications:user:1 0 99
OK
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;限制-2&#34;&gt;限制&lt;/h3&gt;
&lt;p&gt;Redis列表的最大长度是 2^32-1（4,294,967,295）个元素。&lt;/p&gt;
&lt;h3 id=&#34;基础命令-2&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LPUSH&lt;/strong&gt; 在列表的头部添加一个新的元素；&lt;strong&gt;RPUSH&lt;/strong&gt; 在尾部添加。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LPOP&lt;/strong&gt; 从一个列表的头部删除并返回一个元素；&lt;strong&gt;RPOP&lt;/strong&gt; 从列表的尾部删除并返回一个元素。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLEN&lt;/strong&gt; 返回一个列表的长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LMOVE&lt;/strong&gt; 将元素从一个列表中原子地移动到另一个列表中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LTRIM&lt;/strong&gt; 将一个列表减少到包含指定范围内的元素。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;阻塞命令&#34;&gt;阻塞命令&lt;/h3&gt;
&lt;p&gt;列表支持几个封锁命令。比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;BLPOP&lt;/strong&gt; 从一个列表的头部移除并返回一个元素。如果列表是空的，该命令会阻塞，直到有元素或者达到指定超时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BLMOVE&lt;/strong&gt; 原子地将元素从源列表中移动到目标列表中。如果源列表是空的，该命令会阻塞，直到有元素。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-2&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;访问列表头部或尾部的操作是 O(1)，这意味着它们的效率很高。然而，操作列表中的元素的命令通常是&lt;br&gt;
O(n)，对大列表运行 &lt;strong&gt;LINDEX&lt;/strong&gt;, &lt;strong&gt;LINSERT&lt;/strong&gt;, 和 &lt;strong&gt;LSET&lt;/strong&gt; 命令时要小心。&lt;/p&gt;
&lt;h2 id=&#34;set-集合&#34;&gt;Set 集合&lt;/h2&gt;
&lt;p&gt;Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的。可以使用 Redis 集合来有效地：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;追溯唯一项（例如，追溯访问给定博客文章的所有唯一IP地址）。&lt;/li&gt;
&lt;li&gt;表示关系（例如，具有特定角色的所有用户的集合）。&lt;/li&gt;
&lt;li&gt;执行常见的集合操作，如交集，并集，差集。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;示例-3&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;存储用户123和456的最喜欢的图书ID集：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SADD user:123:favorites 347
(integer) 1
&amp;gt; SADD user:123:favorites 561
(integer) 1
&amp;gt; SADD user:123:favorites 742
(integer) 1
&amp;gt; SADD user:456:favorites 561
(integer) 1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;检查用户123是否喜欢书742和299&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SISMEMBER user:123:favorites 742
(integer) 1
&amp;gt; SISMEMBER user:123:favorites 299
(integer) 0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;用户123和456均喜欢的书&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SINTER user:123:favorites user:456:favorites
1) &amp;quot;561&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;用户123收藏了多少本书？&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SCARD user:123:favorites
(integer) 3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;限制-3&#34;&gt;限制&lt;/h3&gt;
&lt;p&gt;Redis 集合最多容纳2^32 - 1 (4,294,967,295)个成员。&lt;/p&gt;
&lt;h3 id=&#34;基础命令-3&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SADD&lt;/strong&gt; 向集合添加新成员。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SREM&lt;/strong&gt; 从集合中删除指定成员。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SISMEMBER&lt;/strong&gt; 测试字符串是否是集合成员。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SINTER&lt;/strong&gt; 返回两个或多个集合的交集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SCARD&lt;/strong&gt; 返回集合的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-3&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;大多数集合操作，包括添加、删除和检查是否是集合成员，都是 O(1)。这意味着它们是非常高效的。然而，&lt;strong&gt;SMEMBERS&lt;/strong&gt; 是 O(n)，它返回整个集合。对于有几十万个成员或更大的大型集合，可以考虑使用&lt;strong&gt;SSCAN&lt;/strong&gt;，它可以迭代地检索一个集合的所有成员。&lt;/p&gt;
&lt;h2 id=&#34;hash-哈希&#34;&gt;Hash 哈希&lt;/h2&gt;
&lt;p&gt;哈希是键值对的集合构造的记录类型。可以使用哈希来表示对象和分组计算器。&lt;/p&gt;
&lt;h3 id=&#34;示例-4&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用哈希表示用户资料&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; HSET user:123 username martina firstName Martina lastName Elisa country GB
(integer) 4
&amp;gt; HGET user:123 username
&amp;quot;martina&amp;quot;
&amp;gt; HGETALL user:123
1) &amp;quot;username&amp;quot;
2) &amp;quot;martina&amp;quot;
3) &amp;quot;firstName&amp;quot;
4) &amp;quot;Martina&amp;quot;
5) &amp;quot;lastName&amp;quot;
6) &amp;quot;Elisa&amp;quot;
7) &amp;quot;country&amp;quot;
8) &amp;quot;GB&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;存储设备 777 ping 服务器、发出请求或发送错误的次数的计数器：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; HINCRBY device:777:stats pings 1
(integer) 1
&amp;gt; HINCRBY device:777:stats pings 1
(integer) 2
&amp;gt; HINCRBY device:777:stats pings 1
(integer) 3
&amp;gt; HINCRBY device:777:stats errors 1
(integer) 1
&amp;gt; HINCRBY device:777:stats requests 1
(integer) 1
&amp;gt; HGET device:777:stats pings
&amp;quot;3&amp;quot;
&amp;gt; HMGET device:777:stats requests errors
1) &amp;quot;1&amp;quot;
2) &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令-4&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HSET&lt;/strong&gt; 设置哈希上的一个或多个字段的值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HGET&lt;/strong&gt; 返回一个给定字段的值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HMGET&lt;/strong&gt; 返回一个或多个给定字段的值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HINCRBY&lt;/strong&gt; 增加给定字段的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-4&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;大多数Redis哈希命令是O(1)。少数命令，如 &lt;strong&gt;HKEYS&lt;/strong&gt;、&lt;strong&gt;HVALS&lt;/strong&gt; 和 &lt;strong&gt;HGETALL&lt;/strong&gt; 是O(n)，其中 n 是一个哈希中键值对的数量。&lt;/p&gt;
&lt;h3 id=&#34;限制-4&#34;&gt;限制&lt;/h3&gt;
&lt;p&gt;每个哈希最多可以存储4,294,967,295（2^32 - 1）个键值对。实践中，只受部署 Redis 机器的内存限制。&lt;/p&gt;
&lt;h2 id=&#34;sorted-set-有序集合&#34;&gt;Sorted Set 有序集合&lt;/h2&gt;
&lt;p&gt;Redis 有序集合是按分数排序的唯一字符串（成员）的集合。当一个以上的字符串具有相同的分数时，这些字符串将按词典排序。使用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;排行榜。例如，使用有序集合维护大型网络游戏中最高分的有序列表。&lt;/li&gt;
&lt;li&gt;限流器。使用排序集建立一个滑动窗口限流器，以防止过多的 API 请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;示例-5&#34;&gt;示例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;实时更新玩家的分数排行榜：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; ZADD leaderboard:455 100 user:1
(integer) 1
&amp;gt; ZADD leaderboard:455 75 user:2
(integer) 1
&amp;gt; ZADD leaderboard:455 101 user:3
(integer) 1
&amp;gt; ZADD leaderboard:455 15 user:4
(integer) 1
&amp;gt; ZADD leaderboard:455 275 user:2
(integer) 0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;获取前3名玩家的分数：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; ZRANGE leaderboard:455 0 2 REV WITHSCORES
1) &amp;quot;user:2&amp;quot;
2) &amp;quot;275&amp;quot;
3) &amp;quot;user:3&amp;quot;
4) &amp;quot;101&amp;quot;
5) &amp;quot;user:1&amp;quot;
6) &amp;quot;100&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;用户2的排名&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; ZREVRANK leaderboard:455 user:2
(integer) 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基础命令-5&#34;&gt;基础命令&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ZADD&lt;/strong&gt; 将新成员和分数添加到集合。如果该成员已经存在，那么更新分数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZRANGE&lt;/strong&gt; 返回有序集合指定区间内的成员。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZRANK&lt;/strong&gt; 返回成员的排名，（升序）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZREVRANK&lt;/strong&gt; 返回成员的排名（降序）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能-5&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;大多数有序集合的操作是 O(log(n))，其中 n 是成员的数量。在运行 &lt;strong&gt;ZRANGE&lt;/strong&gt; 命令时，返回集合非常大（例如，数以万计或更多）的情况下要谨慎一些，这个命令的时间复杂度是O(log(n) + m)，其中 m 是返回的结果数量。&lt;/p&gt;
">Redis (2) 数据类型（字符串/列表/集合/哈希/有序集合）</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/kEYDRAsfA/"" data-c="
          &lt;p&gt;从源码编译并安装 Redis，环境为 WSL2。&lt;/p&gt;
&lt;h2 id=&#34;下载源码&#34;&gt;下载源码&lt;/h2&gt;
&lt;p&gt;运行下面的命令下载 Redis 最新稳定版源码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://download.redis.io/redis-stable.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;编译&#34;&gt;编译&lt;/h2&gt;
&lt;p&gt;首先切换到下载 Redis 源码压缩文件目录解压源码，然后进入源码目录并执行 &lt;code&gt;make&lt;/code&gt; 命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tar -xzvf redis-stable.tar.gz
cd redis-stable
make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果编译成功，在 src 目录下会生成包括以下两个文件在内的 Redis 二进制文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redis-server：Redis 服务端&lt;/li&gt;
&lt;li&gt;redis-cli 与 redis 服务端交互的命令行工具&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果需要安装到 &lt;code&gt;/usr/local/bin&lt;/code&gt; 目录，执行以下命令即可：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;前台启动并停止-redis&#34;&gt;前台启动并停止 Redis&lt;/h2&gt;
&lt;p&gt;安装 Reids 后，执行以下命令即可启动 Redis：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果启动成功，将会看到启动日志，并且 Redis 在前台运行，输入 Ctrl-C 即可停止运行。&lt;/p&gt;
&lt;h2 id=&#34;redis-cli-与-redis-server-交互&#34;&gt;redis-cli 与 redis server 交互&lt;/h2&gt;
&lt;p&gt;执行以下命令即可与 redis 服务器连接&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-cli -h ip -p port
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;存储并检索&#34;&gt;存储并检索&lt;/h2&gt;
&lt;p&gt;执行以下命令向 redis 服务器存储数据并从 redis 服务器检索数据（&amp;gt; 是命令行提示符）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; SET user:1 salvatore
OK
&amp;gt; GET user:1
&amp;quot;salvatore&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
">Redis（1）编译安装</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/1a-hQkc8c/"" data-c="
          &lt;p&gt;在以下场景 &lt;code&gt;@Transaction&lt;/code&gt; 事务会失效：&lt;/p&gt;
&lt;h3 id=&#34;把注解标注在非-public-方法&#34;&gt;把注解标注在非 public 方法&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private TransactionAttribute computeTransactionAttribute(Method method, Class&amp;lt;?&amp;gt; targetClass) {
    // Don&#39;t allow no-public methods as required.
    if (allowPublicMethodsOnly() &amp;amp;&amp;amp; !Modifier.isPublic(method.getModifiers())){
        return null;
    }
        ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;propagation-传播行为配置不合理&#34;&gt;propagation 传播行为配置不合理&lt;/h3&gt;
&lt;p&gt;如果配置以下 3 种事务传播行为，事务将不会发生回滚：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;TransactionDefinition.PROPAGATION_SUPPORTS&lt;/code&gt;: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TransactionDefinition.PROPAGATION_NOT_SUPPORTED&lt;/code&gt;: 以非事务方式运行，如果当前存在事务，则把当前事务挂起。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TransactionDefinition.PROPAGATION_NEVER&lt;/code&gt;: 以非事务方式运行，如果当前存在事务，则抛出异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rollback-属性设置错误&#34;&gt;rollback 属性设置错误&lt;/h3&gt;
&lt;p&gt;默认情况下，事务只有遇到运行期异常（RuntimeException 的子类）时才会回滚，Error 也会导致事务回滚，但是，在遇到受查异常时不会回滚。&lt;/p&gt;
&lt;h3 id=&#34;在同一个类中方法调用导致事务失效&#34;&gt;在同一个类中方法调用，导致事务失效&lt;/h3&gt;
&lt;p&gt;若同一类中方法内部调用事务会失效。这是由于 Spring AOP 代理的原因造成的，内部内部调用只是普通方法调用，只有当 &lt;code&gt;@Transactional&lt;/code&gt; 注解的方法在类以外被调用的时候，才会由Spring 生成的代理对象管理。&lt;/p&gt;
&lt;h3 id=&#34;主动-catch-异常&#34;&gt;主动 catch 异常&lt;/h3&gt;
&lt;p&gt;主动 catch 异常，代表没有出现异常，事务会失效。&lt;/p&gt;
&lt;h3 id=&#34;数据库引擎不支持事务&#34;&gt;数据库引擎不支持事务&lt;/h3&gt;
&lt;p&gt;数据库引擎不支持事务，例如 MyISAM，当然不会生效。&lt;/p&gt;
">@Transaction 注解失效场景</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/5PnOhK37O/"" data-c="
          &lt;p&gt;自动配置是由 Spring 自动发现 &lt;code&gt;@Configuration&lt;/code&gt; 类，并添加到应用上下文。自动配置可能是有条件的，其激活取决于外部因素，例如具有特定值的某个配置参数。&lt;/p&gt;
&lt;h2 id=&#34;springboot-如何实现自动装配&#34;&gt;SpringBoot 如何实现自动装配&lt;/h2&gt;
&lt;p&gt;Spring Boot 应用启动入口通常如下面代码所示：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpringBootApplication
public class DemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt; 是 Spring Boot 的核心注解，其代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(
    excludeFilters = {@Filter(
    type = FilterType.CUSTOM,
    classes = {TypeExcludeFilter.class}
), @Filter(
    type = FilterType.CUSTOM,
    classes = {AutoConfigurationExcludeFilter.class}
)}
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以把 &lt;code&gt;@SpringBootApplication&lt;/code&gt;  看作 &lt;code&gt;@Configuration&lt;/code&gt;、&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;、&lt;code&gt;@ComponentScan&lt;/code&gt; 注解的集合，作用分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@Configuration&lt;/code&gt;：允许在上下文中注册额外的 bean 或导入其他配置类。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;：启用 Spring Boot 的自动配置机制。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;：扫描被 &lt;code&gt;@Component&lt;/code&gt; ( &lt;code&gt;@Service&lt;/code&gt;, &lt;code&gt;@Controller&lt;/code&gt;)注解的 bean。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;enableautoconfiguration-实现自动装配的核心注解&#34;&gt;&lt;code&gt;@EnableAutoConfiguration&lt;/code&gt;: 实现自动装配的核心注解&lt;/h3&gt;
&lt;p&gt;&lt;code&gt; @EnableAutoConfiguration&lt;/code&gt; 注解的代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import({AutoConfigurationImportSelector.class})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;自动装配核心功能的实现实际是通过 &lt;code&gt;AutoConfigurationImportSelector&lt;/code&gt; 类。&lt;/p&gt;
&lt;h3 id=&#34;autoconfigurationimportselector加载自动装配类&#34;&gt;AutoConfigurationImportSelector:加载自动装配类&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {
}
public interface DeferredImportSelector extends ImportSelector {
}
public interface ImportSelector {
    String[] selectImports(AnnotationMetadata var1);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;AutoConfigurationImportSelector&lt;/code&gt; 类实现了 &lt;code&gt;ImportSelector&lt;/code&gt; 接口，&lt;code&gt;selectImports&lt;/code&gt; 方法主要用于获取所有符合条件的类加载到 IoC 容器中。&lt;code&gt;selectImports&lt;/code&gt; 方法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public String[] selectImports(AnnotationMetadata annotationMetadata) {
    // 自动装配是否打开
    if (!this.isEnabled(annotationMetadata)) {
            return NO_IMPORTS;
    } else {
        // 获取所有需要装配的 bean
        AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(annotationMetadata);
            return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;getAutoConfigurationEntry()&lt;/code&gt; 方法主要负责加载自动配置类，详细代码如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) {
    // 自动装配是否打开
     if (!this.isEnabled(annotationMetadata)) {
         return EMPTY_ENTRY;
    } else {
        // 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName
        AnnotationAttributes attributes = this.getAttributes(annotationMetadata);
        // 获取需要自动装配的所有配置类
         List&amp;lt;String&amp;gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes);
         // 移除不满足条件的类
        configurations = this.removeDuplicates(configurations);
        Set&amp;lt;String&amp;gt; exclusions = this.getExclusions(annotationMetadata, attributes);
        this.checkExcludedClasses(configurations, exclusions);
        configurations.removeAll(exclusions);
        configurations = this.getConfigurationClassFilter().filter(configurations);
        this.fireAutoConfigurationImportEvents(configurations, exclusions);
            return new AutoConfigurationEntry(configurations, exclusions);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;判断自动装配是否打开。默认 &lt;code&gt;spring.boot.enableautoconfiguration=true&lt;/code&gt;，可在 &lt;code&gt;application.properties&lt;/code&gt; 或 &lt;code&gt;application.yml&lt;/code&gt; 中配置。&lt;/li&gt;
&lt;li&gt;用于获取 &lt;code&gt;EnableAutoConfiguration&lt;/code&gt; 注解中的 &lt;code&gt;exclude&lt;/code&gt; 和 &lt;code&gt;excludeName&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;读取 &lt;code&gt;META-INF/spring.factories&lt;/code&gt;，获取需要自动装配的所有配置类。&lt;/li&gt;
&lt;li&gt;移除不满足条件的类&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如， spring-boot-autoconfigure 项目中的  文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\
org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据此文件，Spring Boot 将尝试运行 RabbitMQ、Cassandra、MongoDB 和 Hibernate 的所有配置类。这些类是否装配将取决于类路径是否存在类，例如 &lt;code&gt;MongoAutoConfiguration&lt;/code&gt;：。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Configuration
@ConditionalOnClass(MongoClient.class)
@EnableConfigurationProperties(MongoProperties.class)
@ConditionalOnMissingBean(type = &amp;quot;org.springframework.data.mongodb.MongoDbFactory&amp;quot;)
public class MongoAutoConfiguration {
    // configuration code
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spring Boot 提供了一些条件注解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnBean&lt;/code&gt;：当容器里有指定 Bean 的条件下&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnMissingBean&lt;/code&gt;：当容器里没有指定 Bean 的情况下。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnSingleCandidate&lt;/code&gt;：当指定 Bean 在容器中只有一个，或者虽然有多个但是指定首选 Bean。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnClass&lt;/code&gt;：当类路径下有指定类的条件下。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnMissingClass&lt;/code&gt;：当类路径下没有指定类的条件下。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnProperty&lt;/code&gt;：指定的属性是否有指定的值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnResource&lt;/code&gt;：类路径是否有指定的值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnExpression&lt;/code&gt;：基于 SpEL 表达式作为判断条件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnJava&lt;/code&gt;：基于 Java 版本作为判断条件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnJndi&lt;/code&gt;：在 JNDI 存在的条件下差在指定的位置。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnNotWebApplication&lt;/code&gt;：当前项目不是 Web 项目的条件下。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ConditionalOnWebApplication&lt;/code&gt;：当前项目是 Web 项 目的条件下&lt;/li&gt;
&lt;/ul&gt;
">Spring Boot 自动配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/iDQygBprt/"" data-c="
          &lt;p&gt;很多开源框架也使用了插件扩展方式，例如，Dubbo 通过 SPI 方式实现了插件化的效果。MyBatis 也提供了类似的插件扩展机制。&lt;/p&gt;
&lt;p&gt;MyBatis 允许自定义 Interceptor 拦截 SQL 语句执行过程中的某些关键逻辑，允许拦截的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executor 类中的 update()、query()、flushStatements()、commit()、rollback()、getTransaction()、close()、isClosed()方法。&lt;/li&gt;
&lt;li&gt;ParameterHandler 中的 setParameters()、getParameterObject() 方法。&lt;/li&gt;
&lt;li&gt;ResultSetHandler中的 handleOutputParameters()、handleResultSets()方法。&lt;/li&gt;
&lt;li&gt;StatementHandler 中的parameterize()、prepare()、batch()、update()、query()方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;编写插件的步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实现 &lt;code&gt;Interceptor&lt;/code&gt; 接口。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;@Intercepts&lt;/code&gt; 注解完成插件签名。&lt;/li&gt;
&lt;li&gt;在配置文件中注册插件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;@Intercepts&lt;/code&gt; 注解中可以配置多个 &lt;code&gt;@Signature&lt;/code&gt; 注解，&lt;code&gt;@Signature&lt;/code&gt; 注解用来指定插件实现类要拦截的目标方法信息，其中的 &lt;code&gt;type&lt;/code&gt; 属性指定了要拦截的类，&lt;code&gt;method&lt;/code&gt; 属性指定了要拦截的目标方法名称，&lt;code&gt;args&lt;/code&gt; 属性指定了要拦截的目标方法的参数列表。通过 &lt;code&gt;@Signature&lt;/code&gt; 注解中的这三个配置，就可以确定要拦截的目标方法的方法签名。&lt;/p&gt;
&lt;p&gt;下面以实现审计功能插件为例。&lt;/p&gt;
&lt;p&gt;定义几个注解，来表明一个字段是需要审计的，它们是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@CreateTime&lt;/code&gt;：创建时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@UpdateTime&lt;/code&gt;：最后更新时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@CreateBy&lt;/code&gt;：创建人信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@UpdateBy&lt;/code&gt;：最后更新人信息&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Slf4j
@Intercepts({
        @Signature(type = Executor.class, method = &amp;quot;update&amp;quot;, args = {MappedStatement.class, Object.class}),
        @Signature(type = StatementHandler.class, method = &amp;quot;prepare&amp;quot;, args = {Connection.class, Integer.class})
})
public class AuditingInterceptor implements Interceptor {
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        Object target = invocation.getTarget();
        if (target instanceof Executor) {
            Object[] args = invocation.getArgs();
            MappedStatement mappedStatement = (MappedStatement) args[0];
            Object parameter = args[1];
            setAuditValue(parameter, mappedStatement.getSqlCommandType());
        }
        if (target instanceof StatementHandler) {
            StatementHandler statementHandler = (StatementHandler) invocation.getTarget();
            replaceSQL(statementHandler);
        }

        Object result = invocation.proceed();
        AuditFiledContext.clear();
        return result;
    }

    @Override
    public Object plugin(Object target) {
        return Plugin.wrap(target, this);
    }

    private void setAuditValue(Object parameter, SqlCommandType sqlCommandType) throws IllegalAccessException {
        Class&amp;lt;?&amp;gt; aClass = parameter.getClass();
        List&amp;lt;Field&amp;gt; declaredFields = new ArrayList&amp;lt;&amp;gt;();
        declaredFields.addAll(List.of(aClass.getDeclaredFields()));
        declaredFields.addAll(List.of(aClass.getSuperclass().getDeclaredFields()));

        for (Field field : declaredFields) {
            if (SqlCommandType.INSERT.equals(sqlCommandType)) { // insert 语句插入 createBy
                if (field.getAnnotation(CreateBy.class) != null) {
                    field.setAccessible(true);
                    field.set(parameter, AuditFiledContext.getUserName());
                    String column = field.getAnnotation(CreateBy.class).column();
                    AuditFiledContext.set(AuditFiledContext.CREATE_BY_COLUMN, column);
                    AuditFiledContext.set(AuditFiledContext.CREATE_BY_PROPERTY, field.getName());
                }

                if (field.getAnnotation(CreateTime.class) != null) { // insert 语句插入 createTime
                    field.setAccessible(true);
                    field.set(parameter, new Date());
                    String column = field.getAnnotation(CreateTime.class).column();
                    AuditFiledContext.set(AuditFiledContext.CREATE_TIME_COLUMN, column);
                    AuditFiledContext.set(AuditFiledContext.CREATE_TIME_PROPERTY, field.getName());
                }
            } else if (SqlCommandType.UPDATE.equals(sqlCommandType)) {
                if (field.getAnnotation(UpdateBy.class) != null) { // update 语句插入 updateBy
                    field.setAccessible(true);
                    field.set(parameter, AuditFiledContext.getUserName());
                    String column = field.getAnnotation(UpdateBy.class).column();
                    AuditFiledContext.set(AuditFiledContext.UPDATE_BY_COLUMN, column);
                    AuditFiledContext.set(AuditFiledContext.UPDATE_BY_PROPERTY, field.getName());
                }
                if (field.getAnnotation(UpdateTime.class) != null) { // update 语句插入 updateTime
                    field.setAccessible(true);
                    field.set(parameter, new Date());
                    String column = field.getAnnotation(UpdateTime.class).column();
                    AuditFiledContext.set(AuditFiledContext.UPDATE_TIME_COLUMN, column);
                    AuditFiledContext.set(AuditFiledContext.UPDATE_TIME_PROPERTY, field.getName());
                }
            }
        }
    }

    private void replaceSQL(StatementHandler statementHandler) throws NoSuchFieldException, IllegalAccessException {
        MetaObject metaObject = MetaObject.forObject(
                statementHandler,
                SystemMetaObject.DEFAULT_OBJECT_FACTORY,
                SystemMetaObject.DEFAULT_OBJECT_WRAPPER_FACTORY,
                new DefaultReflectorFactory()
        );
        // 获取成员变量 mappedStatement
        MappedStatement mappedStatement = (MappedStatement) metaObject.getValue(&amp;quot;delegate.mappedStatement&amp;quot;);
        BoundSql boundSql = statementHandler.getBoundSql();
        String originSQL = boundSql.getSql();
        Field field = boundSql.getClass().getDeclaredField(&amp;quot;sql&amp;quot;);
        String newSql = generateNewSql(mappedStatement.getSqlCommandType(), originSQL);
        field.setAccessible(true);
        field.set(boundSql, newSql);
        addParameterMapping(mappedStatement, boundSql);
    }

    private String generateNewSql(SqlCommandType sqlCommandType, String originalSQL) {
        String newSql = &amp;quot;&amp;quot;;
        if (SqlCommandType.UPDATE.equals(sqlCommandType)) {
            int i = originalSQL.indexOf(&amp;quot; set &amp;quot;);
            newSql = originalSQL.substring(0, i + 4) + &amp;quot; &amp;quot; + AuditFiledContext.get(AuditFiledContext.UPDATE_BY_COLUMN) + &amp;quot;=?, &amp;quot;
                    + AuditFiledContext.get(AuditFiledContext.UPDATE_TIME_COLUMN) + &amp;quot;=?, &amp;quot; + originalSQL.substring(i + 5);
        } else if (SqlCommandType.INSERT.equals(sqlCommandType)) {
            int i = originalSQL.indexOf(&amp;quot;(&amp;quot;);
            String addInsertFiled = originalSQL.substring(0, i + 1) + AuditFiledContext.get(AuditFiledContext.CREATE_BY_COLUMN) + &amp;quot;, &amp;quot;
                    + AuditFiledContext.get(AuditFiledContext.CREATE_TIME_COLUMN) + &amp;quot;, &amp;quot; + originalSQL.substring(i + 1);
            int i1 = addInsertFiled.indexOf(&amp;quot;values(&amp;quot;);
            newSql = addInsertFiled.substring(0, i1 + 7) + &amp;quot;?, ?, &amp;quot; + addInsertFiled.substring(i1 + 7);
        }
        return newSql;
    }

    private void addParameterMapping(MappedStatement mappedStatement, BoundSql boundSql) {
        List&amp;lt;ParameterMapping&amp;gt; parameterMappings = boundSql.getParameterMappings();
        if (mappedStatement.getSqlCommandType().equals(SqlCommandType.UPDATE)) {
            parameterMappings.add(0, new ParameterMapping.Builder(mappedStatement.getConfiguration(), AuditFiledContext.get(AuditFiledContext.UPDATE_TIME_PROPERTY), Date.class).build());
            parameterMappings.add(0, new ParameterMapping.Builder(mappedStatement.getConfiguration(), AuditFiledContext.get(AuditFiledContext.UPDATE_BY_PROPERTY), String.class).build());
        } else if (mappedStatement.getSqlCommandType().equals(SqlCommandType.INSERT)) {
            parameterMappings.add(0, new ParameterMapping.Builder(mappedStatement.getConfiguration(), AuditFiledContext.get(AuditFiledContext.CREATE_TIME_PROPERTY), Date.class).build());
            parameterMappings.add(0, new ParameterMapping.Builder(mappedStatement.getConfiguration(), AuditFiledContext.get(AuditFiledContext.CREATE_BY_PROPERTY), String.class).build());
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码及测试请查看&lt;a href=&#34;https://github.com/flipped94/mybatis-interceptor-audit&#34;&gt;仓库&lt;/a&gt;&lt;/p&gt;
">MyBatis 插件</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/H34OOTkit/"" data-c="
          &lt;p&gt;在普通的主从复制方案下（如在 Spring Boot 集成 Reids 主从中所描述的那样），一旦 主节点宕机，需要手动恢复主节点或选择从节点成为新的主节点（需要修改应用的主节点地址），这个过程需要人工干预。可以借助 Redis Sentinel（哨兵）实现自动故障切换，解决这个痛点。&lt;/p&gt;
&lt;h1 id=&#34;什么是-redis-sentinel&#34;&gt;什么是 Redis Sentinel&lt;/h1&gt;
&lt;p&gt;Sentinel 是 Redis 的一种运行模式，依赖于 Redis 工作，本身不提供读写服务，通过如下命令就可以让 Redis 以 Sentinel 方式运行：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;redis-sentinel /path/to/sentinel.conf
或者
redis-server /path/to/sentinel.conf --sentinel
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;部署单机模拟&#34;&gt;部署【单机模拟】&lt;/h1&gt;
&lt;p&gt;下面以 3 个 Sentinel 节点，1 个主节点，2 个从节点组成一个 Redis Sentinel 为例进行部署&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;节点&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ip&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;port&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;M&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6379&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6380&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6381&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;S1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;26379&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;S2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;26380&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;S2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;127.0.0.1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;26381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;     +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+
Configuration: quorum = 2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;M1 表示主节点，R1 和 R2 表示从节点&lt;/li&gt;
&lt;li&gt;S1，S2，S3 表示哨兵节点&lt;/li&gt;
&lt;li&gt;quorum 表示判定主节点失效最少需要的仲裁节点数。这里的值为 2 ，即当有 2 个 sentinel 认为主节点失效时，才算真正失效。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;运行节点&#34;&gt;运行节点&lt;/h2&gt;
&lt;p&gt;节点配置及代码可在 &lt;a href=&#34;https://github.com/flipped94/redis-sentinel-demo&#34;&gt;仓库&lt;/a&gt; 找到。主节点配置是 Redis 默认配置，从节点配置主要修改 replicaof，port, pidfile 相关配置。哨兵节点主要修改默认配置的 port 和 pidfile 配置。&lt;br&gt;
运行以下命令即可：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 启动主节点及哨兵
redis-server redis-m.conf
redis-sentinel sentinel-m-s1.conf

# 启动从节点 R1 及哨兵
redis-server redis-r1.conf
redis-sentinel sentinel-r1-s2.conf

# 启动从节点 R2 及哨兵
redis-server redis-r2.conf
redis-sentinel sentinel-r2-s3.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;spring-boot-使用-redis-主从&#34;&gt;Spring Boot 使用 Redis 主从&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;创建 Spring Boot 应用使用 Redis 主从，添加以下依赖，第二个依赖是为了从浏览器或Postman 验证。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
     &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
	&amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;配置节点 application.yml&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;spring:
  redis:
    database: 0
    sentinel:
      master: mymaster
      nodes:
        - 127.0.0.1:26379
        - 127.0.0.1:26380
        - 127.0.0.1:26381
    lettuce:
      shutdown-timeout: 200ms
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;配置 Bean&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Configuration
public class RedisConfig {

    @Resource
    private RedisProperties redisProperties;

    @Bean
    public LettuceConnectionFactory lettuceConnectionFactory() {
        final RedisSentinelConfiguration sentinelConfiguration = new RedisSentinelConfiguration()
                .master(redisProperties.getSentinel().getMaster());
        final LettuceClientConfiguration lettuceClientConfiguration = LettuceClientConfiguration.builder()
                .readFrom(ReadFrom.ANY_REPLICA)
                .build();

        redisProperties.getSentinel().getNodes().forEach(node -&amp;gt; {
            final String[] sentinelNodes = node.split(&amp;quot;:&amp;quot;);
            final String host = sentinelNodes[0];
            final int port = Integer.parseInt(sentinelNodes[1]);
            sentinelConfiguration.sentinel(host, port);
        });

        LettuceConnectionFactory connectionFactory = new LettuceConnectionFactory(sentinelConfiguration, lettuceClientConfiguration);
        connectionFactory.setDatabase(redisProperties.getDatabase());
        return connectionFactory;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Controller&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RestController
public class RedisController {

    private static final String KEY = &amp;quot;REDIS_SENTINEL&amp;quot;;

    @Autowired
    private StringRedisTemplate template;

    @GetMapping(&amp;quot;/{value}&amp;quot;)
    public void addToSet(@PathVariable String value) {
        this.template.opsForSet().add(KEY, value);
    }

    @GetMapping(&amp;quot;/get&amp;quot;)
    public Set&amp;lt;String&amp;gt; getKeyValues() {
        return this.template.opsForSet().members(KEY);
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;从浏览器发送如下三个写请求&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:8080/write4
http://localhost:8080/write5
http://localhost:8080/write6
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;从浏览器发送读请求&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:8080/get

读请求响应
[
    &amp;quot;write4&amp;quot;,
    &amp;quot;write5&amp;quot;,
    &amp;quot;write6&amp;quot;
]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;停止主节点&lt;br&gt;
停止主节点后，将会自动切换主节点，期间不能写，但是可以读，切换后将继续可写。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# 切换主节点
MASTER MODE enabled (user request from &#39;id=6 addr=127.0.0.1:59774 laddr=127.0.0.1:6380 fd=11 name=sentinel-942a512e-cmd age=762 idle=0 flags=x db=0 sub=0 psub=0 ssub=0 multi=4 qbuf=188 qbuf-free=20286 argv-mem=4 multi-mem=169 rbs=2048 rbp=1024 obl=45 oll=0 omem=0 tot-mem=23717 events=r cmd=exec user=default redir=-1 resp=2 lib-name= lib-ver=&#39;)
&lt;/code&gt;&lt;/pre&gt;
">Spring Boot 集成 Redis Sentinel</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/WaSvElZr4/"" data-c="
          &lt;p&gt;单机 Redis 存在单点风险问题，最简单的处理方法就是主从复制，本文使用 Spring Boot 演示 Redis 主从复制（一主两从），结构如下所示。&lt;br&gt;
&lt;img src=&#34;https://github.com/flipped94/redis-master-slave-demo/blob/main/image/redis-master-slave.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;运行-redis-主从&#34;&gt;运行 Redis 主从&lt;/h1&gt;
&lt;p&gt;运行 Redis 主从节点的配置及代码可在 &lt;a href=&#34;https://github.com/flipped94/redis-master-slave-demo&#34;&gt;仓库&lt;/a&gt; 找到。主要修改从节点 replicaof，port, pidfile 相关配置，master 节点配置是 Redis 默认配置。&lt;/p&gt;
&lt;h1 id=&#34;spring-boot-使用-redis-主从&#34;&gt;Spring Boot 使用 Redis 主从&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;创建 Spring Boot 应用使用 Redis 主从，添加以下依赖，第二个依赖是为了从浏览器或Postman 验证。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
     &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
	&amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;配置节点 application.yml&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;redis:
  master:
    host: 127.0.0.1
    port: 6379
  slaves:
    - host: 127.0.0.1
      port: 6380
    - host: 127.0.0.1
      port: 6381
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;配置 Bean&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Data
public class RedisInstance {

    private String host;

    private int port;
}

@Configuration
@ConfigurationProperties(prefix = &amp;quot;redis&amp;quot;)
@Data
public class RedisConfiguration {

    private RedisInstance master;

    private List&amp;lt;RedisInstance&amp;gt; slaves;

    @Bean
    public LettuceConnectionFactory redisConnectionFactory() {
        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()
                .readFrom(ReadFrom.REPLICA_PREFERRED)
                .build();
        RedisStaticMasterReplicaConfiguration staticMasterReplicaConfiguration =
                new RedisStaticMasterReplicaConfiguration(this.getMaster().getHost(), this.getMaster().getPort());
        this.getSlaves().forEach(slave -&amp;gt; staticMasterReplicaConfiguration.addNode(slave.getHost(), slave.getPort()));
        return new LettuceConnectionFactory(staticMasterReplicaConfiguration, clientConfig);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Controller&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@RestController
public class RedisController {

    private static final String KEY = &amp;quot;REDIS_SENTINEL&amp;quot;;

    @Autowired
    private StringRedisTemplate template;

    @GetMapping(&amp;quot;/{value}&amp;quot;)
    public void addToSet(@PathVariable String value) {
        this.template.opsForSet().add(KEY, value);
    }

    @GetMapping(&amp;quot;/get&amp;quot;)
    public Set&amp;lt;String&amp;gt; getKeyValues() {
        return this.template.opsForSet().members(KEY);
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;从浏览器发送如下三个写请求&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:8080/write1
http://localhost:8080/write2
http://localhost:8080/write3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;从浏览器发送读请求&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:8080/get

读请求响应
[
    &amp;quot;write1&amp;quot;,
    &amp;quot;write2&amp;quot;,
    &amp;quot;write3&amp;quot;
]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;停止主节点&lt;br&gt;
停止主节点后，应用将无法连接主节点，尝试添加新项，请求会被 hang 住，但是可以正常读取。重新启动主节点后，写将恢复。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;[xecutorLoop-1-3] i.l.core.protocol.ConnectionWatchdog     : Reconnecting, last destination was /127.0.0.1:6379
[oEventLoop-6-10] i.l.core.protocol.ConnectionWatchdog     : Cannot reconnect to [127.0.0.1:6379]: Connection closed prematurely
&lt;/code&gt;&lt;/pre&gt;
">Spring Boot 集成 Redis 主从复制</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/UqOG-r8J9/"" data-c="
          &lt;p&gt;本文主要关于 Kafka Producer 设计和 Producer API。&lt;/p&gt;
&lt;h2 id=&#34;producer-设计&#34;&gt;Producer 设计&lt;/h2&gt;
&lt;h3 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h3&gt;
&lt;p&gt;Producer 直接将数据发送给作为分区领导者的代理，而不需要任何介入的路由层。为了帮助 Producer 做到这一点，所有的 Kafka 节点可以在任何时间，响应关于哪些服务器处于活动状态以及主题的分区的领导者在哪里的元数据请求，以便 Producer 适当地发送请求。&lt;/p&gt;
&lt;p&gt;客户端控制将消息发布到哪个分区，这可以是随机完成的（随机负载均衡），也可以通过某些语义分区函数完成。Kafka 提供语义分区的接口，允许用户指定要分区的键，并使用该键对分区进行散列(如果需要，还可以覆盖分区函数)。&lt;/p&gt;
&lt;h3 id=&#34;异步发送&#34;&gt;异步发送&lt;/h3&gt;
&lt;p&gt;批处理是效率的主要驱动之一，为了实现批处理，Producer 在内存中积累数据，并在单个请求批量中发送。可以将批处理配置为累积不超过固定数量的消息，等待时间不超过某个固定延迟范围(比如64k或10毫秒)。这样就可以累积更多的字节来发送，并减少服务器的 I/O 操作。这个缓冲区是可配置的，它提供了一种机制，可以用少量额外的延迟来换取更好的吞吐量。&lt;/p&gt;
&lt;h2 id=&#34;producer-api&#34;&gt;Producer API&lt;/h2&gt;
&lt;p&gt;Producer API 允许应用程序向Kafka集群中的主题发送数据流。需要以下 Maven 依赖：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.kafka&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;kafka-clients&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.7.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kafka 客户端，将记录发布到 Kafka 集群。 Producer 是线程安全的，并且跨线程共享单个 Producer 实例通常比拥有多个实例要快。&lt;br&gt;
下面是一个简单的示例，发送连续数字的字符串作为键/值对的记录。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void producerSend() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;quot;localhost:9092&amp;quot;);
        props.put(ProducerConfig.ACKS_CONFIG, &amp;quot;all&amp;quot;);
        props.put(ProducerConfig.RETRIES_CONFIG, &amp;quot;0&amp;quot;);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, &amp;quot;16384&amp;quot;);
        props.put(ProducerConfig.LINGER_MS_CONFIG, &amp;quot;1&amp;quot;);
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, &amp;quot;33554432&amp;quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        // Producer的主对象
        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);

        for (int i = 0; i &amp;lt; 100; i++) {
            // ProducerRecord：消息对象
            producer.send(new ProducerRecord&amp;lt;String, String&amp;gt;(&amp;quot;test-topic&amp;quot;, &amp;quot;key-&amp;quot; + i, &amp;quot;value-&amp;quot; + i));
        }
        // 所有的通道打开都需要关闭
        producer.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Producer 由一个缓冲区和一个后台 I/O 线程组成，前者保存尚未传输到服务器的记录，后者负责将这些记录转换为请求并传输到集群。如果在使用之后没有关闭 Producer，这些资源就会泄漏。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;send()&lt;/code&gt; 方法是异步的。调用时，它将记录添加到等待记录发送的缓冲区中并立即返回。这允许 Producer 批量处理记录以提高效率。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;acks&lt;/code&gt; 配置控制请求完成的条件。设置为 &lt;code&gt;all&lt;/code&gt; 时将导致阻塞在提交记录，这是最慢但最持久的设置。&lt;/p&gt;
&lt;p&gt;如果请求失败，Producer 可以自动重试，但由于将 &lt;code&gt;retries&lt;/code&gt; 指定为0，所以它不会重试。启用重试还增加了重复的可能性。&lt;/p&gt;
&lt;p&gt;Producer 为每个分区维护未发送记录的缓冲区。这些缓冲区的大小由 &lt;code&gt;batch.size&lt;/code&gt; 配置指定。增大这个值可能会导致更多的批处理，但需要更多的内存(因为通常为每个活动分区设置一个这样的缓冲区)。&lt;/p&gt;
&lt;p&gt;默认情况下，即使缓冲区中有额外的未使用空间，也可以立即发送缓冲区。如果想减少请求的数量，可以设置 &lt;code&gt;linger.ms&lt;/code&gt; 的值大于0，表示 Producer 在发送请求之前等待的毫秒数，希望有更多的记录填充缓冲区。例如，上面的代码片段中，因为将 &lt;code&gt;linger.ms&lt;/code&gt; 设置为1毫秒，所以可能所有100条记录都将在一个请求中发送，。但是，如果没有填满缓冲区，这个设置会给请求增加1毫秒的延迟。到达缓冲区时间接近的记录通常会在一个批处理，即使 &lt;code&gt;linger.ms&lt;/code&gt; 的值为0，因此，在大负载下，会忽视 &lt;code&gt;linger.ms&lt;/code&gt; 配置；将此配置设置为大于0的值可以在不处于最大负载下时导致更少、更有效的请求，代价是少量的延迟。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;buffer.memory&lt;/code&gt; 控制 Producer 可用来缓冲的内存总量。如果记录的发送速度比它们传输到服务器的速度快，那么这个缓冲区空间将被耗尽。当缓冲区空间耗尽时，将阻塞其他的 &lt;code&gt;send&lt;/code&gt; 调用。阻塞时间的阈值由 &lt;code&gt;max.block.ms&lt;/code&gt; 决定，如果超市会抛出 &lt;code&gt;TimeoutException&lt;/code&gt; 异常。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;key.serializer&lt;/code&gt; 和 &lt;code&gt;value.serializer&lt;/code&gt; 表示如何将 &lt;code&gt;ProducerRecord&lt;/code&gt; 提供的键和值对象转换为字节。对于简单的字符串或字节类型，可以使用内置的 &lt;code&gt;ByteArraySerializer&lt;/code&gt; 或 &lt;code&gt;StringSerializer&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;从Kafka 0.11开始，KafkaProducer 支持另外两种模式：幂等 Producer 和 事务 Producer。幂等 Producer 增强了 Kafka 的交付语义，从至少一次交付（at least once）到精确一次交付（exactly once）。特别是 Producer 重试将不再引入重复。事务 Producer 允许应用程序自动地将消息发送到多个分区(和主题!)。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;enable.idempotence&lt;/code&gt; 设置为 &lt;code&gt;true&lt;/code&gt; 开启等幂。开启后，&lt;code&gt;retries &lt;/code&gt; 配置将默认为&lt;code&gt;Integer.MAX_VALUE&lt;/code&gt; ，&lt;code&gt;acks&lt;/code&gt; 配置将默认为 &lt;code&gt;all&lt;/code&gt;。幂等 Producer 不需要修改API，因此不需要修改现有的应用程序来利用这个特性。&lt;/p&gt;
&lt;p&gt;为了利用幂等 Producer，必须避免应用程序级的重发，因为这些不能重复。因此，如果应用程序启用幂等性，建议不设置重试配置，因为它将默认为 &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt;。此外，如果 &lt;code&gt;send(ProducerRecord)&lt;/code&gt; 在无限重试的情况下返回一个错误(例如，消息在发送之前在缓冲区中过期)，那么建议关闭 Producer 并检查最后生成的消息的内容，确保它没有重复。最后，Producer 只能保证在单个会话中发送的消息的幂等性。&lt;/p&gt;
&lt;p&gt;要使用事务 Producer，必须设置 &lt;code&gt;transactional.id&lt;/code&gt;。设置后，幂等性就会自动与幂等性所依赖的 Producer 配置一起启用。此外，事务中包含的主题应该配置持久性。特别是 &lt;code&gt;replication.factor&lt;/code&gt; 应该至少为3，这些主题的 &lt;code&gt;min.insync.replicas&lt;/code&gt; 应该设置为2。最后，为了从端到端实现事务保证，Consumer 也必须被配置为只读取已提交的消息。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;transactional.id&lt;/code&gt; 的目的是在单个 Producer 实例的多个会话之间启用事务恢复。它通常是从分区的、有状态的应用程序中的shard标识符派生的。因此，对于在分区应用程序中运行的每个生产者实例，它应该是唯一的。&lt;/p&gt;
&lt;p&gt;所有新的事务 api 都是阻塞的，并在失败时抛出异常。下面的示例说明了如何使用新api。它与上面的示例类似，只是所有100条消息都是一个事务的一部分。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Properties props = new Properties();
 props.put(&amp;quot;bootstrap.servers&amp;quot;, &amp;quot;localhost:9092&amp;quot;);
 props.put(&amp;quot;transactional.id&amp;quot;, &amp;quot;my-transactional-id&amp;quot;);
 Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props, new StringSerializer(), new StringSerializer());

 producer.initTransactions();

 try {
     producer.beginTransaction();
     for (int i = 0; i &amp;lt; 100; i++)
         producer.send(new ProducerRecord&amp;lt;&amp;gt;(&amp;quot;my-topic&amp;quot;, Integer.toString(i), Integer.toString(i)));
     producer.commitTransaction();
 } catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
     // We can&#39;t recover from these exceptions, so our only option is to close the producer and exit.
     producer.close();
 } catch (KafkaException e) {
     // For all other exceptions, just abort the transaction and try again.
     producer.abortTransaction();
 }
 producer.close();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正如示例中所示，每个 Producer 只能有一个打开的事务。在 &lt;code&gt;beginTransaction()&lt;/code&gt; 和 &lt;code&gt; commitTransaction()&lt;/code&gt; 调用之间发送的所有消息都将是单个事务的一部分。设置了 &lt;code&gt;transactional.id&lt;/code&gt; 时，Producer 发送的所有消息必须是事务的一部分。&lt;/p&gt;
&lt;p&gt;事务 Producer 使用异常传达错误状态。特别是，不需要为 &lt;code&gt;producer.send()&lt;/code&gt; 设置回调或 在返回的 &lt;code&gt;Future&lt;/code&gt; 上调用 &lt;code&gt;.get()&lt;/code&gt;：如果任何 &lt;code&gt;producer.send()&lt;/code&gt; 或事务调用在事务期间出现不可恢复的错误，将引发 KafkaException。&lt;/p&gt;
&lt;p&gt;通过在收到 KafkaException 时调用 &lt;code&gt;producer.send()&lt;/code&gt;，可以确保任何成功的写入都标记为已中止，从而保留事务性保证。&lt;/p&gt;
&lt;p&gt;此客户端可以与版本 0.10.0 或更高版本的代理进行通信。较旧或较新的代理可能不支持某些客户端功能。例如，事务 API 需要代理版本 0.11.0 或更新版本。调用正在运行的代理版本中不可用的 API 时，将收到不受支持的返回异常。&lt;br&gt;
除了第一个示例中的异步发送模式外，还有同步发送（异步阻塞）和异步回调两种模式。&lt;br&gt;
&lt;strong&gt;同步发送（异步阻塞）&lt;/strong&gt;&lt;br&gt;
同步发送与异步发送的区别在于发送后的操作，由于每次发送后都调用了 &lt;code&gt;Future#get&lt;/code&gt;，相当于阻塞在该处，代码如下所示。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
     * 同步发送（异步阻塞）
     * 
     * @throws ExecutionException
     * @throws InterruptedException
*/
public static void producerSyncSend() throws InterruptedException, ExecutionException {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;quot;localhost:9092&amp;quot;);
        props.put(ProducerConfig.ACKS_CONFIG, &amp;quot;all&amp;quot;);
        props.put(ProducerConfig.RETRIES_CONFIG, &amp;quot;0&amp;quot;);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, &amp;quot;16384&amp;quot;);
        props.put(ProducerConfig.LINGER_MS_CONFIG, &amp;quot;1&amp;quot;);
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, &amp;quot;33554432&amp;quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        // Producer的主对象
        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);

        for (int i = 0; i &amp;lt; 100; i++) {
            // ProducerRecord：消息对象
            Future&amp;lt;RecordMetadata&amp;gt; future = producer
                    .send(new ProducerRecord&amp;lt;String, String&amp;gt;(&amp;quot;test-topic&amp;quot;, &amp;quot;key-&amp;quot; + i, &amp;quot;value-&amp;quot; + i));
            RecordMetadata recordMetadata = future.get();
            System.out.println(&amp;quot;partition : &amp;quot; + recordMetadata.partition() + &amp;quot;, offset : &amp;quot; + recordMetadata.offset());
        }
        // 所有的通道打开都需要关闭
        producer.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;异步回调发送&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; /**
     * 异步发送带回调
     */
    public static void producerSendWithCallback() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;quot;localhost:9092&amp;quot;);
        props.put(ProducerConfig.ACKS_CONFIG, &amp;quot;all&amp;quot;);
        props.put(ProducerConfig.RETRIES_CONFIG, &amp;quot;0&amp;quot;);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, &amp;quot;16384&amp;quot;);
        props.put(ProducerConfig.LINGER_MS_CONFIG, &amp;quot;1&amp;quot;);
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, &amp;quot;33554432&amp;quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        // Producer的主对象
        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);

        for (int i = 0; i &amp;lt; 100; i++) {
            // ProducerRecord：消息对象
            producer.send(new ProducerRecord&amp;lt;String, String&amp;gt;(&amp;quot;test-topic&amp;quot;, &amp;quot;key-&amp;quot; + i, &amp;quot;value-&amp;quot; + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    System.out.println(
                            &amp;quot;partition : &amp;quot; + recordMetadata.partition() + &amp;quot;, offset : &amp;quot; + recordMetadata.offset());
                };
            });
        }
        // 所有的通道打开都需要关闭
        producer.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前面的示例中，每个 Partition 的记录是不确定。载均衡的目的是将消息尽可能平均分配，尽可能将消息平均分配给所有分区&lt;br&gt;
&lt;strong&gt;自定义 Partition 负载均衡&lt;/strong&gt;&lt;br&gt;
自定义 Partition， 实现 &lt;code&gt;Partitioner&lt;/code&gt; 接口，自己实现分区方法。&lt;br&gt;
在创建 &lt;code&gt;test-topic&lt;/code&gt; 时，指定了3个分区，这里简单的对 key 做处理之后，取余。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 自定义 Partition
public class SamplePartition implements Partitioner {

    @Override
    public void configure(Map&amp;lt;String, ?&amp;gt; arg0) {
        // TODO Auto-generated method stub

    }

    @Override
    public void close() {
        // TODO Auto-generated method stub

    }

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object Value, byte[] valueBytes, Cluster cluster) {
        String keyStr = key + &amp;quot;&amp;quot;;
        String keyInt = keyStr.substring(4);
        System.out.println(&amp;quot;======== keyInt ==========&amp;quot; + keyInt);
        int i = Integer.parseInt(keyInt);
        System.out.println(&amp;quot;======== i ==========&amp;quot; + i);

        return i % 3;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
     * 使用自定义 Partition
     * 异步发送带回调和Partition
*/
public static void producerSendWithCallbackAndPartition() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;quot;localhost:9092&amp;quot;);
        props.put(ProducerConfig.ACKS_CONFIG, &amp;quot;all&amp;quot;);
        props.put(ProducerConfig.RETRIES_CONFIG, &amp;quot;0&amp;quot;);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, &amp;quot;16384&amp;quot;);
        props.put(ProducerConfig.LINGER_MS_CONFIG, &amp;quot;1&amp;quot;);
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, &amp;quot;33554432&amp;quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                &amp;quot;org.apache.kafka.common.serialization.StringSerializer&amp;quot;);
        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, &amp;quot;work.flipped.kafka.producer.SamplePartition&amp;quot;);
        // Producer的主对象
        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);

        for (int i = 0; i &amp;lt; 100; i++) {
            // ProducerRecord：消息对象
            producer.send(new ProducerRecord&amp;lt;String, String&amp;gt;(&amp;quot;test-topic&amp;quot;, &amp;quot;key-&amp;quot; + i, &amp;quot;value-&amp;quot; + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    System.out.println(
                            &amp;quot;partition : &amp;quot; + recordMetadata.partition() + &amp;quot;, offset : &amp;quot; + recordMetadata.offset());
                };
            });
        }
        // 所有的通道打开都需要关闭
        producer.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;三个 Partition 的记录几乎一样多，分别为33，33，34，运行结果如图所示。&lt;img src=&#34;https://img.flipped.work/img/20210124212456.png&#34;/&gt;&lt;/p&gt;
&lt;h2 id=&#34;消息传递保障&#34;&gt;消息传递保障&lt;/h2&gt;
&lt;p&gt;在下一章介绍 Kafka Consumer后，介绍此内容。&lt;/p&gt;
">Kafka（三）Producer</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/qqGWSVvBP/"" data-c="
          &lt;p&gt;Kafka 包括五个核心 API：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Admin API 允许管理和检查主题、代理和其他Kafka对象。&lt;/li&gt;
&lt;li&gt;Producer  API 允许应用程序向 Kafka 集群中的主题发送数据流。&lt;/li&gt;
&lt;li&gt;Consumer API 允许应用程序从 Kafka 集群中的主题中读取数据流。&lt;/li&gt;
&lt;li&gt;Streams API 允许将数据流从输入主题转换为输出主题。&lt;/li&gt;
&lt;li&gt;Connect API 允许实现连续地从一些源系统或应用程序拉入Kafka 或从 Kafka 推入一些接收器系统或应用程序的连接器。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka 在一个独立于语言的协议上公开了它所有的功能，该协议有许多编程语言的客户端可用。然而，只有Java 客户端作为 Kafka 主要项目的一部分进行维护，其他的都可以作为独立的开源项目使用。&lt;br&gt;
本文只介绍 Admin API，其他 API 在后续章节给出。&lt;/p&gt;
&lt;h2 id=&#34;admin-api&#34;&gt;Admin API&lt;/h2&gt;
&lt;p&gt;Admin API支持管理和检查 Topic、Boker、ACL 和其他 Kafka 对象。要使用 Admin API，需要添加以下Maven依赖项:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.kafka&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;kafka-clients&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.7.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有关 Admin API 的更多信息，请参阅&lt;a href=&#34;https://kafka.apache.org/27/javadoc/index.html?org/apache/kafka/clients/admin/Admin.html&#34;&gt;javadoc&lt;/a&gt;。&lt;br&gt;
相对比较重要的几个 API，如下表所示。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;API&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AdminClient&lt;/td&gt;
&lt;td&gt;AdminClient 对象&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NewTopic&lt;/td&gt;
&lt;td&gt;创建 Topic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CreateTopicsResult&lt;/td&gt;
&lt;td&gt;创建 Topic 的返回结果&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ListTopicsResult&lt;/td&gt;
&lt;td&gt;查询 Topic 列表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ListTopicsOptions&lt;/td&gt;
&lt;td&gt;查询 Topic 列表及选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DescribeTopicsResult&lt;/td&gt;
&lt;td&gt;查询 Topics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DescribeConfigsResult&lt;/td&gt;
&lt;td&gt;查询 Topics 配置项&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;创建-adminclient&#34;&gt;创建 AdminClient&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static final String TOPIC_NAME = &amp;quot;test-topic&amp;quot;;

    public static AdminClient getAdminClient() {
        Properties properties = new Properties();
        properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;quot;localhost:9092&amp;quot;);
        return AdminClient.create(properties);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;创建-topic&#34;&gt;创建 Topic&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void createTopic() {
        AdminClient adminClient = getAdminClient();
        short rs = 1; // 副本因子
        NewTopic newTopic = new NewTopic(TOPIC_NAME, 3, rs);
        CreateTopicsResult topics = adminClient.createTopics(Arrays.asList(newTopic));
        System.out.println(&amp;quot;topics: &amp;quot; + topics);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;查看-topic-列表&#34;&gt;查看 Topic 列表&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void topicList() {
        AdminClient adminClient = getAdminClient();
        try {
            ListTopicsResult listTopicsResult = adminClient.listTopics();
            Set&amp;lt;String&amp;gt; names = listTopicsResult.names().get();
            System.out.println(&amp;quot;================&amp;quot;);
            names.forEach(System.out::println);
            System.out.println(&amp;quot;================&amp;quot;);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;删除-topic&#34;&gt;删除 Topic&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void deleteTopic() {
        AdminClient adminClient = getAdminClient();
        DeleteTopicsResult deleteTopicsResult = adminClient.deleteTopics(Collections.singletonList(TOPIC_NAME));
        try {
            deleteTopicsResult.all().get();
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;描述-topic&#34;&gt;描述 Topic&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void describeTopic() {
        AdminClient adminClient = getAdminClient();
        DescribeTopicsResult describeTopicsResult = adminClient
                .describeTopics(Arrays.asList(&amp;quot;test-topic&amp;quot;, &amp;quot;second-topic&amp;quot;));
        try {
            Map&amp;lt;String, TopicDescription&amp;gt; stringTopicDescriptionMap = describeTopicsResult.all().get();
            Set&amp;lt;Map.Entry&amp;lt;String, TopicDescription&amp;gt;&amp;gt; entries = stringTopicDescriptionMap.entrySet();
            System.out.println(&amp;quot;===========&amp;quot;);
            entries.forEach(entry -&amp;gt; {
                System.out.println(entry.getKey() + &amp;quot;:&amp;quot; + entry.getValue());
                System.out.println(&amp;quot;===========&amp;quot;);
            });
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;topic-配置信息&#34;&gt;Topic 配置信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void describeConfig() {
        AdminClient adminClient = getAdminClient();
        ConfigResource configResource = new ConfigResource(ConfigResource.Type.TOPIC, TOPIC_NAME);
        DescribeConfigsResult describeConfigsResult = adminClient
                .describeConfigs(Collections.singletonList(configResource));
        Map&amp;lt;ConfigResource, Config&amp;gt; configResourceConfigMap = null;
        try {
            configResourceConfigMap = describeConfigsResult.all().get();
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }
        assert configResourceConfigMap != null;
        Set&amp;lt;Map.Entry&amp;lt;ConfigResource, Config&amp;gt;&amp;gt; entries = configResourceConfigMap.entrySet();
        entries.forEach(entry -&amp;gt; System.out.println(entry.getKey() + &amp;quot;:&amp;quot; + entry.getValue()));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;修改-topic-配置&#34;&gt;修改 Topic 配置&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void alterConfigResult() {
        AdminClient adminClient = getAdminClient();
        Map&amp;lt;ConfigResource, Config&amp;gt; configMap = new HashMap&amp;lt;&amp;gt;();
        
        // 两个参数
        ConfigResource configResource = new ConfigResource(ConfigResource.Type.TOPIC, TOPIC_NAME);
        Config config = new Config(Collections.singletonList(new ConfigEntry(&amp;quot;preallocate&amp;quot;, &amp;quot;true&amp;quot;)));
        configMap.put(configResource, config);
        
        AlterConfigsResult alterConfigsResult = adminClient.alterConfigs(configMap);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;增加-partition-数量&#34;&gt;增加 Partition 数量&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void incrPartitions(int numPartitions) {
        AdminClient adminClient = getAdminClient();
        Map&amp;lt;String, NewPartitions&amp;gt; partitionsMap = new HashMap&amp;lt;&amp;gt;();
        NewPartitions newPartitions = NewPartitions.increaseTo(numPartitions);
        partitionsMap.put(TOPIC_NAME, newPartitions);
        CreatePartitionsResult partitions = adminClient.createPartitions(partitionsMap);
}
&lt;/code&gt;&lt;/pre&gt;
">Kafka（二）Admin API</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/zawpATTcu/"" data-c="
          &lt;h2 id=&#34;11-引言&#34;&gt;1.1 引言&lt;/h2&gt;
&lt;h3 id=&#34;什么是事件流&#34;&gt;什么是事件流？&lt;/h3&gt;
&lt;p&gt;从技术上讲，事件流是指以流的形式实时捕获事件源(如数据库、传感器、移动设备、云服务和软件应用程序)中的数据；持久地存储这些事件流以供以后检索;实时和回顾性地操作、处理和响应事件流；并根据需要将事件流路由到不同的目标的技术。因此，事件流确保了数据的连续流和解释，以便正确的信息在正确的时间出现在正确的位置。&lt;/p&gt;
&lt;h3 id=&#34;使用事件流可以做什么&#34;&gt;使用事件流可以做什么?&lt;/h3&gt;
&lt;p&gt;事件流应用于跨越众多行业和组织，包括:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实时处理支付和金融交易，如在证券交易所、银行和保险公司。&lt;/li&gt;
&lt;li&gt;实时跟踪和监控汽车、卡车、车队和发货，如物流和汽车行业。&lt;/li&gt;
&lt;li&gt;持续从物联网设备或其他设备(如工厂和风电场)获取和分析传感器数据。&lt;/li&gt;
&lt;li&gt;收集并立即响应客户的互动和订单，例如在零售，酒店和旅游行业以及移动应用程序中。&lt;/li&gt;
&lt;li&gt;监测住院病人的情况，预测病情变化，确保在紧急情况下及时治疗。&lt;/li&gt;
&lt;li&gt;连接、存储和提供由公司不同部门产生的数据。&lt;/li&gt;
&lt;li&gt;作为数据平台、事件驱动架构和微服务的基础。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;apache-kafka-是事件流平台意味着什么&#34;&gt;Apache Kafka 是事件流平台意味着什么？&lt;/h3&gt;
&lt;p&gt;Kafka结合了三个关键功能，所以可以用一个经过实战测试的解决方案来实现你的端到端事件流用例:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;发布（写入）和订阅（读取）事件流，包括从其他系统连续导入/导出数据。&lt;/li&gt;
&lt;li&gt;根据需要持久而可靠地存储事件流。&lt;/li&gt;
&lt;li&gt;处理事件流的发生或追溯。&lt;br&gt;
所有这些功能都以分布式，高度可扩展，弹性，容错和安全的方式提供。可以选择将 Kafka 部署在裸机硬件，虚拟机和容器，本地以及云中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kafka-概述&#34;&gt;Kafka 概述&lt;/h3&gt;
&lt;p&gt;Kafka是一个分布式系统，由服务器（Server）和客户端（Client）组成，通过高性能的TCP网络协议进行通信。它可以部署在裸机、虚拟机、内部环境和云环境中的容器上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务器&lt;/strong&gt;：Kafka 是作为一个集群运行的一个或多个服务器，可以跨多个数据中心或云区域。这些服务器中的一些形成了存储层，称为代理（Broker）。其他服务器运行 Kafka 连接 （ Kafka Connect）以事件流的形式不断导入和导出数据，将 Kafka 与现有系统集成，如关系数据库和其他Kafka集群。Kafka 集群是高度可扩展和容错的，如果它的任何一个服务器故障，其他服务器将接管它的工作，以确保不丢失任何数据的连续操作。&lt;br&gt;
&lt;strong&gt;客户端&lt;/strong&gt;：客户端实现编写分布式应用程序和微服务，即使在网络问题或机器故障的情况下，它们也可以并行地、大规模地、以容错的方式读取、写入和处理事件流。Kafka 社区提供了数十个客户端：Java 和 Scala 客户端，更高级别的 Kafka Streams 库，Go、Python、C/C++ 和许多其他编程语言以及REST API。&lt;/p&gt;
&lt;h3 id=&#34;主要概念及术语&#34;&gt;主要概念及术语&lt;/h3&gt;
&lt;p&gt;事件记录了在这个世界或你的业务中“发生了一些事情”的事实。它在文档中也称为记录或消息。当你向Kafka读写数据时，你是以事件的形式来完成的。从概念上讲，事件具有键、值、时间戳和可选的元数据头。下面是一个例子:&lt;/p&gt;
&lt;p&gt;活动重点:“爱丽丝”&lt;br&gt;
事件值:“向Bob支付了200美元”&lt;br&gt;
事件时间戳:“2020年6月25日下午2:06”&lt;br&gt;
生产者是那些向Kafka发布(写)事件的客户端应用程序，消费者是那些订阅(读和处理)这些事件的客户端应用程序。在Kafka中，生产者和消费者是完全解耦的，并且彼此是不可知的，这是一个关键的设计元素，以实现Kafka众所周知的高可伸缩性。例如，生产者永远不需要等待消费者。Kafka提供了各种各样的保证，比如精确地处理一次事件的能力。&lt;/p&gt;
&lt;p&gt;事件被组织并持久地存储在主题中。非常简单，主题类似于文件系统中的文件夹，事件是该文件夹中的文件。一个示例主题名称可以是“payments”。Kafka中的主题总是多生产者和多订阅者:一个主题可以有0个、1个或多个生产者向它写入事件，也可以有0个、1个或多个消费者订阅这些事件。主题中的事件可以根据需要经常读取—与传统消息传递系统不同，事件在使用后不会被删除。相反，你可以通过每个主题的配置设置来定义Kafka应该保留你的事件多长时间，超过这个时间旧的事件就会被丢弃。Kafka的性能与数据大小是一致的，所以长时间存储数据是非常好的。&lt;/p&gt;
&lt;p&gt;主题是分区的，这意味着一个主题被分散在位于不同Kafka broker上的许多“桶”上。数据的分布式放置对于可伸缩性非常重要，因为它允许客户机应用程序同时从多个代理读取和写入数据。当一个新事件被发布到一个主题时，它实际上被附加到该主题的一个分区中。具有相同事件键的事件(例如，一个客户或车辆ID)被写入到同一个分区，Kafka保证任何给定topic-partition的消费者总是会按照写入的顺序读取该分区的事件。&lt;/p&gt;
&lt;h3 id=&#34;主要概念及术语-2&#34;&gt;主要概念及术语&lt;/h3&gt;
&lt;p&gt;事件（Event）记录了在这个世界或你的业务中“发生了一些事情”的事实。它在文档中也称为记录或消息。向 Kafka 读写数据时，是以事件的形式完成的。从概念上讲，事件具有键（key）、值（value）、时间戳和可选的元数据头。下面是一个例子:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事件 Key:“爱丽丝”&lt;/li&gt;
&lt;li&gt;事件 Value:“向Bob支付了200美元”&lt;/li&gt;
&lt;li&gt;事件时间戳:“2020年6月25日下午2:06”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生产者（Producer）是那些向Kafka发布(写)事件的客户端应用程序，消费者（Consumer）是那些订阅(读和处理)这些事件的客户端应用程序。在Kafka中，生产者和消费者是完全解耦的，并且彼此是不可知的，这是实现 Kafka 众所周知的高可伸缩性的一个关键设计。例如，生产者永远不需要等待消费者。Kafka 提供了各种各样的保证，比如精确地处理一次事件的能力。&lt;/p&gt;
&lt;p&gt;事件被组织并持久地存储在主题（Topic）中。主题类似于文件系统中的文件夹，事件是该文件夹中的文件。示例的主题名称可以是“payments”。Kafka中的主题总是多生产者和多订阅者：一个主题可以有0个、1个或多个生产者向它写入事件，也可以有0个、1个或多个消费者订阅这些事件。主题中的事件可以根据需要经常读取，与传统消息传递系统不同，事件在使用后不会被删除。相反，可以通过每个主题的配置设置定义事件保留多长时间，超过这个时间旧的事件就会被丢弃。Kafka的性能相对于数据大小实际上是恒定的，因此长时间存储数据是完全可以的。&lt;/p&gt;
&lt;p&gt;主题是分区的（Partition），这意味着一个主题被分散在位于不同 Kafka 代理上的许多“桶(Bucket)”上。数据的分布式存储对于可伸缩性非常重要，因为它允许客户端应用程序同时从多个代理读取和写入数据。当一个新事件被发布到一个主题时，它实际上被附加到该主题的一个分区中。具有相同事件 key 的事件（例如，一个客户或车辆ID）将被写入到同一个分区，并且Kafka保证，何给定topic-partition的消费者总是会按照写入的顺序读取该分区的事件。&lt;br&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210124001127.png&#34;/&gt;&lt;br&gt;
如上图所示，示例主题有四个分区P1-P4。两个不同的生产者客户端通过网络将事件写入主题的分区，彼此独立地向主题发布新事件。具有相同键的事件（在图中用它们的颜色表示）被写入到相同的分区。注意，如果合适的话，两个生产者都可以写同一个分区。&lt;/p&gt;
&lt;p&gt;为了使数据具有容错性和高可用性，可以在每个地理区域或数据中心之间复制每个主题，以便始终有多个代理具有数据副本，以防万一出错。常见的生产设置复制因子为3，即数据将始终有三个副本。 此复制在主题分区级别执行。&lt;/p&gt;
&lt;p&gt;该入门手册应该足够介绍。 如果您有兴趣，文档的“设计”部分将详细介绍Kafka的各种概念。&lt;/p&gt;
&lt;p&gt;让你的数据容错和可用性,每一个主题可以被复制,甚至跨geo-regions或数据中心,这样总有多个经纪人有一份数据以防出错,你想做代理维护,等等。一个常见的生产设置是3的复制因子，也就是说，您的数据总是有三个副本。该复制在主题分区级别上执行。&lt;/p&gt;
&lt;h3 id=&#34;kafka-api&#34;&gt;Kafka API&lt;/h3&gt;
&lt;p&gt;除了用于管理和管理任务的命令行工具外，Kafka 还有用于 Java和Scala的五个核心API：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation.html#adminapi&#34;&gt;Admin API&lt;/a&gt;，用于管理和检查主题，代理和其他Kafka对象。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation.html#producerapi&#34;&gt;Producer API&lt;/a&gt;，用于将事件流发布（写）到一个或多个Kafka主题。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation.html#consumerapi&#34;&gt;Consumer API&lt;/a&gt;，订阅（读）一个或多个主题并处理为其产生的事件流。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34;&gt;Streams API&lt;/a&gt;，实现流处理应用程序和微服务。它提供了处理事件流的高级函数，包括转换、有状态操作（如聚合和连接、开窗、基于事件时间的处理等等）。从一个或多个主题读取输入，以便生成到一个或多个主题的输出，从而有效地将输入流转换为输出流。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation.html#connect&#34;&gt;Connect API&lt;/a&gt;，用于构建和运行可重用的数据导入/导出连接器，用于消费（读）或产生（写）来自外部系统和应用程序的事件流，以便与 Kafka 集成。例如，连接到关系数据库（如PostgreSQL）的连接器可能会捕获对一组表的每个更改。通常不需要实现自己的连接器，因为 Kafka 社区已经提供了数百个现成的连接器。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;12-用例&#34;&gt;1.2 用例&lt;/h2&gt;
&lt;h3 id=&#34;消息队列&#34;&gt;消息队列&lt;/h3&gt;
&lt;p&gt;Kafka可以很好地替代传消息代理。消息代理的使用有多种原因（将处理与数据生产者分离，缓冲未处理的消息等）。与大多数消息系统相比，Kafka 具有更好的吞吐量、内置分区、复制和容错，这使得它成为大规模消息处理应用程序的良好解决方案。&lt;br&gt;
在这个领域，Kafka 可以与 ActiveMQ 或 RabbitMQ 等传统消息系统相媲美。&lt;/p&gt;
&lt;h3 id=&#34;网站活跃追踪&#34;&gt;网站活跃追踪&lt;/h3&gt;
&lt;p&gt;Kafka 最初的用例是能够重建一个用户活跃跟踪管道作为一组实时发布-订阅管道。这意味着站点活跃（页面浏览、搜索或其他用户可能采取的行动）被发布到每个活动类型有一个主题的中心主题。这些管道可用于订阅一系列用例，包括实时处理、实时监控，并加载到Hadoop或离线数据仓库系统中以进行离线处理和报告。&lt;br&gt;
活跃跟踪的工作量通常非常大，因为会为每个用户页面视图生成许多活跃消息。&lt;/p&gt;
&lt;h3 id=&#34;度量&#34;&gt;度量&lt;/h3&gt;
&lt;p&gt;Kafka 经常用于运行监控数据。这涉及到从分布式应用程序聚合统计信息来生成集中的操作数据提要。&lt;br&gt;
###日志聚合&lt;br&gt;
许多人使用 Kafka 作为日志聚合解决方案的替代品。日志聚合通常从服务器收集物理日志文件，并将它们放在一个中心位置（可能是文件服务器或HDFS）进行处理。Kafka抽象了文件的细节，并将日志或事件数据作为消息流进行了更清晰的抽象。这允许更低的延迟处理，更容易支持多个数据源和分布式数据消费。与以日志为中心的系统（如Scribe或Flume）相比，Kafka提供了同样好的性能，由于复制而提供了更强的持久性保证，而且端到端延迟要低得多。&lt;/p&gt;
&lt;h3 id=&#34;流处理&#34;&gt;流处理&lt;/h3&gt;
&lt;p&gt;许多 Kafka 用户在处理管道中处理数据，该管道由多个阶段组成，原始输入数据从 Kafka 主题消费，然后聚合，丰富，或转换成新的主题，以进一步消费或后续处理。例如，推荐新闻文章的处理管道可能会从 RSS 订阅中抓取文章内容，并将其发布到“articles”主题；进一步的处理可能会对这些内容进行规范化或重复数据删除，并将清洗后的文章内容发布到新主题中；最后一个处理阶段可能会尝试向用户推荐这些内容。这种处理管道根据各个主题创建实时数据流图。从0.10.0.0开始，一个轻量级但强大的流处理库 Kafka Streams 在 Apache Kafka 中可用来执行如上所述的数据处理。除了 Kafka，其他开源流处理工具包括 Apache Storm 和 Apache Samza。&lt;/p&gt;
&lt;h2 id=&#34;13-快速开始&#34;&gt;1.3 快速开始&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;获取 Kafka&lt;br&gt;
&lt;a href=&#34;https://www.apache.org/dyn/closer.cgi?path=/kafka/2.7.0/kafka_2.13-2.7.0.tgz&#34;&gt;下载&lt;/a&gt;最新的Kafka版本并解压缩：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ tar -xzf kafka_2.13-2.7.0.tgz
$ cd kafka_2.13-2.7.0
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;启动 KAFKA 环境&lt;br&gt;
&lt;strong&gt;注意：本地环境必须安装了Java 8+&lt;/strong&gt;。顺序运行以下命令启动所有服务：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# S启动 ZooKeeper 服务
# 注意：很快 Apache Kafka 就将不再需要 Zookeeper.
$ bin/zookeeper-server-start.sh config/zookeeper.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;打开另一个终端，执行下面的命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 启动 Kafka 服务
$ bin/kafka-server-start.sh config/server.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在，一个基本的 Kafka 环境运行成功，可以使用了。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;创建主题存储事件&lt;br&gt;
Kafka 是一个分布式事件流平台，允许在多台机器上读取、写入、存储和处理事件（在文档中也称为记录或消息）。&lt;br&gt;
例如，支付交易、来自移动电话的地理位置更新、发货订单、来自物联网设备或医疗设备的传感器测量等等。这些事件被组织并存储在主题中。主题类似于文件系统中的文件夹，事件是该文件夹中的文件。&lt;br&gt;
因此，编写事件之前，必须创建主题。打开另一个终端并运行:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所有 Kafka 命令行工具都有额外的选项：运行不带任何参数的 Kafka-topics.sh 命令来显示使用信息。例如，显示新主题的分区数等细节:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210124093047.png&#34;/&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;向主题写入事件&lt;br&gt;
Kafka 客户端通过网络与 Kafka 代理通信，进行写(或读)事件。一旦收到，代理将以持久和容错的方式存储事件。&lt;br&gt;
运行控制台生产者客户端，在主题中写入事件。默认情况下，输入的每一行将导致一个单独的事件被写入主题。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ bin/kafka-console-producer.sh --topic quickstart-events --broker-list localhost:9092
This is my first event
This is my second event
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以随时使用 Ctrl-C 停止生产者客户端。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;读事件&lt;br&gt;
打开另一个终端并运行控制台消费者客户端读取刚刚创建的事件:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
This is my first event
This is my second event
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同样，可以随时使用 Ctrl-C 停止消费者客户端。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;使用 KAFKA CONNECT 导入/导出数据作为事件流&lt;br&gt;
可能在关系数据库或传统消息系统等现有系统中拥有大量数据，以及许多已经使用这些系统的应用程序。Kafka Connect 允许不断地从外部系统摄取数据到 Kafka，反之亦然。因此，将现有的系统与Kafka集成是非常容易的。为了使这个过程更容易，Kafka 社区提供了很多连接器。&lt;br&gt;
查看 &lt;a href=&#34;https://kafka.apache.org/documentation/#connect&#34;&gt;Kafka Connect 部分&lt;/a&gt;，了解更多关于如何导入/导出数据到/出 Kafka。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用 KAFKA 流处理事件&lt;br&gt;
一旦数据作为事件存储在 Kafka 中，就可以使用 Kafka Streams 客户端库处理数据。它允许实现关键任务实时应用程序和微服务，其中输入和/或输出数据存储在Kafka主题中。Kafka Streams 结合了在客户端编写和部署标准 Java 和 Scala 应用程序的简便性以及 Kafka 服务器端集群技术的优势，使这些应用程序具有高度可伸缩性，弹性，容错性和分布式性。 该库支持一次精确处理，有状态操作和聚合，开窗，联接，基于事件时间的处理等等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面是如何实现流行的WordCount算法:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;KStream&amp;lt;String, String&amp;gt; textLines = builder.stream(&amp;quot;quickstart-events&amp;quot;);

KTable&amp;lt;String, Long&amp;gt; wordCounts = textLines
            .flatMapValues(line -&amp;gt; Arrays.asList(line.toLowerCase().split(&amp;quot; &amp;quot;)))
            .groupBy((keyIgnored, word) -&amp;gt; word)
            .count();

wordCounts.toStream().to(&amp;quot;output-topic&amp;quot;), Produced.with(Serdes.String(), Serdes.Long()));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/25/documentation/streams/quickstart&#34;&gt;Kafka Stream Demo&lt;/a&gt; 和&lt;a href=&#34;https://kafka.apache.org/25/documentation/streams/tutorial&#34;&gt;应用程序开发教程&lt;/a&gt;演示了如何编写和运行这样的流应用程序。&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;终止 KAFKA&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;使用 Ctrl-C 停止生产者和消费者客户端（如果还没有这样做的话）。&lt;/li&gt;
&lt;li&gt;用 Ctrl-C 停止 Kafka 代理。&lt;/li&gt;
&lt;li&gt;最后，按 Ctrl-C 停止 ZooKeeper 服务器。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果还想删除本地 Kafka 环境的任何数据，包括已创建事件，只需运行命令:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ rm -rf /tmp/kafka-logs /tmp/zookeeper
&lt;/code&gt;&lt;/pre&gt;
">Kafka（一） 入门</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/MW6ZY5hk/"" data-c="
          &lt;p&gt;与 WSL 不同，WSL2 是一个完整的Linux内核。本文主要介绍在win10（版本号&lt;strong&gt;19042.746，专业版&lt;/strong&gt;）中启用 WSL2。&lt;/p&gt;
&lt;h2 id=&#34;安装wsl2&#34;&gt;安装WSL2&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-win10&#34;&gt;点击&lt;/a&gt;查看微软的官方说明。&lt;/p&gt;
&lt;h3 id=&#34;步骤1-启用linux子系统&#34;&gt;步骤1 启用Linux子系统&lt;/h3&gt;
&lt;p&gt;在Windows上安装任何Linux发行版之前，必须启用 Linux 子系统功能。&lt;/p&gt;
&lt;p&gt;以管理员身份打开PowerShell并运行：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;步骤2-启用虚拟机功能&#34;&gt;步骤2 启用虚拟机功能&lt;/h3&gt;
&lt;p&gt;安装WSL 2之前，必须启用虚拟机平台可选功能。以管理员身份打开PowerShell并运行：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重启电脑，完成WSL安装并更新到WSL 2。&lt;/p&gt;
&lt;h3 id=&#34;步骤3-下载linux内核更新程序包&#34;&gt;步骤3 下载Linux内核更新程序包&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi&#34;&gt;点击下载&lt;/a&gt;，双击安装。&lt;/p&gt;
&lt;h3 id=&#34;步骤4-将wsl-2设置为默认版本&#34;&gt;步骤4 将WSL 2设置为默认版本&lt;/h3&gt;
&lt;p&gt;在 PowerShell 中运行以下命令，WSL 2设置为默认版本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wsl --set-default-version 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;步骤5-安装发行版&#34;&gt;步骤5 安装发行版&lt;/h3&gt;
&lt;p&gt;打开&lt;a href=&#34;https://aka.ms/wslstore&#34;&gt;Microsoft商店&lt;/a&gt;，然后选择喜欢的Linux发行版。&lt;/p&gt;
&lt;h3 id=&#34;步骤6-验证&#34;&gt;步骤6 验证&lt;/h3&gt;
&lt;p&gt;在 PowerShell 中运行以下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wsl -l -v
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210120214258.png&#34;/&gt;
">安装 WSL2 (win10专业版，19042)</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/Kyv9tMmW/"" data-c="
          &lt;p&gt;nvm 是一个管理 node 版本的工具，可以安装切换不同版本的 node 提高开发效率。但是 nvm 默认的下载地址 http://nodejs.org/dist/ 服务器在国外，国内很慢，可能会下载失败。&lt;br&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210105094833.png&#34;/&gt;&lt;br&gt;
可以使用淘宝的镜像。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;where nvm&lt;/code&gt; 找到nvm安装路径&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210105095516.png&#34;/&gt;
&lt;ul&gt;
&lt;li&gt;找到在该目录下的 settings.txt 文件，将下面这两句话复制到 settings.txt 并保存&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;node_mirror: https://npm.taobao.org/mirrors/node/
npm_mirror: https://npm.taobao.org/mirrors/npm/
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;测试结果&lt;br&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210105095916.png&#34;/&gt;&lt;/li&gt;
&lt;/ul&gt;
">解决nvm下载node慢的问题</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/9m2MXIyWR/"" data-c="
          &lt;ul&gt;
&lt;li&gt;为什么 wait 方法必须在 synchronized 保护的同步代码中使用？&lt;/li&gt;
&lt;li&gt;为什么 wait/notify/notifyAll 被定义在 Object 类中，而 sleep 定义在 Thread 类中？&lt;/li&gt;
&lt;li&gt;wait/notify 和 sleep 方法的异同？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;为什么-wait-必须在-synchronized-保护的同步代码中使用&#34;&gt;为什么 wait 必须在 synchronized 保护的同步代码中使用？&lt;/h2&gt;
&lt;p&gt;wait 方法的源码注释：wait method should always be used in a loop。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; synchronized (obj) {
     while (condition does not hold)
         obj.wait();
         ... // Perform action appropriate to condition

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method should only be called by a thread that is the owner of this object&#39;s monitor.”意思是说，在使用 wait 方法时，必须把 wait 方法写在 synchronized 保护的 while 代码块中，并始终判断执行条件是否满足，如果满足就往下继续执行，如果不满足就执行 wait 方法，而在执行 wait 方法之前，必须先持有对象的 monitor 锁，也就是通常所说的 synchronized 锁。&lt;/p&gt;
&lt;p&gt;如果不要求 wait 方法放在 synchronized 保护的同步代码中使用，而是可以随意调用，那么就有可能写出这样的代码。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class BlockingQueue {
    Queue&amp;lt;String&amp;gt; buffer = new LinkedList&amp;lt;String&amp;gt;();
    public void give(String data) {
        buffer.add(data);
        notify();  // Since someone may be waiting in take
    }
    public String take() throws InterruptedException {
        while (buffer.isEmpty()) {
            wait();
        }
        return buffer.remove();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;give 方法负责往 buffer 中添加数据，添加完之后执行 notify 方法来唤醒之前等待的线程，take 方法检查 buffer 是否为空，如果为空就进入等待，如果不为空就取出一个数据，这是典型的生产者消费者的思想。&lt;/p&gt;
&lt;p&gt;但是这段代码并没有受 synchronized 保护，于是便有可能发生以下场景：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;首先，消费者线程调用 take 方法并判断 buffer.isEmpty 方法是否返回 true，若为 true 代表buffer是空的，则线程希望进入等待，但是在线程调用 wait 方法之前，就被调度器暂停了，所以此时还没来得及执行 wait 方法。&lt;br&gt;
此时生产者开始运行，执行了整个 give 方法，它往 buffer 中添加了数据，并执行了 notify 方法，但 notify 并没有任何效果，因为消费者线程的 wait 方法没来得及执行，所以没有线程在等待被唤醒。&lt;br&gt;
此时，刚才被调度器暂停的消费者线程回来继续执行 wait 方法并进入了等待。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;虽然消费者判断了 buffer.isEmpty 条件，但真正执行 wait 方法时，之前的 buffer.isEmpty 的结果已经过期了，不再符合最新的场景了，因为这里的“判断-执行”不是一个原子操作，它在中间被打断了，是线程不安全的。&lt;/p&gt;
&lt;p&gt;假设这时没有更多的生产者进行生产，消费者便有可能陷入无穷无尽的等待，因为它错过了刚才 give 方法内的 notify 的唤醒。&lt;/p&gt;
&lt;p&gt;因为 wait 方法所在的 take 方法没有被 synchronized 保护，所以它的 while 判断和 wait 方法无法构成原子操作，那么此时整个程序就很容易出错。&lt;/p&gt;
&lt;p&gt;把代码改写成源码注释所要求的被 synchronized 保护的同步代码块的形式，代码如下。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void give(String data) {
   synchronized (this) {
      buffer.add(data);
      notify();
  }
}

public String take() throws InterruptedException {
   synchronized (this) {
    while (buffer.isEmpty()) {
         wait();
       }
     return buffer.remove();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样就可以确保 notify 方法永远不会在 buffer.isEmpty 和 wait 方法之间被调用，提升了程序的安全性。&lt;br&gt;
另外，wait 方法会释放 monitor 锁，这也要求必须首先进入到 synchronized 内持有这把锁。&lt;/p&gt;
&lt;p&gt;这里还存在一个“虚假唤醒”的问题，线程可能在既没有被notify/notifyAll，也没有被中断或者超时的情况下被唤醒，虚假唤醒发生的概率很小，但是依然需要保证在发生虚假唤醒的时候的正确性，所以就需要采用while循环的结构。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;while (condition does not hold)
    obj.wait();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样即便被虚假唤醒了，也会再次检查while里面的条件，如果不满足条件，就会继续wait，也就消除了虚假唤醒的风险。&lt;/p&gt;
&lt;h2 id=&#34;为什么-waitnotifynotifyall-被定义在-object-类中而-sleep-定义在-thread-类中&#34;&gt;为什么 wait/notify/notifyAll 被定义在 Object 类中，而 sleep 定义在 Thread 类中？&lt;/h2&gt;
&lt;p&gt;主要有两点原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因为 Java 中每个对象都有称为 monitor 监视器的锁，由于每个对象都可以上锁，这就要求在对象头中有一个用来保存锁信息的位置。这个锁是对象级别的，而非线程级别的，wait/notify/notifyAll 也都是锁级别的操作，它们的锁属于对象，所以把它们定义在 Object 类中是最合适，因为 Object 类是所有对象的父类。&lt;/li&gt;
&lt;li&gt;如果把 wait/notify/notifyAll 方法定义在 Thread 类中，会带来局限性，比如一个线程可能持有多把锁，以便实现相互配合的复杂逻辑，假设此时 wait 方法定义在 Thread 类中，如何实现让一个线程持有多把锁呢？又如何明确线程等待的是哪把锁呢？既然是让当前线程去等待某个对象的锁，自然应该通过操作对象来实现，而不是操作线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;waitnotify-和-sleep-方法的异同&#34;&gt;wait/notify 和 sleep 方法的异同&lt;/h2&gt;
&lt;p&gt;相同点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它们都可以让线程阻塞。&lt;/li&gt;
&lt;li&gt;它们都可以响应 interrupt 中断：在等待的过程中如果收到中断信号，都可以进行响应，并抛出 InterruptedException 异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是它们也有很多的不同点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。&lt;/li&gt;
&lt;li&gt;在同步代码中执行 sleep 方法时，并不会释放 monitor 锁，但执行 wait 方法时会主动释放 monitor 锁。&lt;/li&gt;
&lt;li&gt;sleep 方法中会要求必须定义一个时间，时间到期后会主动恢复，而对于没有参数的 wait 方法而言，意味着永久等待，直到被中断或被唤醒才能恢复，它并不会主动恢复。&lt;/li&gt;
&lt;li&gt;wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。&lt;/li&gt;
&lt;/ul&gt;
">wait/notify/notifyAll 方法</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/gohIUX3YT/"" data-c="
          &lt;h2 id=&#34;线程-6-种状态&#34;&gt;线程 6 种状态&lt;/h2&gt;
&lt;p&gt;线程有自己的生命周期，在 Java 中线程的生命周期中一共有 6 种状态，转换图如下所示，图片来源：《Java并发编程的艺术》&lt;br&gt;
&lt;img src=&#34;https://img.flipped.work/img/20210101161850.png&#34;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New（新创建）&lt;/li&gt;
&lt;li&gt;Runnable（可运行）&lt;/li&gt;
&lt;li&gt;Blocked（被阻塞）&lt;/li&gt;
&lt;li&gt;Waiting（等待）&lt;/li&gt;
&lt;li&gt;Timed Waiting（计时等待）&lt;/li&gt;
&lt;li&gt;Terminated（被终止）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果想要确定线程当前的状态，可以通过 getState() 方法，并且线程在任何时刻只可能处于 1 种状态。&lt;/p&gt;
&lt;h3 id=&#34;new-新创建&#34;&gt;New 新创建&lt;/h3&gt;
&lt;p&gt;New 表示线程被创建但尚未启动的状态：当用 new Thread() 新建一个线程时，如果线程没有开始运行 start() 方法，所以也没有开始执行 run() 方法里面的代码，那么此时它的状态就是 New。而一旦线程调用了 start()，它的状态就会从 New 变成 Runnable。&lt;/p&gt;
&lt;h3 id=&#34;runnable-可运行&#34;&gt;Runnable 可运行&lt;/h3&gt;
&lt;p&gt;Java 中的 Runable 状态对应操作系统线程状态中的两种状态，分别是 Running 和 Ready，也就是说，Java 中处于 Runnable 状态的线程有可能正在执行，也有可能没有正在执行，正在等待被分配 CPU 资源。&lt;/p&gt;
&lt;p&gt;所以，如果一个正在运行的线程是 Runnable 状态，当它运行到任务的一半时，执行该线程的 CPU 被调度去做其他事情，导致该线程暂时不运行，它的状态依然不变，还是 Runnable，因为它有可能随时被调度回来继续执行任务。&lt;/p&gt;
&lt;h3 id=&#34;阻塞状态&#34;&gt;阻塞状态&lt;/h3&gt;
&lt;p&gt;在 Java 中阻塞状态通常不仅仅是 Blocked，实际上它包括三种状态，分别是 Blocked(被阻塞）、Waiting(等待）、Timed Waiting(计时等待），这三 种状态统称为阻塞状态，下面来看看这三种状态具体是什么含义。&lt;/p&gt;
&lt;h4 id=&#34;blocked-被阻塞&#34;&gt;Blocked 被阻塞&lt;/h4&gt;
&lt;p&gt;从箭头的流转方向可以看出，从 Runnable 状态进入 Blocked 状态只有一种可能，就是进入 synchronized 保护的代码（synchronized 代码块，还是 synchronized 方法）时没有抢到 monitor 锁。&lt;br&gt;
当处于 Blocked 的线程抢到 monitor 锁，就会从 Blocked 状态回到Runnable 状态。&lt;/p&gt;
&lt;h4 id=&#34;waiting-等待&#34;&gt;Waiting 等待&lt;/h4&gt;
&lt;p&gt;线程进入 Waiting 状态有三种可能性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有设置 Timeout 参数的 Object.wait() 方法。&lt;/li&gt;
&lt;li&gt;没有设置 Timeout 参数的 Thread.join() 方法。&lt;/li&gt;
&lt;li&gt;LockSupport.park() 方法。&lt;br&gt;
Blocked 仅仅针对 synchronized monitor 锁，可是在 Java 中还有很多其他的锁，比如 ReentrantLock，如果线程在获取这种锁时没有抢到该锁就会进入 Waiting 状态，因为本质上它执行了 LockSupport.park() 方法，所以会进入 Waiting 状态。同样，Object.wait() 和 Thread.join() 也会让线程进入 Waiting 状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Blocked 与 Waiting 的区别是 Blocked 在等待其他线程释放 monitor 锁，而 Waiting 则是在等待某个条件，比如 join 的线程执行完毕，或者是 notify()/notifyAll() 。&lt;/p&gt;
&lt;h4 id=&#34;timed-waiting-限期等待&#34;&gt;Timed Waiting 限期等待&lt;/h4&gt;
&lt;p&gt;Waiting 和 Timed Waiting 状态非常相似，区别仅在于有没有时间限制，Timed Waiting 会等待超时，由系统自动唤醒，或者在超时前被唤醒信号唤醒。&lt;br&gt;
以下情况会让线程进入 Timed Waiting 状态。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置了时间参数的 Thread.sleep(long millis) 方法；&lt;/li&gt;
&lt;li&gt;设置了时间参数的 Object.wait(long timeout) 方法；&lt;/li&gt;
&lt;li&gt;设置了时间参数的 Thread.join(long millis) 方法；&lt;/li&gt;
&lt;li&gt;设置了时间参数的 LockSupport.parkNanos(long nanos) 方法和 LockSupport.parkUntil(long deadline) 方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从 Blocked 状态进入 Runnable 状态，要求线程获取 monitor 锁。&lt;br&gt;
从 Waiting 状态流转到其他状态则比较特殊，因为 Waiting 是不限时的，无论过了多长时间它都不会主动恢复，只有当执行了 LockSupport.unpark()，或者 join 的线程运行结束，或者被中断时才可以进入 Runnable 状态。如果其他线程调用 notify() 或 notifyAll()来唤醒它，它会直接进入 Blocked 状态，因为唤醒 Waiting 线程的线程如果调用 notify() 或 notifyAll()，要求必须首先持有该 monitor 锁，所以处于 Waiting 状态的线程被唤醒时拿不到该锁，就会进入 Blocked 状态，直到执行了 notify()/notifyAll() 的唤醒它的线程执行完毕并释放 monitor 锁，才可能轮到它去抢夺这把锁，如果它能抢到，就会从 Blocked 状态回到 Runnable 状态。&lt;/p&gt;
&lt;p&gt;在 Timed Waiting 中执行 notify() 和 notifyAll() 也是一样的道理，它们会先进入 Blocked 状态，然后抢夺锁成功后，再回到 Runnable 状态。如果它的超时时间到了且能直接获取到锁/join的线程运行结束/被中断/调用了LockSupport.unpark()，会直接恢复到 Runnable 状态，而无需经历 Blocked 状态。&lt;/p&gt;
&lt;h3 id=&#34;terminated-终止&#34;&gt;Terminated 终止&lt;/h3&gt;
&lt;p&gt;要想进入这个状态有两种可能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run() 方法执行完毕，线程正常退出。&lt;/li&gt;
&lt;li&gt;出现一个没有捕获的异常，终止了 run() 方法，最终导致意外终止。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;注意点&#34;&gt;注意点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;线程的状态是需要按照箭头方向来走的，比如线程从 New 状态是不可以直接进入 Blocked 状态的，它需要先经历 Runnable 状态。&lt;/li&gt;
&lt;li&gt;线程生命周期不可逆：一旦进入 Runnable 状态就不能回到 New 状态；一旦被终止就不可能再有任何状态的变化。所以一个线程只能有一次 New 和 Terminated 状态，只有处于中间状态才可以相互转换。&lt;/li&gt;
&lt;/ul&gt;
">线程状态</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/0N3BonuMR/"" data-c="
          &lt;h2 id=&#34;启动线程&#34;&gt;启动线程&lt;/h2&gt;
&lt;p&gt;启动线程非常简单，只需要调用 Thread 类的 start() 方法，并在 run() 方法中定义需要执行的任务，但如果想要正确停止它就没那么简单了。&lt;/p&gt;
&lt;h2 id=&#34;原理介绍&#34;&gt;原理介绍&lt;/h2&gt;
&lt;p&gt;通常情况下，不会手动停止线程，而是允许线程运行到结束，让它自然停止。但是，某些特殊情况下，需要提前停止线程，比如程序运行出错重启等，这种情况下，正确停止线程就很重要。&lt;/p&gt;
&lt;h2 id=&#34;为什么不强制停止&#34;&gt;为什么不强制停止&lt;/h2&gt;
&lt;p&gt;正确停止线程的方式是使用 interrupt。但 interrupt 仅仅起到通知被停止线程的作用。而对于被停止线程而言，它既可以选择立即停止，也可以选择一段时间后停止，也可以选择压根不停止。&lt;/p&gt;
&lt;p&gt;强制停止线程可能会造成一些安全的问题，比如：线程正在写入一个文件，这时收到终止信号，它就需要根据自身业务判断，是选择立即停止，还是将整个文件写入成功后停止，如果选择立即停止就可能造成数据不完整。&lt;/p&gt;
&lt;h2 id=&#34;用-interrupt-停止线程&#34;&gt;用 interrupt 停止线程&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;while (!Thread.currentThread().isInterrupted() &amp;amp;&amp;amp; more work to do) {
    do more work
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一旦调用线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。线程执行时，应该定期检查这个标记位，如果标记位被设置成 true，就说明有程序想终止该线程。如代码所示，在 while 循环体判断语句中，首先通过 Thread.currentThread().isInterrupt() 判断线程是否被中断，随后检查是否还有工作要做。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class StopThread implements Runnable {
    
    @Override
    public void run() {
        int count = 0;
        while (!Thread.currentThread().isInterrupted() &amp;amp;&amp;amp; count &amp;lt; 1000) {
            System.out.println(&amp;quot;count = &amp;quot; + count++);
        }
    }

    public static void main(String[] args) throws InterruptedException {
        Thread thread = new Thread(new StopThread());
        thread.start();
        Thread.sleep(5);
        thread.interrupt();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 StopThread 类的 run() 方法中，首先判断线程是否被中断，然后判断 count 值是否小于 1000。线程会在每次循环开始之前，检查是否被中断了。接下来在 main 函数中会启动该线程，然后休眠 5 毫秒后立刻中断线程，该线程会检测到中断信号，于是在还没打印完1000个数的时候就会停下来，这种就属于通过 interrupt 正确停止线程的情况。&lt;/p&gt;
&lt;h2 id=&#34;sleep-期间能否感受到中断&#34;&gt;sleep 期间能否感受到中断&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Runnable runnable = () -&amp;gt; {
    int num = 0;
    try {
        while (!Thread.currentThread().isInterrupted() &amp;amp;&amp;amp; num &amp;lt;= 1000) {
            System.out.println(num);
            num++;
            Thread.sleep(1000000);
        }
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;改写上面的代码，每打印一个数字，就进入一次 sleep，而此时将 Thread.sleep() 的休眠时间设置为 1000 秒钟。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class StopDuringSleep {
 
    public static void main(String[] args) throws InterruptedException {
        Runnable runnable = () -&amp;gt; {
            int num = 0;
            try {
               while (!Thread.currentThread().isInterrupted() &amp;amp;&amp;amp; num &amp;lt;= 1000){
                    System.out.println(num);
                    num++;
                    Thread.sleep(1000000);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        };
        Thread thread = new Thread(runnable);
        thread.start();
        Thread.sleep(5);
        thread.interrupt();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;主线程休眠 5 毫秒后，通知子线程中断，此时子线程仍在执行 sleep 语句，处于休眠中。那么在休眠中的线程是否能够感受到中断通知呢？是否需要等到休眠结束后才能中断线程呢？如果是这样，就会带来严重的问题，因为响应中断太不及时了。&lt;/p&gt;
&lt;p&gt;如果 sleep、wait 等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，那么线程是可以感受到中断信号的，并且会抛出一个 InterruptedException 异常，同时清除中断信号，将中断标记位设置成 false。这样一来即便线程还在休眠，仍然能够响应中断通知，并抛出异常。&lt;/p&gt;
&lt;h2 id=&#34;最佳处理方式&#34;&gt;最佳处理方式&lt;/h2&gt;
&lt;p&gt;我们编写的方法内调用了 sleep 或者 wait 等能响应中断的方法时，仅仅 catch 住异常是不够的。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void subTas() {
    try {
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        // 在这里不处理该异常是非常不好的
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以在方法中使用 try/catch 或在方法签名中声明 throws  InterruptedException。&lt;/p&gt;
&lt;h3 id=&#34;方法签名抛异常run-强制-trycatch&#34;&gt;方法签名抛异常，run() 强制 try/catch&lt;/h3&gt;
&lt;p&gt;如上面的代码所示，catch 语句块里代码是空的，它并没有进行任何处理。假设线程执行到这个方法，并且正在 sleep，此时有线程发送 interrupt 通知试图中断线程，就会立即抛出异常，并清除中断信号。抛出的异常被 catch 语句块捕捉。&lt;/p&gt;
&lt;p&gt;但是，捕捉到异常的 catch 没有进行任何处理逻辑，相当于把中断信号给隐藏了，这样做是不合理的，那么应该怎么处理呢？首先，可以选择在方法签名中抛出异常。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void subTask2() throws InterruptedException {
    Thread.sleep(1000);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如代码所示，要求每一个方法的调用方有义务去处理异常。调用方要不使用 try/catch 并在 catch 中正确处理异常，要不将异常声明到方法签名中，便可以将中断信号层层传递到顶层，最终让 run() 方法可以捕获到异常。run() 方法本身没有抛出 checkedException 的能力，只能通过 try/catch 来处理异常，就可以根据不同逻辑来进行相应的处理。&lt;/p&gt;
&lt;h3 id=&#34;再次中断&#34;&gt;再次中断&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void reInterrupt() {
    try {
        Thread.sleep(2000);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        e.printStackTrace();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了将异常声明到方法签名中的方式外，还可以在 catch 语句中再次中断线程。如代码所示，需要在 catch 语句块中调用 Thread.currentThread().interrupt() 函数。因为如果线程在休眠期间被中断，那么会自动清除中断信号。如果这时手动添加中断信号，中断信号依然可以被捕捉到。这样后续执行的方法依然可以检测到这里发生过中断，可以做出相应的处理，整个线程可以正常退出。&lt;/p&gt;
&lt;p&gt;不能盲目吞掉中断，如果不在方法签名中声明，也不在 catch 语句块中再次恢复中断，而是在 catch 中不作处理，会导致中断信号被完全忽略，最终导致线程无法正确停止。&lt;/p&gt;
&lt;h2 id=&#34;为什么用-volatile-标记位的停止方法是错误的&#34;&gt;为什么用 volatile 标记位的停止方法是错误的&lt;/h2&gt;
&lt;h3 id=&#34;错误的停止方法&#34;&gt;错误的停止方法&lt;/h3&gt;
&lt;p&gt;首先，看几种停止线程的错误方法。比如 stop()，suspend() 和 resume()，这些方法已经被 Java 直接标记为 @Deprecated。如果再调用这些方法，IDE 会友好地提示，不应该再使用它们了。 stop() 会直接把线程停止，这样就没有给线程足够的时间来处理想要在停止前保存数据的逻辑，会导致出现数据完整性等问题。&lt;/p&gt;
&lt;p&gt;而对于 suspend() 和 resume() 而言，它们的问题在于如果线程调用 suspend()，它并不会释放锁，就开始进入休眠，但此时有可能仍持有锁，这样就容易导致死锁问题，因为这把锁在线程被 resume() 之前，是不会被释放的。所以 suspend() 和 resume() 组合使用的方法也被废弃了。&lt;/p&gt;
&lt;h3 id=&#34;volatile-修饰标记位适用的场景&#34;&gt;volatile 修饰标记位适用的场景&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class VolatileCanStop implements Runnable { 

    private volatile boolean canceled = false;

    @Override
    public void run() {
        int num = 0;
        try {
            while (!canceled &amp;amp;&amp;amp; num &amp;lt;= 1000000) {
                if (num % 10 == 0) {
                    System.out.println(num + &amp;quot;是10的倍数。&amp;quot;);
                }
                num++;
                Thread.sleep(1);
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) throws InterruptedException {
        VolatileCanStop r = new VolatileCanStop();
        Thread thread = new Thread(r);
        thread.start();
        Thread.sleep(3000);
        r.canceled = true;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如代码所示，在循环体中又进行了两层判断，首先判断 canceled 变量的值，canceled 变量是一个被 volatile 修饰的初始值为 false 的布尔值，当该值变为 true 时，while 跳出循环，while 的第二个判断条件是 num 值小于1000000（一百万），在while 循环体里，只要是 10 的倍数就打印出来，然后 num++。&lt;/p&gt;
&lt;p&gt;接下来，启动线程，经过 3 秒钟的时间，把用 volatile 修饰的布尔值的标记位设置成 true，这样，正在运行的线程就会在下一次 while 循环中判断出 canceled 的值已经变成 true 了，这样就不再满足 while 的判断条件，跳出整个 while 循环，线程就停止了，这种情况是演示 volatile 修饰的标记位可以正常工作的情况。&lt;/p&gt;
&lt;h3 id=&#34;volatile-修饰标记位不适用的场景&#34;&gt;volatile 修饰标记位不适用的场景&lt;/h3&gt;
&lt;p&gt;接下来用一个生产者/消费者模式的案例来演示为什么说  volatile 标记位的停止方法是不完美的。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Producer implements Runnable {

    public volatile boolean canceled = false;

    BlockingQueue storage;

    public Producer(BlockingQueue storage) {
        this.storage = storage;
    }

    @Override
    public void run() {
        int num = 0;
        try {
            while (num &amp;lt;= 100000 &amp;amp;&amp;amp; !canceled) {
                if (num % 50 == 0) {
                    storage.put(num);
                    System.out.println(num + &amp;quot;是50的倍数,被放到仓库中了。&amp;quot;);
                }
                num++;
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            System.out.println(&amp;quot;生产者结束运行&amp;quot;);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;声明一个生产者 Producer，通过 volatile 标记的初始值为 false 的布尔值 canceled 来停止线程。在 run() 方法中，while 的判断语句是 num 是否小于 100000 及 canceled 是否被标记。while 循环体中判断 num 如果是 50 的倍数就放到 storage 仓库中，storage 是生产者与消费者之间进行通信的存储器，当 num 大于 100000 或被通知停止时，会跳出 while 循环并执行 finally 语句块。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Consumer {
    BlockingQueue storage;
    public Consumer(BlockingQueue storage) {
        this.storage = storage;
    }
    public boolean needMoreNums() {
        if (Math.random() &amp;gt; 0.97) {
            return false;
        }
        return true;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;消费者 Consumer 生产者共用同一个仓库 storage，并且在方法内通过 needMoreNums() 方法判断是否需要继续使用更多的数字，生产者生产了一些 50 的倍数供消费者使用，消费者是否继续使用数字的判断条件是产生一个随机数并与 0.97 进行比较，大于 0.97 就不再继续使用数字。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) throws InterruptedException {
        ArrayBlockingQueue storage = new ArrayBlockingQueue(8);
        Producer producer = new Producer(storage);
        Thread producerThread = new Thread(producer);
        producerThread.start();
        Thread.sleep(500);
        Consumer consumer = new Consumer(storage);
        while (consumer.needMoreNums()) {
            System.out.println(consumer.storage.take() + &amp;quot;被消费了&amp;quot;);
            Thread.sleep(100);
        }
        System.out.println(&amp;quot;消费者不需要更多数据了。&amp;quot;);
        //一旦消费不需要更多数据了，我们应该让生产者也停下来，但是实际情况却停不下来
        producer.canceled = true;
        System.out.println(producer.canceled);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;main 函数中创建了生产者/消费者共用的仓库 BlockingQueue storage，仓库容量是 8，并且建立生产者并将生产者放入线程后启动线程，启动后进行 500 毫秒的休眠，休眠时间保障生产者有足够的时间把仓库塞满，而仓库达到容量后就不会再继续往里塞，这时生产者会阻塞，500 毫秒后消费者也被创建出来，并判断是否需要使用更多的数字，然后每次消费后休眠 100 毫秒。&lt;/p&gt;
&lt;p&gt;当消费者不再需要数据，就会将 canceled 的标记位设置为 true，理论上此时生产者会跳出 while 循环，并打印输出“生产者运行结束”。结果却是，虽然把 canceled 设置成 true，但生产者仍然没有停止，这是因为在这种情况下，生产者在执行 storage.put(num) 时发生阻塞，在它被叫醒之前是没有办法进入下一次循环判断 canceled 的值的，所以在这种情况下用 volatile 是没有办法让生产者停下来的，相反如果用 interrupt 语句来中断，即使生产者处于阻塞状态，仍然能够感受到中断信号，并做响应处理。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
">停止线程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/X4Fq8787p/"" data-c="
          &lt;p&gt;实现线程的方式到底有几种？大部分人会说有 2 种、3 种或是 4 种，其实实现线程的方法只有 1 种。2 种实现方式的描述是最基本的，也是最为熟知的。&lt;/p&gt;
&lt;h2 id=&#34;实现-runnable-接口&#34;&gt;实现 Runnable 接口&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RunnableThread implements Runnable {

   @Override
    public void run() {
        System.out.println(&#39;用实现Runnable接口实现线程&#39;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第 1 种方式是实现 Runnable 接口，如代码所示，RunnableThread 类实现 Runnable 接口，重写 run() 方法。只需要把 RunnableThread 的实例传到 Thread 类就可以实现多线程。&lt;/p&gt;
&lt;h2 id=&#34;继承-thread-类&#34;&gt;继承 Thread 类&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExtendsThread extends Thread {

    @Override
    public void run() {
        System.out.println(&#39;用Thread类实现线程&#39;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第 2 种方式是继承 Thread 类，并重写 run() 方法。&lt;/p&gt;
&lt;h2 id=&#34;线程池创建&#34;&gt;线程池创建&lt;/h2&gt;
&lt;p&gt;第 3 种方式通过线程池创建线程。线程池的确实现了多线程，比如给线程池的线程数量设置成 10，那么就会有 10 个子线程来工作。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static class DefaultThreadFactory implements ThreadFactory {
        private static final AtomicInteger poolNumber = new AtomicInteger(1);
        private final ThreadGroup group;
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        DefaultThreadFactory() {
            SecurityManager s = System.getSecurityManager();
            group = (s != null) ? s.getThreadGroup() :
                                  Thread.currentThread().getThreadGroup();
            namePrefix = &amp;quot;pool-&amp;quot; +
                          poolNumber.getAndIncrement() +
                         &amp;quot;-thread-&amp;quot;;
        }

        public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r,
                                  namePrefix + threadNumber.getAndIncrement(),
                                  0);
            if (t.isDaemon())
                t.setDaemon(false);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;线程池通过线程工厂（默认采用 DefaultThreadFactory）创建线程 ，它会给线程设置一些默认值，比如，线程的名字、是否是守护线程，以及线程的优先级等，但最终通过 new Thread() 创建线程。&lt;/p&gt;
&lt;h2 id=&#34;有返回值的-callable-创建线程&#34;&gt;有返回值的 Callable 创建线程&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class CallableTask implements Callable&amp;lt;Integer&amp;gt; {

   @Override
    public Integer call() throws Exception {
        return new Random().nextInt();
    }
}
//创建线程池
ExecutorService service = Executors.newFixedThreadPool(10);
//提交任务，并用 Future提交返回结果
Future&amp;lt;Integer&amp;gt; future = service.submit(new CallableTask());
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第 4 种线程创建方式通过有返回值的 Callable 创建线程，Runnable 创建线程无返回值，Callable 和与之相关的 Future、FutureTask，可以把线程执行的结果作为返回值返回，如代码所示，实现了 Callable 接口，它的泛型设置成 Integer，然后它会返回一个随机数。&lt;/p&gt;
&lt;p&gt;但是，无论是 Callable 还是 FutureTask，和 Runnable 一样，都是需要被执行的一个任务，它们本身不是线程，它们可以放到线程池中执行，如代码所示， submit() 方法把任务放到线程池中，并由线程池创建的线程执行，而子线程的创建方式是实现 Runnable 接口和继承 Thread 类。&lt;/p&gt;
&lt;h2 id=&#34;实现线程只有一种方式&#34;&gt;实现线程只有一种方式&lt;/h2&gt;
&lt;p&gt;先认为有两种创建线程的方式（其他比如线程池，是在 new Thread() 外做了一层封装，最终都是基于 Runnable 接口或继承 Thread 类实现），为什么说这两种方式本质上是一种呢？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void run() {
    if (target != null) {
        target.run();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第一种方式，也就是实现 Runnable 接口方式。启动线程需要调用 start() 方法，而 start() 方法最终会调用 run() 方法，第一种方式中 第 1 行代码 if (target != null) ，判断 target 是否等于 null，如果不等于 null，就执行第 2 行代码 target.run()，而 target 实际上是一个 Runnable，即使用 Runnable 接口实现线程时传给Thread类的对象。&lt;/p&gt;
&lt;p&gt;第二种方式，也就是继承 Thread 方式，会把上述的 run() 方法重写，重写后 run() 方法里直接就是所需要执行的任务，最终调用 thread.start() 方法来启动线程，而 start() 方法最终也会调用这个已经被重写的 run() 方法来执行它的任务。&lt;/p&gt;
&lt;p&gt;所以，实现线程只有一种方式，而要想实现线程执行的内容，却有两种方式，也就是可以通过 实现 Runnable 接口的方式，或是继承 Thread 类重写 run() 方法的方式，把想要执行的代码传入，让线程去执行。&lt;/p&gt;
&lt;h2 id=&#34;实现-runnable-接口比继承-thread-类实现线程要好&#34;&gt;实现 Runnable 接口比继承 Thread 类实现线程要好&lt;/h2&gt;
&lt;p&gt;现在对两种实现线程的方式进行对比，也就是为什么实现 Runnable 接口比继承 Thread 类实现线程要好？&lt;/p&gt;
&lt;p&gt;首先，Runnable 里只有一个 run() 方法，它定义了需要执行的内容，这种情况下，实现了 Runnable 与 Thread 类的解耦，Thread 类负责线程启动和属性设置等内容。&lt;/p&gt;
&lt;p&gt;第二点就是在某些情况下可以提高性能，使用继承 Thread 类方式，每次执行一次任务，都需要新建一个独立的线程，如果此时执行的内容比较少且需要多次执行，创建线程、销毁线程，这些操作操作比 run() 方法本身开销要大得多。如果使用实现 Runnable 接口的方式，就可以把任务直接传入线程池，使用一些固定的线程来完成任务，不需要每次新建销毁线程，大大降低了性能开销。&lt;/p&gt;
&lt;p&gt;第三点好处在于 Java 语言不支持双继承，如果一旦继承了 Thread 类，那么它后续就没有办法再继承其他的类，如果未来这个类需要继承其他类实现一些功能上的拓展，它就没有办法做到了，限制了代码未来的可拓展性。&lt;/p&gt;
&lt;p&gt;综上所述，应该优先选择通过实现 Runnable 接口的方式来创建线程。&lt;/p&gt;
">实现线程的方法</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/about/"" data-c="
          &lt;blockquote&gt;
&lt;p&gt;欢迎来到我的小站呀，很高兴遇见你！🤝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;关于本站&#34;&gt;🏠 关于本站&lt;/h2&gt;
&lt;h2 id=&#34;博主是谁&#34;&gt;👨‍💻 博主是谁&lt;/h2&gt;
&lt;h2 id=&#34;兴趣爱好&#34;&gt;⛹ 兴趣爱好&lt;/h2&gt;
&lt;h2 id=&#34;联系我呀&#34;&gt;📬 联系我呀&lt;/h2&gt;
">关于</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://flipped94.github.io/post/hello-gridea/"" data-c="
          &lt;p&gt;👏  欢迎使用 &lt;strong&gt;Gridea&lt;/strong&gt; ！&lt;br&gt;
✍️  &lt;strong&gt;Gridea&lt;/strong&gt; 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/getgridea/gridea&#34;&gt;Github&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://gridea.dev/&#34;&gt;Gridea 主页&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://fehey.com/&#34;&gt;示例网站&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;特性&#34;&gt;特性👇&lt;/h2&gt;
&lt;p&gt;📝  你可以使用最酷的 &lt;strong&gt;Markdown&lt;/strong&gt; 语法，进行快速创作&lt;/p&gt;
&lt;p&gt;🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片&lt;/p&gt;
&lt;p&gt;🏷️  你可以对文章进行标签分组&lt;/p&gt;
&lt;p&gt;📋  你可以自定义菜单，甚至可以创建外部链接菜单&lt;/p&gt;
&lt;p&gt;💻  你可以在 &lt;strong&gt;Windows&lt;/strong&gt;，&lt;strong&gt;MacOS&lt;/strong&gt; 或 &lt;strong&gt;Linux&lt;/strong&gt; 设备上使用此客户端&lt;/p&gt;
&lt;p&gt;🌎  你可以使用 &lt;strong&gt;𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌&lt;/strong&gt; 或 &lt;strong&gt;Coding Pages&lt;/strong&gt; 向世界展示，未来将支持更多平台&lt;/p&gt;
&lt;p&gt;💬  你可以进行简单的配置，接入 &lt;a href=&#34;https://github.com/gitalk/gitalk&#34;&gt;Gitalk&lt;/a&gt; 或 &lt;a href=&#34;https://github.com/SukkaW/DisqusJS&#34;&gt;DisqusJS&lt;/a&gt; 评论系统&lt;/p&gt;
&lt;p&gt;🇬🇧  你可以使用&lt;strong&gt;中文简体&lt;/strong&gt;或&lt;strong&gt;英语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力&lt;/p&gt;
&lt;p&gt;🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步&lt;/p&gt;
&lt;p&gt;🌱 当然 &lt;strong&gt;Gridea&lt;/strong&gt; 还很年轻，有很多不足，但请相信，它会不停向前 🏃&lt;/p&gt;
&lt;p&gt;未来，它一定会成为你离不开的伙伴&lt;/p&gt;
&lt;p&gt;尽情发挥你的才华吧！&lt;/p&gt;
&lt;p&gt;😘 Enjoy~&lt;/p&gt;
">Hello Gridea</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  !function () {
    let times = document.querySelectorAll('.publish-time');
    for (let i = 0; i < times.length; i++) {
      let date = times[i].dataset.t;
      let time = Math.floor((new Date().getTime() - new Date(date).getTime()) / 1000);
      if (time < 60) {
        str = time + '秒之前';
      } else if (time < 3600) {
        str = Math.floor(time / 60) + '分钟之前';
      } else if (time >= 3600 && time < 86400) {
        str = Math.floor(time / 3600) + '小时之前';
      } else if (time >= 86400 && time < 259200) {
        str = Math.floor(time / 86400) + '天之前';
      } else {
        str = times[i].textContent;
      }
      times[i].textContent = str;
    }
  }();
</script>

<script>
  let language = '';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 200
  });
</script>






</html>